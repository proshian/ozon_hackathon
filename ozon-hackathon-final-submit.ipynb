{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nfrom functools import partial\nfrom typing import List, Iterable\nimport os\n\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom catboost import CatBoostClassifier, Pool\nfrom catboost.utils import eval_metric\nfrom scipy.spatial.distance import cosine, euclidean\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:10:23.678400Z","start_time":"2023-05-19T06:10:16.503064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load data","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_parquet(\"/kaggle/input/hackathon-files-for-participants-ozon/train_pairs.parquet\")\netl = pd.read_parquet(\"/kaggle/input/hackathon-files-for-participants-ozon/train_data.parquet\")","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:12:05.012452Z","start_time":"2023-05-19T06:11:27.878101Z"},"execution":{"iopub.status.busy":"2023-05-30T19:40:55.339941Z","iopub.execute_input":"2023-05-30T19:40:55.340648Z","iopub.status.idle":"2023-05-30T19:41:23.702574Z","shell.execute_reply.started":"2023-05-30T19:40:55.340613Z","shell.execute_reply":"2023-05-30T19:41:23.701600Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dataset.head(2)","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:12:07.891757Z","start_time":"2023-05-19T06:12:07.868318Z"},"execution":{"iopub.status.busy":"2023-05-30T19:41:23.704009Z","iopub.execute_input":"2023-05-30T19:41:23.704396Z","iopub.status.idle":"2023-05-30T19:41:23.722338Z","shell.execute_reply.started":"2023-05-30T19:41:23.704361Z","shell.execute_reply":"2023-05-30T19:41:23.721395Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   target  variantid1  variantid2\n0     0.0    51197862    51198054\n1     1.0    53062686   536165289","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>variantid1</th>\n      <th>variantid2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>51197862</td>\n      <td>51198054</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>53062686</td>\n      <td>536165289</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset[\"target\"].value_counts()","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:12:20.476738Z","start_time":"2023-05-19T06:12:20.458918Z"},"execution":{"iopub.status.busy":"2023-05-30T19:41:23.725475Z","iopub.execute_input":"2023-05-30T19:41:23.725880Z","iopub.status.idle":"2023-05-30T19:41:23.740349Z","shell.execute_reply.started":"2023-05-30T19:41:23.725849Z","shell.execute_reply":"2023-05-30T19:41:23.739269Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0.0    171527\n1.0    135013\nName: target, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"etl.head(2)","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:12:27.245184Z","start_time":"2023-05-19T06:12:27.228294Z"},"execution":{"iopub.status.busy":"2023-05-30T19:41:23.741842Z","iopub.execute_input":"2023-05-30T19:41:23.743102Z","iopub.status.idle":"2023-05-30T19:41:23.774555Z","shell.execute_reply.started":"2023-05-30T19:41:23.743069Z","shell.execute_reply":"2023-05-30T19:41:23.772448Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   variantid                                               name  \\\n0   51195767  Удлинитель Партнер-Электро ПВС 2х0,75 ГОСТ,6A,...   \n1   53565809  Магнитный кабель USB 2.0 A (m) - USB Type-C (m...   \n\n                                          categories color_parsed  \\\n0  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...  [оранжевый]   \n1  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Кабели ...    [красный]   \n\n                            pic_embeddings_resnet_v1  \\\n0                                               None   \n1  [[0.26863545, -0.3130674, 0.29023397, 0.073978...   \n\n                       main_pic_embeddings_resnet_v1  \\\n0  [[0.04603629, 0.18839523, -0.09973055, -0.6636...   \n1  [[1.1471839, -0.665361, 0.7745614, 0.26716197,...   \n\n                                        name_bert_64  \\\n0  [-0.47045058, 0.67237014, 0.48984158, -0.54485...   \n1  [-0.6575592, 0.6522429, 0.5426037, -0.54347897...   \n\n                   characteristic_attributes_mapping  \n0  {\"Номинальный ток, А\":[\"10\"],\"Цвет товара\":[\"о...  \n1  {\"Конструктивные особенности\":[\"Магнитная конс...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variantid</th>\n      <th>name</th>\n      <th>categories</th>\n      <th>color_parsed</th>\n      <th>pic_embeddings_resnet_v1</th>\n      <th>main_pic_embeddings_resnet_v1</th>\n      <th>name_bert_64</th>\n      <th>characteristic_attributes_mapping</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>51195767</td>\n      <td>Удлинитель Партнер-Электро ПВС 2х0,75 ГОСТ,6A,...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n      <td>[оранжевый]</td>\n      <td>None</td>\n      <td>[[0.04603629, 0.18839523, -0.09973055, -0.6636...</td>\n      <td>[-0.47045058, 0.67237014, 0.48984158, -0.54485...</td>\n      <td>{\"Номинальный ток, А\":[\"10\"],\"Цвет товара\":[\"о...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53565809</td>\n      <td>Магнитный кабель USB 2.0 A (m) - USB Type-C (m...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Кабели ...</td>\n      <td>[красный]</td>\n      <td>[[0.26863545, -0.3130674, 0.29023397, 0.073978...</td>\n      <td>[[1.1471839, -0.665361, 0.7745614, 0.26716197,...</td>\n      <td>[-0.6575592, 0.6522429, 0.5426037, -0.54347897...</td>\n      <td>{\"Конструктивные особенности\":[\"Магнитная конс...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"etl.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:41:23.776354Z","iopub.execute_input":"2023-05-30T19:41:23.777102Z","iopub.status.idle":"2023-05-30T19:41:24.692141Z","shell.execute_reply.started":"2023-05-30T19:41:23.777071Z","shell.execute_reply":"2023-05-30T19:41:24.691184Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 457063 entries, 0 to 457062\nData columns (total 8 columns):\n #   Column                             Non-Null Count   Dtype \n---  ------                             --------------   ----- \n 0   variantid                          457063 non-null  int64 \n 1   name                               457063 non-null  object\n 2   categories                         457063 non-null  object\n 3   color_parsed                       378652 non-null  object\n 4   pic_embeddings_resnet_v1           303467 non-null  object\n 5   main_pic_embeddings_resnet_v1      457063 non-null  object\n 6   name_bert_64                       457063 non-null  object\n 7   characteristic_attributes_mapping  457036 non-null  object\ndtypes: int64(1), object(7)\nmemory usage: 27.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nfrom copy import copy\nfrom transformers import BertTokenizer, BertModel\n\n\n# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n# model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n\ndef percent_of_intersection(lst1, lst2):\n    min_len = min(len(lst1), len(lst2))\n    \n    return len(list(set(lst1) & set(lst2))) / min_len if min_len > 0 else 0\n\ndef get_words_and_num_values(tokens):\n    words = []\n    numerical_values = []\n    for token in tokens:\n        if bool(re.search('[0-9]', token)):\n            if bool(re.search('[а-яА-ЯёЁa-zA-Z]', token)):\n                numerical_values.append(copy(token))\n            else:\n                numerical_values.append(copy(token))\n        else:\n            if bool(re.search('[a-zA-Z]', token)):\n                if len(token) > 4:\n                    words.append(copy(token))\n                else:\n                    numerical_values.append(copy(token))\n            else:\n                words.append(copy(token))\n\n    return words, numerical_values\n\n\ndef tokenize_text(text):\n    delimiters = '-', '. ', ' ', ':', '/', ', ', '\\'', '\\\"'\n    text += ' '\n    regex_pattern = '|'.join(map(re.escape, delimiters))\n    tokens = re.split(regex_pattern, text)\n    return tokens\n\n\ndef texts_to_intersection_percent(t1, t2):\n    _, nums1 = get_words_and_num_values(tokenize_text(t1))\n    _, nums2 = get_words_and_num_values(tokenize_text(t2))\n    return percent_of_intersection(nums1, nums2)\n    \n\n\ndef text_to_emb(text, model, tokenizer):\n    tokens = tokenize_text(text)\n    words, _ = get_words_and_num_values(tokens)\n    limit = 512  # есть названия больше, из берт не принимает :(\n    new_text = ' '.join(words)[:512]\n    encoded_input = tokenizer(new_text, return_tensors='pt')\n    emb = model(**encoded_input)\n    \n    return emb\n\n\n# def text_to_emb_and_num_vals_and_insterction_percent(text, model, tokenizer):\n#     tokens = tokenize_text(text)\n#     words, numerical_values = get_words_and_num_values(tokens)\n#     new_text = ' '.join(words)\n#     encoded_input = tokenizer(new_text, return_tensors='pt')\n#     emb = model(**encoded_input)\n    \n#     return emb, numerical_values, insterction_percent","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:41:24.693639Z","iopub.execute_input":"2023-05-30T19:41:24.693971Z","iopub.status.idle":"2023-05-30T19:41:24.736752Z","shell.execute_reply.started":"2023-05-30T19:41:24.693941Z","shell.execute_reply":"2023-05-30T19:41:24.735785Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# text1 = 'Удлинитель Партнер-Электро ПВС 2х0,75 ГОСТ,6A,30 метров,IP 44'\n\n# text_to_emb(text1, model, tokenizer)[1].detach().numpy()[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:41:24.738501Z","iopub.execute_input":"2023-05-30T19:41:24.738833Z","iopub.status.idle":"2023-05-30T19:41:24.750339Z","shell.execute_reply.started":"2023-05-30T19:41:24.738802Z","shell.execute_reply":"2023-05-30T19:41:24.749261Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# etl[[\"eugene_bert_embedding\"]] = (\n#     etl[\"name\"].apply(\n#         lambda x: pd.Series(text_to_emb(x, model, tokenizer)[1].detach().numpy()[0])\n#     )\n# )","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-05-30T19:41:24.751926Z","iopub.execute_input":"2023-05-30T19:41:24.752625Z","iopub.status.idle":"2023-05-30T19:41:24.761695Z","shell.execute_reply.started":"2023-05-30T19:41:24.752592Z","shell.execute_reply":"2023-05-30T19:41:24.760775Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# etl['eugene_bert_embedding'] = np.nan\n\n# for ind in tqdm(etl.index):\n#     text_to_emb(etl.at[ind, 'name'], model, tokenizer)[1].detach().numpy()[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:41:24.766105Z","iopub.execute_input":"2023-05-30T19:41:24.766409Z","iopub.status.idle":"2023-05-30T19:41:24.773424Z","shell.execute_reply.started":"2023-05-30T19:41:24.766386Z","shell.execute_reply":"2023-05-30T19:41:24.772478Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# for product in tqdm(etl.itertuples(), total = len(etl)):\n#     text_to_emb(product.name, model, tokenizer)[1].detach().numpy()[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:41:24.774839Z","iopub.execute_input":"2023-05-30T19:41:24.775361Z","iopub.status.idle":"2023-05-30T19:41:24.785214Z","shell.execute_reply.started":"2023-05-30T19:41:24.775331Z","shell.execute_reply":"2023-05-30T19:41:24.784214Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# etl['eugene_bert_embedding'] = np.nan\n\n# total = 0\n# for website in websites.itertuples():\n#     total += website.total_views\n# return total","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:41:24.786815Z","iopub.execute_input":"2023-05-30T19:41:24.787583Z","iopub.status.idle":"2023-05-30T19:41:24.796244Z","shell.execute_reply.started":"2023-05-30T19:41:24.787552Z","shell.execute_reply":"2023-05-30T19:41:24.795248Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# решил для каждого типа фичей посмотреть на несколько примеров\nfrom collections import defaultdict \n\nd = defaultdict(list)\n\nexample_ids = [0, 100, 1000, 10000]\n\nfor i in example_ids:\n    for key in etl:\n        d[key].append(etl[key][i])","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:41:24.797732Z","iopub.execute_input":"2023-05-30T19:41:24.798129Z","iopub.status.idle":"2023-05-30T19:41:24.813590Z","shell.execute_reply.started":"2023-05-30T19:41:24.798099Z","shell.execute_reply":"2023-05-30T19:41:24.812399Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"d[\"categories\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:41:24.815368Z","iopub.execute_input":"2023-05-30T19:41:24.815697Z","iopub.status.idle":"2023-05-30T19:41:24.827135Z","shell.execute_reply.started":"2023-05-30T19:41:24.815667Z","shell.execute_reply":"2023-05-30T19:41:24.826216Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые фильтры, разветвители и удлинители\", \"4\": \"Сетевой фильтр, удлинитель, разветвитель\"}'"},"metadata":{}}]},{"cell_type":"markdown","source":"Get raw data for each variantid.","metadata":{}},{"cell_type":"code","source":"features = (\n    dataset\n    .merge(\n        etl\n        .add_suffix('1'),\n        on=\"variantid1\"\n    )\n    .merge(\n        etl\n        .add_suffix('2'),\n        on=\"variantid2\"\n    )\n)","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:13:06.702876Z","start_time":"2023-05-19T06:13:03.688111Z"},"execution":{"iopub.status.busy":"2023-05-30T19:41:24.828681Z","iopub.execute_input":"2023-05-30T19:41:24.829007Z","iopub.status.idle":"2023-05-30T19:41:26.198968Z","shell.execute_reply.started":"2023-05-30T19:41:24.828978Z","shell.execute_reply":"2023-05-30T19:41:26.197989Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"features.head(2)","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:13:09.645490Z","start_time":"2023-05-19T06:13:09.620414Z"},"execution":{"iopub.status.busy":"2023-05-30T19:41:26.200223Z","iopub.execute_input":"2023-05-30T19:41:26.200591Z","iopub.status.idle":"2023-05-30T19:41:26.231196Z","shell.execute_reply.started":"2023-05-30T19:41:26.200560Z","shell.execute_reply":"2023-05-30T19:41:26.230221Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   target  variantid1  variantid2  \\\n0     0.0    51197862    51198054   \n1     0.0    51197862    51199884   \n\n                                               name1  \\\n0  Удлинитель TDM Electric Люкс УЛ05В 5 м (SQ1303...   \n1  Удлинитель TDM Electric Люкс УЛ05В 5 м (SQ1303...   \n\n                                         categories1 color_parsed1  \\\n0  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...       [белый]   \n1  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...       [белый]   \n\n  pic_embeddings_resnet_v11  \\\n0                      None   \n1                      None   \n\n                      main_pic_embeddings_resnet_v11  \\\n0  [[-0.4304909, -0.49474272, -0.46439183, -0.060...   \n1  [[-0.4304909, -0.49474272, -0.46439183, -0.060...   \n\n                                       name_bert_641  \\\n0  [-0.5104684, 0.56158644, 0.58873796, -0.529718...   \n1  [-0.5104684, 0.56158644, 0.58873796, -0.529718...   \n\n                  characteristic_attributes_mapping1  \\\n0  {\"Число жил\":[\"3\"],\"Макс. нагрузка, Вт\":[\"3500...   \n1  {\"Число жил\":[\"3\"],\"Макс. нагрузка, Вт\":[\"3500...   \n\n                                               name2  \\\n0  Удлинитель TDM Electric Люкс УЛ05В 1.5 м (SQ13...   \n1  Удлинитель TDM Electric Люкс УЛ05В 3 м (SQ1303...   \n\n                                         categories2 color_parsed2  \\\n0  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...       [белый]   \n1  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...       [белый]   \n\n  pic_embeddings_resnet_v12  \\\n0                      None   \n1                      None   \n\n                      main_pic_embeddings_resnet_v12  \\\n0  [[-0.42941108, -0.5129398, -0.4753536, -0.0677...   \n1  [[-0.43180764, -0.49580905, -0.5062628, -0.130...   \n\n                                       name_bert_642  \\\n0  [-0.455473, 0.58157134, 0.5870387, -0.5325003,...   \n1  [-0.5425725, 0.6415736, 0.51481575, -0.5687392...   \n\n                  characteristic_attributes_mapping2  \n0  {\"Электробезопасность\":[\"Заземление\"],\"Длина к...  \n1  {\"Макс. нагрузка, Вт\":[\"3500\"],\"Стандарт защит...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>variantid1</th>\n      <th>variantid2</th>\n      <th>name1</th>\n      <th>categories1</th>\n      <th>color_parsed1</th>\n      <th>pic_embeddings_resnet_v11</th>\n      <th>main_pic_embeddings_resnet_v11</th>\n      <th>name_bert_641</th>\n      <th>characteristic_attributes_mapping1</th>\n      <th>name2</th>\n      <th>categories2</th>\n      <th>color_parsed2</th>\n      <th>pic_embeddings_resnet_v12</th>\n      <th>main_pic_embeddings_resnet_v12</th>\n      <th>name_bert_642</th>\n      <th>characteristic_attributes_mapping2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>51197862</td>\n      <td>51198054</td>\n      <td>Удлинитель TDM Electric Люкс УЛ05В 5 м (SQ1303...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n      <td>[белый]</td>\n      <td>None</td>\n      <td>[[-0.4304909, -0.49474272, -0.46439183, -0.060...</td>\n      <td>[-0.5104684, 0.56158644, 0.58873796, -0.529718...</td>\n      <td>{\"Число жил\":[\"3\"],\"Макс. нагрузка, Вт\":[\"3500...</td>\n      <td>Удлинитель TDM Electric Люкс УЛ05В 1.5 м (SQ13...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n      <td>[белый]</td>\n      <td>None</td>\n      <td>[[-0.42941108, -0.5129398, -0.4753536, -0.0677...</td>\n      <td>[-0.455473, 0.58157134, 0.5870387, -0.5325003,...</td>\n      <td>{\"Электробезопасность\":[\"Заземление\"],\"Длина к...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>51197862</td>\n      <td>51199884</td>\n      <td>Удлинитель TDM Electric Люкс УЛ05В 5 м (SQ1303...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n      <td>[белый]</td>\n      <td>None</td>\n      <td>[[-0.4304909, -0.49474272, -0.46439183, -0.060...</td>\n      <td>[-0.5104684, 0.56158644, 0.58873796, -0.529718...</td>\n      <td>{\"Число жил\":[\"3\"],\"Макс. нагрузка, Вт\":[\"3500...</td>\n      <td>Удлинитель TDM Electric Люкс УЛ05В 3 м (SQ1303...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n      <td>[белый]</td>\n      <td>None</td>\n      <td>[[-0.43180764, -0.49580905, -0.5062628, -0.130...</td>\n      <td>[-0.5425725, 0.6415736, 0.51481575, -0.5687392...</td>\n      <td>{\"Макс. нагрузка, Вт\":[\"3500\"],\"Стандарт защит...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Features functions.","metadata":{}},{"cell_type":"code","source":"def get_pic_features(main_pic_embeddings_1,\n                     main_pic_embeddings_2,\n                     percentiles: List[int]):\n    \"\"\"Calculate distances percentiles for \n    pairwise pic distances. Percentiles are useful \n    when product has several pictures.\n    \"\"\"\n    \n    if main_pic_embeddings_1 is not None and main_pic_embeddings_2 is not None:\n        main_pic_embeddings_1 = np.array([x for x in main_pic_embeddings_1])\n        main_pic_embeddings_2 = np.array([x for x in main_pic_embeddings_2])\n        \n        dist_m = pairwise_distances(\n            main_pic_embeddings_1, main_pic_embeddings_2\n        )\n    else:\n        dist_m = np.array([[-1]])\n\n    pair_features = []\n    pair_features += np.percentile(dist_m, percentiles).tolist()\n\n    return pair_features\n\n\ndef text_dense_distances(ozon_embedding, comp_embedding):\n    \"\"\"Calculate Euclidean and Cosine distances between\n    ozon_embedding and comp_embedding.\n    \"\"\"\n    pair_features = []\n    if ozon_embedding is None or comp_embedding is None:\n        pair_features = [-1, -1]\n    elif len(ozon_embedding) == 0 or len(comp_embedding) == 0:\n        pair_features = [-1, -1]\n    else:\n        pair_features.append(\n            euclidean(ozon_embedding, comp_embedding)\n        )\n        cosine_value = cosine(ozon_embedding, comp_embedding)\n        \n        pair_features.append(cosine_value)\n\n    return pair_features\n","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:14:03.019463Z","start_time":"2023-05-19T06:14:03.002869Z"},"execution":{"iopub.status.busy":"2023-05-30T19:41:26.232682Z","iopub.execute_input":"2023-05-30T19:41:26.233345Z","iopub.status.idle":"2023-05-30T19:41:26.243143Z","shell.execute_reply.started":"2023-05-30T19:41:26.233284Z","shell.execute_reply":"2023-05-30T19:41:26.242070Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"get_pic_features_func = partial(\n    get_pic_features,\n    percentiles=[0, 25, 50]\n)","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:14:25.968001Z","start_time":"2023-05-19T06:14:25.965711Z"},"execution":{"iopub.status.busy":"2023-05-30T19:41:26.244760Z","iopub.execute_input":"2023-05-30T19:41:26.245141Z","iopub.status.idle":"2023-05-30T19:41:26.257132Z","shell.execute_reply.started":"2023-05-30T19:41:26.245106Z","shell.execute_reply":"2023-05-30T19:41:26.256244Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"features[[\"pic_dist_0_perc\", \"pic_dist_25_perc\", \"pic_dist_50_perc\"]] = (\n    features[[\"pic_embeddings_resnet_v11\", \"pic_embeddings_resnet_v12\"]].apply(\n        lambda x: pd.Series(get_pic_features_func(*x)), axis=1\n    )\n)\n\n# btw try to add distances between main pic embs","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:17:05.936723Z","start_time":"2023-05-19T06:14:27.944747Z"},"execution":{"iopub.status.busy":"2023-05-30T19:41:26.258323Z","iopub.execute_input":"2023-05-30T19:41:26.258738Z","iopub.status.idle":"2023-05-30T19:44:32.314227Z","shell.execute_reply.started":"2023-05-30T19:41:26.258707Z","shell.execute_reply":"2023-05-30T19:44:32.313130Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"features[[\"euclidean_name_bert_dist\", \"cosine_name_bert_dist\"]] = (\n    features[[\"name_bert_641\", \"name_bert_642\"]].apply(\n        lambda x: pd.Series(text_dense_distances(*x)), axis=1\n    )\n)\n\n# try to use your favorite NLP model","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:18:48.810761Z","start_time":"2023-05-19T06:17:26.418017Z"},"execution":{"iopub.status.busy":"2023-05-30T19:44:32.315682Z","iopub.execute_input":"2023-05-30T19:44:32.316030Z","iopub.status.idle":"2023-05-30T19:45:54.957564Z","shell.execute_reply.started":"2023-05-30T19:44:32.315994Z","shell.execute_reply":"2023-05-30T19:45:54.956581Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# # Добавим расстояния для фичей от Жени\n\n# features[[\"euclidean_eugene_name_bert_dist\", \"cosine_eugene_name_bert_dist\"]] = (\n#     features[[\"eugene_bert_embedding1\", \"eugene_bert_embedding2\"]].apply(\n#         lambda x: pd.Series(text_dense_distances(*x)), axis=1\n#     )\n# )\n\n# # try to use your favorite NLP model","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:45:54.959099Z","iopub.execute_input":"2023-05-30T19:45:54.959788Z","iopub.status.idle":"2023-05-30T19:45:54.964088Z","shell.execute_reply.started":"2023-05-30T19:45:54.959755Z","shell.execute_reply":"2023-05-30T19:45:54.963348Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# добавим долю совпадающих численных значений\n\nfeatures[[\"numerical_intersection_percent\"]] = (\n    features[[\"name1\", \"name2\"]].apply(\n        lambda x: pd.Series(texts_to_intersection_percent(*x)), axis=1\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:45:54.965833Z","iopub.execute_input":"2023-05-30T19:45:54.966454Z","iopub.status.idle":"2023-05-30T19:47:27.239872Z","shell.execute_reply.started":"2023-05-30T19:45:54.966424Z","shell.execute_reply":"2023-05-30T19:47:27.238877Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"features[\"cat3\"] = features[\"categories1\"].apply(lambda x: json.loads(x)[\"3\"])\ncat3_counts = features[\"cat3\"].value_counts().to_dict()","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:28:28.028773Z","start_time":"2023-05-19T06:28:27.086139Z"},"execution":{"iopub.status.busy":"2023-05-30T19:47:27.241507Z","iopub.execute_input":"2023-05-30T19:47:27.241881Z","iopub.status.idle":"2023-05-30T19:47:28.641692Z","shell.execute_reply.started":"2023-05-30T19:47:27.241837Z","shell.execute_reply":"2023-05-30T19:47:28.640695Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Let's find good cat size threshold","metadata":{}},{"cell_type":"code","source":"cntr = 0\nfor cat3 in cat3_counts:\n    if cat3_counts[cat3] < 1_000:\n        cntr += cat3_counts[cat3]\n        \ncntr","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:28:30.630458Z","start_time":"2023-05-19T06:28:30.624296Z"},"execution":{"iopub.status.busy":"2023-05-30T19:47:28.643277Z","iopub.execute_input":"2023-05-30T19:47:28.643663Z","iopub.status.idle":"2023-05-30T19:47:28.654028Z","shell.execute_reply.started":"2023-05-30T19:47:28.643629Z","shell.execute_reply":"2023-05-30T19:47:28.652995Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"10765"},"metadata":{}}]},{"cell_type":"markdown","source":"10k for \"rest\" cats probably is good","metadata":{}},{"cell_type":"code","source":"features[\"cat3_grouped\"] = features[\"cat3\"].apply(lambda x: x if cat3_counts[x] > 1000 else \"rest\")","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:28:36.996792Z","start_time":"2023-05-19T06:28:36.896447Z"},"execution":{"iopub.status.busy":"2023-05-30T19:47:28.655575Z","iopub.execute_input":"2023-05-30T19:47:28.655917Z","iopub.status.idle":"2023-05-30T19:47:28.761356Z","shell.execute_reply.started":"2023-05-30T19:47:28.655876Z","shell.execute_reply":"2023-05-30T19:47:28.760439Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:47:28.762847Z","iopub.execute_input":"2023-05-30T19:47:28.763216Z","iopub.status.idle":"2023-05-30T19:47:28.768494Z","shell.execute_reply.started":"2023-05-30T19:47:28.763183Z","shell.execute_reply":"2023-05-30T19:47:28.767502Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"cos = nn.CosineSimilarity(dim=0, eps=1e-6)\ndef dist(input_1, input_2):\n    return 1 - cos(input_1, input_2)\n    #return nn.functional.pairwise_distance(input_1, input_2)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:47:28.769771Z","iopub.execute_input":"2023-05-30T19:47:28.770381Z","iopub.status.idle":"2023-05-30T19:47:28.782477Z","shell.execute_reply.started":"2023-05-30T19:47:28.770338Z","shell.execute_reply":"2023-05-30T19:47:28.781570Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#nn.functional.pairwise_distance(s, s1)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:47:28.789454Z","iopub.execute_input":"2023-05-30T19:47:28.789732Z","iopub.status.idle":"2023-05-30T19:47:28.795078Z","shell.execute_reply.started":"2023-05-30T19:47:28.789707Z","shell.execute_reply":"2023-05-30T19:47:28.794203Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#! Переписать бы как это уже было сделано выше\n\nfeatures['main_cos_dist'] = np.nan\nfeatures['main_evc_dist'] = np.nan\n#from scipy.spatial.distance import cdist\nfrom scipy import spatial\nfor ind in tqdm(features.index):\n    #print(ind)\n    cosine_val = cosine(features['main_pic_embeddings_resnet_v11'][ind][0], features['main_pic_embeddings_resnet_v12'][ind][0])\n    evlid_val = euclidean(features['main_pic_embeddings_resnet_v11'][ind][0], features['main_pic_embeddings_resnet_v12'][ind][0])\n    features.at[ind, 'main_cos_dist'] = cosine_val\n    features.at[ind, 'main_evc_dist'] = evlid_val","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:47:28.796244Z","iopub.execute_input":"2023-05-30T19:47:28.796663Z","iopub.status.idle":"2023-05-30T19:48:40.491783Z","shell.execute_reply.started":"2023-05-30T19:47:28.796632Z","shell.execute_reply":"2023-05-30T19:48:40.490847Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"100%|██████████| 306540/306540 [01:11<00:00, 4276.56it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Choose features","metadata":{}},{"cell_type":"code","source":"feats = [\n    \"pic_dist_0_perc\", \"pic_dist_25_perc\", \"pic_dist_50_perc\", \n    'euclidean_name_bert_dist', 'cosine_name_bert_dist',\n#     'numerical_intersection_percent', 'eugene_bert_embedding1', \"eugene_bert_embedding2\",\n    'numerical_intersection_percent',\n    'main_cos_dist', 'main_evc_dist']","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:28:45.696151Z","start_time":"2023-05-19T06:28:45.692484Z"},"execution":{"iopub.status.busy":"2023-05-30T19:48:40.493228Z","iopub.execute_input":"2023-05-30T19:48:40.494036Z","iopub.status.idle":"2023-05-30T19:48:40.499466Z","shell.execute_reply.started":"2023-05-30T19:48:40.494000Z","shell.execute_reply":"2023-05-30T19:48:40.498459Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Split dataset","metadata":{}},{"cell_type":"code","source":"siamese_feats = ['main_pic_embeddings_resnet_v12', 'main_pic_embeddings_resnet_v11']","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:48:40.500913Z","iopub.execute_input":"2023-05-30T19:48:40.501706Z","iopub.status.idle":"2023-05-30T19:48:40.515372Z","shell.execute_reply.started":"2023-05-30T19:48:40.501670Z","shell.execute_reply":"2023-05-30T19:48:40.514442Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"X_train, X_test = train_test_split(\n    features[feats + [\"target\", \"variantid1\", \"variantid2\", \"cat3_grouped\"] + siamese_feats] ,\n    test_size=0.1, random_state=42, stratify=features[[\"target\", \"cat3_grouped\"]]\n)\n\nX_train, X_val = train_test_split(\n    X_train[feats + [\"target\",  \"variantid1\", \"variantid2\", \"cat3_grouped\"] + siamese_feats], \n    test_size=0.1, random_state=42, stratify=X_train[[\"target\", \"cat3_grouped\"]]\n)\n\ny_test = X_test[[\"target\", \"variantid1\", \"variantid2\"]]\nX_test = X_test.drop([\"target\"], axis=1)\n\ny_train = X_train[\"target\"]\ny_val = X_val[\"target\"]\ny_val_full = X_val[[\"target\", \"variantid1\", \"variantid2\"]]\n\nX_train = X_train.drop([\"target\"], axis=1)\nX_val = X_val.drop([\"target\"], axis=1)\n\n\ntrain_pool = Pool(\n    data=X_train[feats],\n    label=y_train,\n)\neval_pool = Pool(\n    data=X_val[feats],\n    label=y_val,\n)","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:29:01.923278Z","start_time":"2023-05-19T06:28:54.101554Z"},"execution":{"iopub.status.busy":"2023-05-30T19:50:20.956183Z","iopub.execute_input":"2023-05-30T19:50:20.956774Z","iopub.status.idle":"2023-05-30T19:50:25.911102Z","shell.execute_reply.started":"2023-05-30T19:50:20.956742Z","shell.execute_reply":"2023-05-30T19:50:25.910139Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Train model","metadata":{}},{"cell_type":"code","source":"models_path = \"models\"\nif not os.path.exists(models_path):\n   os.makedirs(models_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:50:31.178238Z","iopub.execute_input":"2023-05-30T19:50:31.178845Z","iopub.status.idle":"2023-05-30T19:50:31.183761Z","shell.execute_reply.started":"2023-05-30T19:50:31.178813Z","shell.execute_reply":"2023-05-30T19:50:31.182872Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model = CatBoostClassifier()\n\nmodel.fit(\n    train_pool,\n    eval_set=eval_pool,\n    plot=True,\n    verbose=True,\n    use_best_model=True,\n    early_stopping_rounds=50,\n    metric_period=100\n)\nmodel.save_model(f\"./models/baseline.cbm\")","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:29:24.898318Z","start_time":"2023-05-19T06:29:07.544816Z"},"scrolled":true,"execution":{"iopub.status.busy":"2023-05-30T19:50:31.984257Z","iopub.execute_input":"2023-05-30T19:50:31.984627Z","iopub.status.idle":"2023-05-30T19:51:26.827019Z","shell.execute_reply.started":"2023-05-30T19:50:31.984598Z","shell.execute_reply":"2023-05-30T19:51:26.825961Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beaa00479e8340f28c6c1d56bae3e1ef"}},"metadata":{}},{"name":"stdout","text":"Learning rate set to 0.123728\n0:\tlearn: 0.6593535\ttest: 0.6591851\tbest: 0.6591851 (0)\ttotal: 113ms\tremaining: 1m 52s\n","output_type":"stream"},{"name":"stderr","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","output_type":"stream"},{"name":"stdout","text":"100:\tlearn: 0.5117145\ttest: 0.5096240\tbest: 0.5096240 (100)\ttotal: 5.21s\tremaining: 46.4s\n200:\tlearn: 0.4991001\ttest: 0.4988637\tbest: 0.4988637 (200)\ttotal: 11.2s\tremaining: 44.6s\n300:\tlearn: 0.4918438\ttest: 0.4941857\tbest: 0.4941857 (300)\ttotal: 16.5s\tremaining: 38.2s\n400:\tlearn: 0.4863824\ttest: 0.4912924\tbest: 0.4912924 (400)\ttotal: 21.6s\tremaining: 32.3s\n500:\tlearn: 0.4818511\ttest: 0.4895245\tbest: 0.4895245 (500)\ttotal: 26.8s\tremaining: 26.7s\n600:\tlearn: 0.4779338\ttest: 0.4882246\tbest: 0.4882246 (600)\ttotal: 31.9s\tremaining: 21.2s\n700:\tlearn: 0.4743256\ttest: 0.4872197\tbest: 0.4871879 (699)\ttotal: 37.1s\tremaining: 15.8s\n800:\tlearn: 0.4711851\ttest: 0.4863294\tbest: 0.4863294 (800)\ttotal: 44.2s\tremaining: 11s\n900:\tlearn: 0.4682064\ttest: 0.4858485\tbest: 0.4858206 (888)\ttotal: 49.4s\tremaining: 5.43s\n999:\tlearn: 0.4653841\ttest: 0.4853224\tbest: 0.4853224 (999)\ttotal: 54.4s\tremaining: 0us\n\nbestTest = 0.4853223726\nbestIteration = 999\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model2 = CatBoostClassifier()\n\nmodel2.fit(\n    train_pool,\n    eval_set=eval_pool,\n    plot=True,\n    verbose=True,\n    use_best_model=True,\n    early_stopping_rounds=50,\n    metric_period=100\n)\nmodel2.save_model(f\"./models/baseline2.cbm\")","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:07:37.220431Z","iopub.execute_input":"2023-05-30T20:07:37.220704Z","iopub.status.idle":"2023-05-30T20:08:30.683401Z","shell.execute_reply.started":"2023-05-30T20:07:37.220680Z","shell.execute_reply":"2023-05-30T20:08:30.682331Z"},"trusted":true},"execution_count":101,"outputs":[{"output_type":"display_data","data":{"text/plain":"MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f92d947ad5bd4111b11dc598acc7717a"}},"metadata":{}},{"name":"stdout","text":"Learning rate set to 0.123728\n0:\tlearn: 0.6593535\ttest: 0.6591851\tbest: 0.6591851 (0)\ttotal: 55.7ms\tremaining: 55.7s\n","output_type":"stream"},{"name":"stderr","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","output_type":"stream"},{"name":"stdout","text":"100:\tlearn: 0.5117145\ttest: 0.5096240\tbest: 0.5096240 (100)\ttotal: 5.22s\tremaining: 46.4s\n200:\tlearn: 0.4991001\ttest: 0.4988637\tbest: 0.4988637 (200)\ttotal: 10.3s\tremaining: 40.9s\n300:\tlearn: 0.4918438\ttest: 0.4941857\tbest: 0.4941857 (300)\ttotal: 15.6s\tremaining: 36.2s\n400:\tlearn: 0.4863824\ttest: 0.4912924\tbest: 0.4912924 (400)\ttotal: 21.7s\tremaining: 32.4s\n500:\tlearn: 0.4818511\ttest: 0.4895245\tbest: 0.4895245 (500)\ttotal: 26.8s\tremaining: 26.7s\n600:\tlearn: 0.4779338\ttest: 0.4882246\tbest: 0.4882246 (600)\ttotal: 31.9s\tremaining: 21.2s\n700:\tlearn: 0.4743256\ttest: 0.4872197\tbest: 0.4871879 (699)\ttotal: 37s\tremaining: 15.8s\n800:\tlearn: 0.4711851\ttest: 0.4863294\tbest: 0.4863294 (800)\ttotal: 42s\tremaining: 10.4s\n900:\tlearn: 0.4682064\ttest: 0.4858485\tbest: 0.4858206 (888)\ttotal: 47.1s\tremaining: 5.18s\n999:\tlearn: 0.4653841\ttest: 0.4853224\tbest: 0.4853224 (999)\ttotal: 53.1s\tremaining: 0us\n\nbestTest = 0.4853223726\nbestIteration = 999\n\n","output_type":"stream"}]},{"cell_type":"code","source":"class DistDataset(Dataset):\n    def __init__(self, feats_df: pd.DataFrame, target_df: pd.DataFrame, target_name: str = \"target\"):\n        \"\"\"\n        Args:\n            dist_df: dataframe that contains only columns representing\n            distances between properties of a product pair and 'target' column\n            that equals 1 if the pair is same product, otherwise 0\n        \"\"\"\n        features_as_cols = [feats_df[key] for key in feats_df]\n        self.features = list(zip(*features_as_cols))\n        self.labels = list(target_df)\n    def __len__(self):\n        return len(self.features)\n    def __getitem__(self, idx):\n        inp = torch.tensor(self.features[idx])\n        label = self.labels[idx]\n        return inp, label","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:26.831606Z","iopub.execute_input":"2023-05-30T19:51:26.832273Z","iopub.status.idle":"2023-05-30T19:51:26.840149Z","shell.execute_reply.started":"2023-05-30T19:51:26.832239Z","shell.execute_reply":"2023-05-30T19:51:26.839320Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# DistDataset with numpy backend\n\n# class DistDatasetNp(Dataset):\n#     def __init__(self, dist_df: pd.DataFrame, target_name: str = \"target\"):\n#         \"\"\"\n#         Args:\n#             dist_df: dataframe that contains only columns representing\n#             distances between properties of a product pair and 'target' column\n#             that equals 1 if the pair is same product, otherwise 0\n#         \"\"\"\n#         self.features = dist_df.drop('target', axis = 1).to_numpy().T\n#         self.labels = dist_df['target'].to_numpy()\n#     def __len__(self):\n#         return len(self.features.T)\n#     def __getitem__(self, idx):\n#         inp = torch.tensor(self.features[idx])\n#         label = self.labels[idx]\n#         return inp, label","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:26.842675Z","iopub.execute_input":"2023-05-30T19:51:26.843073Z","iopub.status.idle":"2023-05-30T19:51:26.855823Z","shell.execute_reply.started":"2023-05-30T19:51:26.843042Z","shell.execute_reply":"2023-05-30T19:51:26.854907Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# class DistDataset(DistDatasetZip):\n#     pass","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:26.856992Z","iopub.execute_input":"2023-05-30T19:51:26.858556Z","iopub.status.idle":"2023-05-30T19:51:26.869600Z","shell.execute_reply.started":"2023-05-30T19:51:26.858523Z","shell.execute_reply":"2023-05-30T19:51:26.868651Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"dist_feats = [\n    \"pic_dist_0_perc\", \"pic_dist_25_perc\", \"pic_dist_50_perc\", \n    'euclidean_name_bert_dist', 'cosine_name_bert_dist',\n#     'numerical_intersection_percent', 'eugene_bert_embedding1', \"eugene_bert_embedding2\",\n    'main_cos_dist', 'main_evc_dist']","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:26.871048Z","iopub.execute_input":"2023-05-30T19:51:26.871472Z","iopub.status.idle":"2023-05-30T19:51:26.881373Z","shell.execute_reply.started":"2023-05-30T19:51:26.871440Z","shell.execute_reply":"2023-05-30T19:51:26.880443Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"train_dataset = DistDataset(X_train[dist_feats], y_train)\nval_dataset = DistDataset(X_val[dist_feats], y_val)\ntest_dataset = DistDataset(X_test[dist_feats], y_test['target'])\ntrain_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=100, shuffle=False, drop_last=False)\ndataloaders = {'train':train_dataloader, 'val':val_dataloader}","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:26.882160Z","iopub.execute_input":"2023-05-30T19:51:26.882430Z","iopub.status.idle":"2023-05-30T19:51:27.304985Z","shell.execute_reply.started":"2023-05-30T19:51:26.882405Z","shell.execute_reply":"2023-05-30T19:51:27.304031Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"X_train[dist_feats]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:27.309225Z","iopub.execute_input":"2023-05-30T19:51:27.309962Z","iopub.status.idle":"2023-05-30T19:51:27.332823Z","shell.execute_reply.started":"2023-05-30T19:51:27.309924Z","shell.execute_reply":"2023-05-30T19:51:27.331989Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"        pic_dist_0_perc  pic_dist_25_perc  pic_dist_50_perc  \\\n68341         -1.000000         -1.000000         -1.000000   \n187573         0.000000          3.834663          5.543013   \n157454        -1.000000         -1.000000         -1.000000   \n16957         -1.000000         -1.000000         -1.000000   \n270799        -1.000000         -1.000000         -1.000000   \n...                 ...               ...               ...   \n171008         1.210842          3.224904          5.484363   \n113352         0.000000          0.000000          3.391108   \n238878         3.909940          5.001962          5.394721   \n186693         0.000000          4.009521          5.659083   \n257849        -1.000000         -1.000000         -1.000000   \n\n        euclidean_name_bert_dist  cosine_name_bert_dist  main_cos_dist  \\\n68341                   0.412746               0.004632       0.039550   \n187573                  0.377481               0.003956       0.000000   \n157454                  0.591899               0.010588       0.029861   \n16957                   0.408357               0.004789       0.034551   \n270799                  0.479424               0.006767       0.000000   \n...                          ...                    ...            ...   \n171008                  0.000000               0.000000       0.080943   \n113352                  0.437821               0.005302       0.000000   \n238878                  0.344957               0.003759       0.236717   \n186693                  0.238374               0.001682       0.000000   \n257849                  0.401892               0.004397       0.029037   \n\n        main_evc_dist  \n68341        1.868696  \n187573       0.000000  \n157454       1.794320  \n16957        1.712504  \n270799       0.000000  \n...               ...  \n171008       2.080464  \n113352       0.000000  \n238878       3.875215  \n186693       0.000000  \n257849       1.571943  \n\n[248297 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pic_dist_0_perc</th>\n      <th>pic_dist_25_perc</th>\n      <th>pic_dist_50_perc</th>\n      <th>euclidean_name_bert_dist</th>\n      <th>cosine_name_bert_dist</th>\n      <th>main_cos_dist</th>\n      <th>main_evc_dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>68341</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.412746</td>\n      <td>0.004632</td>\n      <td>0.039550</td>\n      <td>1.868696</td>\n    </tr>\n    <tr>\n      <th>187573</th>\n      <td>0.000000</td>\n      <td>3.834663</td>\n      <td>5.543013</td>\n      <td>0.377481</td>\n      <td>0.003956</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>157454</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.591899</td>\n      <td>0.010588</td>\n      <td>0.029861</td>\n      <td>1.794320</td>\n    </tr>\n    <tr>\n      <th>16957</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.408357</td>\n      <td>0.004789</td>\n      <td>0.034551</td>\n      <td>1.712504</td>\n    </tr>\n    <tr>\n      <th>270799</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.479424</td>\n      <td>0.006767</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>171008</th>\n      <td>1.210842</td>\n      <td>3.224904</td>\n      <td>5.484363</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.080943</td>\n      <td>2.080464</td>\n    </tr>\n    <tr>\n      <th>113352</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.391108</td>\n      <td>0.437821</td>\n      <td>0.005302</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>238878</th>\n      <td>3.909940</td>\n      <td>5.001962</td>\n      <td>5.394721</td>\n      <td>0.344957</td>\n      <td>0.003759</td>\n      <td>0.236717</td>\n      <td>3.875215</td>\n    </tr>\n    <tr>\n      <th>186693</th>\n      <td>0.000000</td>\n      <td>4.009521</td>\n      <td>5.659083</td>\n      <td>0.238374</td>\n      <td>0.001682</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>257849</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.401892</td>\n      <td>0.004397</td>\n      <td>0.029037</td>\n      <td>1.571943</td>\n    </tr>\n  </tbody>\n</table>\n<p>248297 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# from sklearn import preprocessing\n# x = dist_df.values #returns a numpy array\n# min_max_scaler = preprocessing.MinMaxScaler()\n# x_scaled = min_max_scaler.fit_transform(x)\n# norm_dist_df = pd.DataFrame(x_scaled)\n# norm_dist_df","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:27.335163Z","iopub.execute_input":"2023-05-30T19:51:27.335755Z","iopub.status.idle":"2023-05-30T19:51:27.341145Z","shell.execute_reply.started":"2023-05-30T19:51:27.335721Z","shell.execute_reply":"2023-05-30T19:51:27.338655Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# from sklearn.linear_model import LogisticRegression\n# from sklearn.metrics import classification_report, confusion_matrix\n# model = LogisticRegression(solver='liblinear', random_state=0)\n# model = model.fit(X_train[dist_feats], y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:27.342611Z","iopub.execute_input":"2023-05-30T19:51:27.343179Z","iopub.status.idle":"2023-05-30T19:51:27.351603Z","shell.execute_reply.started":"2023-05-30T19:51:27.343147Z","shell.execute_reply":"2023-05-30T19:51:27.350589Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# y_pred = model.predict(X_val[dist_feats])\n# print(classification_report(y_pred, y_val))","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:27.354617Z","iopub.execute_input":"2023-05-30T19:51:27.354865Z","iopub.status.idle":"2023-05-30T19:51:27.363437Z","shell.execute_reply.started":"2023-05-30T19:51:27.354844Z","shell.execute_reply":"2023-05-30T19:51:27.362534Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# from sklearn import preprocessing\n# x = X_train[dist_feats].values #returns a numpy array\n# min_max_scaler = preprocessing.MinMaxScaler()\n# x_scaled = min_max_scaler.fit_transform(x)\n# norm_dist_X_train = pd.DataFrame(x_scaled)\n\n# x = X_val[dist_feats].values #returns a numpy array\n# min_max_scaler = preprocessing.MinMaxScaler()\n# x_scaled = min_max_scaler.fit_transform(x)\n# norm_dist_X_test = pd.DataFrame(x_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:27.365116Z","iopub.execute_input":"2023-05-30T19:51:27.365528Z","iopub.status.idle":"2023-05-30T19:51:27.377820Z","shell.execute_reply.started":"2023-05-30T19:51:27.365497Z","shell.execute_reply":"2023-05-30T19:51:27.376830Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# from sklearn.linear_model import LogisticRegression\n# from sklearn.metrics import classification_report, confusion_matrix\n# model = LogisticRegression(solver='liblinear', random_state=0)\n# model = model.fit(norm_dist_X_train, y_train)\n# y_pred = model.predict(norm_dist_X_test)\n# print(classification_report(y_pred, y_val))","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:27.379684Z","iopub.execute_input":"2023-05-30T19:51:27.380105Z","iopub.status.idle":"2023-05-30T19:51:27.388894Z","shell.execute_reply.started":"2023-05-30T19:51:27.380073Z","shell.execute_reply":"2023-05-30T19:51:27.387833Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class Mega_model(nn.Module):\n    def __init__(self, in_feats):\n        super(Mega_model, self).__init__()\n        self.fc1 = nn.Linear(in_features=in_feats, out_features=in_feats)\n        self.act1 = nn.ReLU()\n        self.fc2 = nn.Linear(in_features=in_feats, out_features=in_feats)\n        self.act2 = nn.ReLU()\n        self.fc3 = nn.Linear(in_features=in_feats, out_features=2)\n        self.Softmax = nn.Softmax(dim=1)\n    def forward(self, input_feat):\n        x = self.fc1(input_feat)\n        x = self.act1(x)\n        x = self.fc2(x)\n        x = self.act2(x)\n        x = self.fc3(x)\n        out = self.Softmax(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:51:27.390308Z","iopub.execute_input":"2023-05-30T19:51:27.391002Z","iopub.status.idle":"2023-05-30T19:51:27.402053Z","shell.execute_reply.started":"2023-05-30T19:51:27.390970Z","shell.execute_reply":"2023-05-30T19:51:27.401137Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score\nepox_num = 20\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nnet_model = Mega_model(len(dist_feats)).to(device)\n\nepox_list = [i for i in range(epox_num)]\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(net_model.parameters(), lr=3e-3)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:54:15.287016Z","iopub.execute_input":"2023-05-30T19:54:15.287425Z","iopub.status.idle":"2023-05-30T19:54:15.295565Z","shell.execute_reply.started":"2023-05-30T19:54:15.287390Z","shell.execute_reply":"2023-05-30T19:54:15.294660Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, num_epochs, dataset):\n    loss_list = {phase : [] for phase in dataset.keys()}\n    acc_list = {phase : [] for phase in dataset.keys()}\n    f1_list = {phase : [] for phase in dataset.keys()}\n    for epoch in range(num_epochs):\n        pred_list = []\n        target = []\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n        for phase in dataset:\n            if phase == 'val':\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0\n            for feats, labels in tqdm(dataset[phase]):\n                feats = feats.to(device)\n                #print(feats)\n                labels = labels.to(device)\n                #labels = labels.float()\n                pred = model(feats)\n                \n                prob, pred_labels = torch.max(pred, 1)\n                #print(pred_labels)\n                pred_list.extend(pred_labels.tolist())\n                target.extend(labels.tolist())\n                loss = criterion(pred, labels.long())\n                if phase == 'train':\n                    optimizer.zero_grad()\n                    loss.backward()\n                    #torch.nn.utils.clip_grad_norm_(model.parameters(), 20)\n                    #model.float()\n                    optimizer.step()\n                running_loss += loss.item()# * inputs.size(0)\n            epoch_loss = running_loss / len(dataset[phase])\n            epoch_acc = accuracy_score(target, pred_list)\n            epoch_f1 = f1_score(target, pred_list, average='micro')\n            print('{} loss: {:.4f}, acc: {:.4f}, rec_1: {:.4f}'.format(phase,\n                                                        epoch_loss,\n                                                        epoch_acc, \n                                                        epoch_f1\n                                                        ))\n            loss_list[phase].append(epoch_loss)\n            acc_list[phase].append(epoch_acc)\n            f1_list[phase].append(epoch_f1)\n    return loss_list, acc_list, f1_list","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:54:15.471672Z","iopub.execute_input":"2023-05-30T19:54:15.472560Z","iopub.status.idle":"2023-05-30T19:54:15.484154Z","shell.execute_reply.started":"2023-05-30T19:54:15.472522Z","shell.execute_reply":"2023-05-30T19:54:15.483234Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"def graf(loss, acc, rec):\n    fig, ax = plt.subplots(2, 3, figsize=(26, 13))\n    ax[0, 0].plot(epox_list, loss['train'])\n    ax[0, 0].set_title(\"Изменение потерь на обучающей выборке\")\n    ax[0, 1].plot(epox_list, acc['train'])\n    ax[0, 1].set_title(\"Изменение точности на обучающей выборке\")\n    ax[0, 2].plot(epox_list, rec['train'])\n    ax[0, 2].set_title(\"Изменение f1 на обучающей выборке\")\n    ax[1, 0].plot(epox_list, loss['val'])\n    ax[1, 0].set_title(\"Изменение потерь на валидационной выборке\")\n    ax[1, 1].plot(epox_list, acc['val'])\n    ax[1, 1].set_title(\"Изменение точности на валидационной выборке\")\n    ax[1, 2].plot(epox_list, rec['val'])\n    ax[1, 2].set_title(\"Изменение f1 на валидационной выборке\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:54:16.913261Z","iopub.execute_input":"2023-05-30T19:54:16.914212Z","iopub.status.idle":"2023-05-30T19:54:16.923188Z","shell.execute_reply.started":"2023-05-30T19:54:16.914171Z","shell.execute_reply":"2023-05-30T19:54:16.922125Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"loss, acc, rec_1 = train_model(net_model, criterion, optimizer, epox_num, dataloaders)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:05:10.846920Z","iopub.execute_input":"2023-05-30T20:05:10.847329Z","iopub.status.idle":"2023-05-30T20:07:37.218568Z","shell.execute_reply.started":"2023-05-30T20:05:10.847275Z","shell.execute_reply":"2023-05-30T20:07:37.217520Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"Epoch 1/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 451.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 698.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 2/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 432.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 701.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 3/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 451.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 704.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 4/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 430.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 697.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 5/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 460.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 708.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 6/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:06<00:00, 410.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 442.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 7/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 425.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 691.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 8/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 464.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 686.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 9/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 455.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 700.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 10/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 433.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 709.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 11/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 458.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 687.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 12/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 454.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 702.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 13/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 456.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 704.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 14/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 465.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 681.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 15/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:06<00:00, 385.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 696.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 16/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 440.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 694.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 17/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 462.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 676.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 18/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 447.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 685.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 19/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:06<00:00, 413.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 655.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\nEpoch 20/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2483/2483 [00:05<00:00, 460.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6132, acc: 0.6698, rec_1: 0.6698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [00:00<00:00, 699.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.6111, acc: 0.6702, rec_1: 0.6702\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nclass SiameseNetwork(nn.Module):\n    \"\"\"\n        Siamese network  based on offcial pytorch example: https://github.com/pytorch/examples/blob/main/siamese_network/main.py\n        Siamese network for image similarity estimation.\n        The network is composed of two identical networks, one for each input.\n        The output of each network is concatenated and passed to a linear layer. \n        The output of the linear layer passed through a sigmoid function.\n        `\"FaceNet\" <https://arxiv.org/pdf/1503.03832.pdf>`_ is a variant of the Siamese network.\n        This implementation varies from FaceNet as we use the `ResNet-18` model from\n        `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_ as our feature extractor.\n        In addition, we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n    \"\"\"\n    def __init__(self, in_features):\n        super(SiameseNetwork, self).__init__()\n        \n        self.feature_extractor = torch.nn.Sequential(\n            nn.Linear(in_features=in_features, out_features=in_features),\n            nn.Sigmoid(),\n            nn.Linear(in_features=in_features, out_features=in_features),\n            nn.ReLU(),\n            nn.Linear(in_features=in_features, out_features=in_features)\n        )\n\n        # add linear layers to compare between the features of the two images\n        self.fc = nn.Sequential(\n            nn.Linear(in_features * 2, 256),\n            nn.ReLU(inplace=True),\n            nn.Linear(256, 1),\n        )\n\n        self.sigmoid = nn.Sigmoid()\n\n        # initialize the weights\n        self.feature_extractor.apply(self.init_weights)\n        self.fc.apply(self.init_weights)\n        \n    def init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            torch.nn.init.xavier_uniform_(m.weight)\n            m.bias.data.fill_(0.01)\n\n    def forward_once(self, x):\n        output = self.feature_extractor(x)\n        output = output.view(output.size()[0], -1)\n        return output\n\n    def forward(self, input1, input2):\n        # get two images' features\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n\n        # concatenate both images' features\n        output = torch.cat((output1, output2), 1)\n\n        # pass the concatenation to the linear layers\n        output = self.fc(output)\n\n        # pass the out of the linear layers to sigmoid layer\n        output = self.sigmoid(output)\n        \n        return output\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:57:05.618724Z","iopub.execute_input":"2023-05-30T19:57:05.619213Z","iopub.status.idle":"2023-05-30T19:57:05.630720Z","shell.execute_reply.started":"2023-05-30T19:57:05.619172Z","shell.execute_reply":"2023-05-30T19:57:05.629560Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"resnet_emb_dim = 128 \nsiam_imgs_net = SiameseNetwork(in_features = resnet_emb_dim)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:57:05.631985Z","iopub.execute_input":"2023-05-30T19:57:05.634518Z","iopub.status.idle":"2023-05-30T19:57:05.653667Z","shell.execute_reply.started":"2023-05-30T19:57:05.634484Z","shell.execute_reply":"2023-05-30T19:57:05.652767Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"class SiamiseMainImgDataset(Dataset):\n    def __init__(self, imgs_1: pd.Series,\n                 imgs_2: pd.Series, target_df: pd.Series):\n        self.imgs_1 = list(imgs_1)\n        self.imgs_2 = list(imgs_2)\n        self.labels = list(target_df)\n    def __len__(self):\n        return len(self.imgs_1)\n    def __getitem__(self, idx):\n        img1 = torch.from_numpy(self.imgs_1[idx][0]).to(torch.float32)\n        img2 = torch.from_numpy(self.imgs_2[idx][0]).to(torch.float32)\n        label = torch.tensor(self.labels[idx], dtype = torch.float32)\n        return img1, img2, label","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:57:05.656704Z","iopub.execute_input":"2023-05-30T19:57:05.657123Z","iopub.status.idle":"2023-05-30T19:57:05.665362Z","shell.execute_reply.started":"2023-05-30T19:57:05.657091Z","shell.execute_reply":"2023-05-30T19:57:05.663355Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"siam_train_dataset = SiamiseMainImgDataset(\n    X_train['main_pic_embeddings_resnet_v11'],\n    X_train['main_pic_embeddings_resnet_v12'],\n    y_train)\n\n# pin_memory = True, num_workers = 1\n\nsiam_train_loader = DataLoader(siam_train_dataset, batch_size=100, shuffle=True, drop_last=True)\n\nsiam_val_dataset = SiamiseMainImgDataset(\n    X_val['main_pic_embeddings_resnet_v11'],\n    X_val['main_pic_embeddings_resnet_v12'],\n    y_val)\n\nsiam_val_loader = DataLoader(siam_val_dataset, batch_size=100, shuffle=False, drop_last=False)\n\nsiam_test_dataset = SiamiseMainImgDataset(\n    X_test['main_pic_embeddings_resnet_v11'],\n    X_test['main_pic_embeddings_resnet_v12'],\n    y_test['target'])\n\nsiam_test_loader = DataLoader(siam_test_dataset, batch_size=100, shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:57:05.666550Z","iopub.execute_input":"2023-05-30T19:57:05.667318Z","iopub.status.idle":"2023-05-30T19:57:05.849235Z","shell.execute_reply.started":"2023-05-30T19:57:05.667259Z","shell.execute_reply":"2023-05-30T19:57:05.848318Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"def train(model, device, train_loader, optimizer, epoch, log_interval = 10, dry_run = False):\n    model.train()\n\n    # we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n    criterion = nn.BCELoss()\n\n    for batch_idx, (images_1, images_2, targets) in enumerate(train_loader):\n        images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(images_1, images_2).squeeze()\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(images_1), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n            if dry_run:\n                break","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:57:05.850784Z","iopub.execute_input":"2023-05-30T19:57:05.851130Z","iopub.status.idle":"2023-05-30T19:57:05.859768Z","shell.execute_reply.started":"2023-05-30T19:57:05.851097Z","shell.execute_reply":"2023-05-30T19:57:05.857864Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"def test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    # we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n    criterion = nn.BCELoss()\n\n    with torch.no_grad():\n        for (images_1, images_2, targets) in test_loader:\n            images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n            outputs = model(images_1, images_2).squeeze()\n            test_loss += criterion(outputs, targets).sum().item()  # sum up batch loss\n            pred = torch.where(outputs > 0.5, 1, 0)  # get the index of the max log-probability\n            correct += pred.eq(targets.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    # for the 1st epoch, the average loss is 0.0001 and the accuracy 97-98%\n    # using default settings. After completing the 10th epoch, the average\n    # loss is 0.0000 and the accuracy 99.5-100% using default settings.\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:57:05.861021Z","iopub.execute_input":"2023-05-30T19:57:05.861668Z","iopub.status.idle":"2023-05-30T19:57:05.873896Z","shell.execute_reply.started":"2023-05-30T19:57:05.861614Z","shell.execute_reply":"2023-05-30T19:57:05.872968Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\n\nepochs = 20\ngamma = 0.7\nlr = 1.0\n\ntorch.manual_seed(42)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nsiam_imgs_net = SiameseNetwork(in_features = resnet_emb_dim).to(device)\noptimizer = torch.optim.Adadelta(siam_imgs_net.parameters(), lr=lr)\n\nscheduler = StepLR(optimizer, step_size=1, gamma=gamma)\nfor epoch in range(1, epochs + 1):\n    train(siam_imgs_net, device, siam_train_loader, optimizer, epoch)\n    test(siam_imgs_net, device, siam_val_loader)\n    scheduler.step()\n\n# torch.save(model.state_dict(), \"siamese_network.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-05-30T19:57:05.876879Z","iopub.execute_input":"2023-05-30T19:57:05.877165Z","iopub.status.idle":"2023-05-30T20:00:33.526374Z","shell.execute_reply.started":"2023-05-30T19:57:05.877142Z","shell.execute_reply":"2023-05-30T20:00:33.525294Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Train Epoch: 1 [0/248297 (0%)]\tLoss: 0.677542\nTrain Epoch: 1 [1000/248297 (0%)]\tLoss: 0.643311\nTrain Epoch: 1 [2000/248297 (1%)]\tLoss: 0.681578\nTrain Epoch: 1 [3000/248297 (1%)]\tLoss: 0.748915\nTrain Epoch: 1 [4000/248297 (2%)]\tLoss: 0.777538\nTrain Epoch: 1 [5000/248297 (2%)]\tLoss: 0.599296\nTrain Epoch: 1 [6000/248297 (2%)]\tLoss: 0.691895\nTrain Epoch: 1 [7000/248297 (3%)]\tLoss: 0.604207\nTrain Epoch: 1 [8000/248297 (3%)]\tLoss: 0.581355\nTrain Epoch: 1 [9000/248297 (4%)]\tLoss: 0.600705\nTrain Epoch: 1 [10000/248297 (4%)]\tLoss: 0.644513\nTrain Epoch: 1 [11000/248297 (4%)]\tLoss: 0.627105\nTrain Epoch: 1 [12000/248297 (5%)]\tLoss: 0.605341\nTrain Epoch: 1 [13000/248297 (5%)]\tLoss: 0.603105\nTrain Epoch: 1 [14000/248297 (6%)]\tLoss: 0.597417\nTrain Epoch: 1 [15000/248297 (6%)]\tLoss: 0.504411\nTrain Epoch: 1 [16000/248297 (6%)]\tLoss: 0.593642\nTrain Epoch: 1 [17000/248297 (7%)]\tLoss: 0.641106\nTrain Epoch: 1 [18000/248297 (7%)]\tLoss: 0.648502\nTrain Epoch: 1 [19000/248297 (8%)]\tLoss: 0.559820\nTrain Epoch: 1 [20000/248297 (8%)]\tLoss: 0.590258\nTrain Epoch: 1 [21000/248297 (8%)]\tLoss: 0.728949\nTrain Epoch: 1 [22000/248297 (9%)]\tLoss: 0.615703\nTrain Epoch: 1 [23000/248297 (9%)]\tLoss: 0.551840\nTrain Epoch: 1 [24000/248297 (10%)]\tLoss: 0.571513\nTrain Epoch: 1 [25000/248297 (10%)]\tLoss: 0.543728\nTrain Epoch: 1 [26000/248297 (10%)]\tLoss: 0.566240\nTrain Epoch: 1 [27000/248297 (11%)]\tLoss: 0.645668\nTrain Epoch: 1 [28000/248297 (11%)]\tLoss: 0.572971\nTrain Epoch: 1 [29000/248297 (12%)]\tLoss: 0.631719\nTrain Epoch: 1 [30000/248297 (12%)]\tLoss: 0.616601\nTrain Epoch: 1 [31000/248297 (12%)]\tLoss: 0.557414\nTrain Epoch: 1 [32000/248297 (13%)]\tLoss: 0.599182\nTrain Epoch: 1 [33000/248297 (13%)]\tLoss: 0.546535\nTrain Epoch: 1 [34000/248297 (14%)]\tLoss: 0.540860\nTrain Epoch: 1 [35000/248297 (14%)]\tLoss: 0.573441\nTrain Epoch: 1 [36000/248297 (15%)]\tLoss: 0.557041\nTrain Epoch: 1 [37000/248297 (15%)]\tLoss: 0.550480\nTrain Epoch: 1 [38000/248297 (15%)]\tLoss: 0.668187\nTrain Epoch: 1 [39000/248297 (16%)]\tLoss: 0.661548\nTrain Epoch: 1 [40000/248297 (16%)]\tLoss: 0.628764\nTrain Epoch: 1 [41000/248297 (17%)]\tLoss: 0.563647\nTrain Epoch: 1 [42000/248297 (17%)]\tLoss: 0.547793\nTrain Epoch: 1 [43000/248297 (17%)]\tLoss: 0.592563\nTrain Epoch: 1 [44000/248297 (18%)]\tLoss: 0.635151\nTrain Epoch: 1 [45000/248297 (18%)]\tLoss: 0.580570\nTrain Epoch: 1 [46000/248297 (19%)]\tLoss: 0.569764\nTrain Epoch: 1 [47000/248297 (19%)]\tLoss: 0.539837\nTrain Epoch: 1 [48000/248297 (19%)]\tLoss: 0.621069\nTrain Epoch: 1 [49000/248297 (20%)]\tLoss: 0.620016\nTrain Epoch: 1 [50000/248297 (20%)]\tLoss: 0.585031\nTrain Epoch: 1 [51000/248297 (21%)]\tLoss: 0.649122\nTrain Epoch: 1 [52000/248297 (21%)]\tLoss: 0.569849\nTrain Epoch: 1 [53000/248297 (21%)]\tLoss: 0.562815\nTrain Epoch: 1 [54000/248297 (22%)]\tLoss: 0.666398\nTrain Epoch: 1 [55000/248297 (22%)]\tLoss: 0.566228\nTrain Epoch: 1 [56000/248297 (23%)]\tLoss: 0.537174\nTrain Epoch: 1 [57000/248297 (23%)]\tLoss: 0.572277\nTrain Epoch: 1 [58000/248297 (23%)]\tLoss: 0.677929\nTrain Epoch: 1 [59000/248297 (24%)]\tLoss: 0.633666\nTrain Epoch: 1 [60000/248297 (24%)]\tLoss: 0.547382\nTrain Epoch: 1 [61000/248297 (25%)]\tLoss: 0.555829\nTrain Epoch: 1 [62000/248297 (25%)]\tLoss: 0.556976\nTrain Epoch: 1 [63000/248297 (25%)]\tLoss: 0.562652\nTrain Epoch: 1 [64000/248297 (26%)]\tLoss: 0.449771\nTrain Epoch: 1 [65000/248297 (26%)]\tLoss: 0.549088\nTrain Epoch: 1 [66000/248297 (27%)]\tLoss: 0.594808\nTrain Epoch: 1 [67000/248297 (27%)]\tLoss: 0.504972\nTrain Epoch: 1 [68000/248297 (27%)]\tLoss: 0.554361\nTrain Epoch: 1 [69000/248297 (28%)]\tLoss: 0.649662\nTrain Epoch: 1 [70000/248297 (28%)]\tLoss: 0.561283\nTrain Epoch: 1 [71000/248297 (29%)]\tLoss: 0.572610\nTrain Epoch: 1 [72000/248297 (29%)]\tLoss: 0.561022\nTrain Epoch: 1 [73000/248297 (29%)]\tLoss: 0.571684\nTrain Epoch: 1 [74000/248297 (30%)]\tLoss: 0.611176\nTrain Epoch: 1 [75000/248297 (30%)]\tLoss: 0.610344\nTrain Epoch: 1 [76000/248297 (31%)]\tLoss: 0.557101\nTrain Epoch: 1 [77000/248297 (31%)]\tLoss: 0.626368\nTrain Epoch: 1 [78000/248297 (31%)]\tLoss: 0.575514\nTrain Epoch: 1 [79000/248297 (32%)]\tLoss: 0.536722\nTrain Epoch: 1 [80000/248297 (32%)]\tLoss: 0.567944\nTrain Epoch: 1 [81000/248297 (33%)]\tLoss: 0.530693\nTrain Epoch: 1 [82000/248297 (33%)]\tLoss: 0.612319\nTrain Epoch: 1 [83000/248297 (33%)]\tLoss: 0.569543\nTrain Epoch: 1 [84000/248297 (34%)]\tLoss: 0.528843\nTrain Epoch: 1 [85000/248297 (34%)]\tLoss: 0.557005\nTrain Epoch: 1 [86000/248297 (35%)]\tLoss: 0.565058\nTrain Epoch: 1 [87000/248297 (35%)]\tLoss: 0.640091\nTrain Epoch: 1 [88000/248297 (35%)]\tLoss: 0.521245\nTrain Epoch: 1 [89000/248297 (36%)]\tLoss: 0.596288\nTrain Epoch: 1 [90000/248297 (36%)]\tLoss: 0.584385\nTrain Epoch: 1 [91000/248297 (37%)]\tLoss: 0.507914\nTrain Epoch: 1 [92000/248297 (37%)]\tLoss: 0.629809\nTrain Epoch: 1 [93000/248297 (37%)]\tLoss: 0.496241\nTrain Epoch: 1 [94000/248297 (38%)]\tLoss: 0.571300\nTrain Epoch: 1 [95000/248297 (38%)]\tLoss: 0.517460\nTrain Epoch: 1 [96000/248297 (39%)]\tLoss: 0.575076\nTrain Epoch: 1 [97000/248297 (39%)]\tLoss: 0.633942\nTrain Epoch: 1 [98000/248297 (39%)]\tLoss: 0.579905\nTrain Epoch: 1 [99000/248297 (40%)]\tLoss: 0.660099\nTrain Epoch: 1 [100000/248297 (40%)]\tLoss: 0.559524\nTrain Epoch: 1 [101000/248297 (41%)]\tLoss: 0.538261\nTrain Epoch: 1 [102000/248297 (41%)]\tLoss: 0.592416\nTrain Epoch: 1 [103000/248297 (41%)]\tLoss: 0.605260\nTrain Epoch: 1 [104000/248297 (42%)]\tLoss: 0.575902\nTrain Epoch: 1 [105000/248297 (42%)]\tLoss: 0.604299\nTrain Epoch: 1 [106000/248297 (43%)]\tLoss: 0.616676\nTrain Epoch: 1 [107000/248297 (43%)]\tLoss: 0.562888\nTrain Epoch: 1 [108000/248297 (44%)]\tLoss: 0.552492\nTrain Epoch: 1 [109000/248297 (44%)]\tLoss: 0.511514\nTrain Epoch: 1 [110000/248297 (44%)]\tLoss: 0.627951\nTrain Epoch: 1 [111000/248297 (45%)]\tLoss: 0.585301\nTrain Epoch: 1 [112000/248297 (45%)]\tLoss: 0.550730\nTrain Epoch: 1 [113000/248297 (46%)]\tLoss: 0.448123\nTrain Epoch: 1 [114000/248297 (46%)]\tLoss: 0.639084\nTrain Epoch: 1 [115000/248297 (46%)]\tLoss: 0.518861\nTrain Epoch: 1 [116000/248297 (47%)]\tLoss: 0.546256\nTrain Epoch: 1 [117000/248297 (47%)]\tLoss: 0.565758\nTrain Epoch: 1 [118000/248297 (48%)]\tLoss: 0.527563\nTrain Epoch: 1 [119000/248297 (48%)]\tLoss: 0.541133\nTrain Epoch: 1 [120000/248297 (48%)]\tLoss: 0.628894\nTrain Epoch: 1 [121000/248297 (49%)]\tLoss: 0.550279\nTrain Epoch: 1 [122000/248297 (49%)]\tLoss: 0.566332\nTrain Epoch: 1 [123000/248297 (50%)]\tLoss: 0.520495\nTrain Epoch: 1 [124000/248297 (50%)]\tLoss: 0.558413\nTrain Epoch: 1 [125000/248297 (50%)]\tLoss: 0.632773\nTrain Epoch: 1 [126000/248297 (51%)]\tLoss: 0.489729\nTrain Epoch: 1 [127000/248297 (51%)]\tLoss: 0.558207\nTrain Epoch: 1 [128000/248297 (52%)]\tLoss: 0.582187\nTrain Epoch: 1 [129000/248297 (52%)]\tLoss: 0.550011\nTrain Epoch: 1 [130000/248297 (52%)]\tLoss: 0.525493\nTrain Epoch: 1 [131000/248297 (53%)]\tLoss: 0.523581\nTrain Epoch: 1 [132000/248297 (53%)]\tLoss: 0.568887\nTrain Epoch: 1 [133000/248297 (54%)]\tLoss: 0.573529\nTrain Epoch: 1 [134000/248297 (54%)]\tLoss: 0.588389\nTrain Epoch: 1 [135000/248297 (54%)]\tLoss: 0.578550\nTrain Epoch: 1 [136000/248297 (55%)]\tLoss: 0.567015\nTrain Epoch: 1 [137000/248297 (55%)]\tLoss: 0.569687\nTrain Epoch: 1 [138000/248297 (56%)]\tLoss: 0.543544\nTrain Epoch: 1 [139000/248297 (56%)]\tLoss: 0.571844\nTrain Epoch: 1 [140000/248297 (56%)]\tLoss: 0.665362\nTrain Epoch: 1 [141000/248297 (57%)]\tLoss: 0.560409\nTrain Epoch: 1 [142000/248297 (57%)]\tLoss: 0.580036\nTrain Epoch: 1 [143000/248297 (58%)]\tLoss: 0.605738\nTrain Epoch: 1 [144000/248297 (58%)]\tLoss: 0.509341\nTrain Epoch: 1 [145000/248297 (58%)]\tLoss: 0.557571\nTrain Epoch: 1 [146000/248297 (59%)]\tLoss: 0.554769\nTrain Epoch: 1 [147000/248297 (59%)]\tLoss: 0.516202\nTrain Epoch: 1 [148000/248297 (60%)]\tLoss: 0.565913\nTrain Epoch: 1 [149000/248297 (60%)]\tLoss: 0.490887\nTrain Epoch: 1 [150000/248297 (60%)]\tLoss: 0.577784\nTrain Epoch: 1 [151000/248297 (61%)]\tLoss: 0.477533\nTrain Epoch: 1 [152000/248297 (61%)]\tLoss: 0.621227\nTrain Epoch: 1 [153000/248297 (62%)]\tLoss: 0.561540\nTrain Epoch: 1 [154000/248297 (62%)]\tLoss: 0.491962\nTrain Epoch: 1 [155000/248297 (62%)]\tLoss: 0.546519\nTrain Epoch: 1 [156000/248297 (63%)]\tLoss: 0.487654\nTrain Epoch: 1 [157000/248297 (63%)]\tLoss: 0.647200\nTrain Epoch: 1 [158000/248297 (64%)]\tLoss: 0.497218\nTrain Epoch: 1 [159000/248297 (64%)]\tLoss: 0.601254\nTrain Epoch: 1 [160000/248297 (64%)]\tLoss: 0.567908\nTrain Epoch: 1 [161000/248297 (65%)]\tLoss: 0.535531\nTrain Epoch: 1 [162000/248297 (65%)]\tLoss: 0.555326\nTrain Epoch: 1 [163000/248297 (66%)]\tLoss: 0.519204\nTrain Epoch: 1 [164000/248297 (66%)]\tLoss: 0.571877\nTrain Epoch: 1 [165000/248297 (66%)]\tLoss: 0.633148\nTrain Epoch: 1 [166000/248297 (67%)]\tLoss: 0.542669\nTrain Epoch: 1 [167000/248297 (67%)]\tLoss: 0.576898\nTrain Epoch: 1 [168000/248297 (68%)]\tLoss: 0.549540\nTrain Epoch: 1 [169000/248297 (68%)]\tLoss: 0.579880\nTrain Epoch: 1 [170000/248297 (68%)]\tLoss: 0.464808\nTrain Epoch: 1 [171000/248297 (69%)]\tLoss: 0.624952\nTrain Epoch: 1 [172000/248297 (69%)]\tLoss: 0.557088\nTrain Epoch: 1 [173000/248297 (70%)]\tLoss: 0.549381\nTrain Epoch: 1 [174000/248297 (70%)]\tLoss: 0.485811\nTrain Epoch: 1 [175000/248297 (71%)]\tLoss: 0.532554\nTrain Epoch: 1 [176000/248297 (71%)]\tLoss: 0.581930\nTrain Epoch: 1 [177000/248297 (71%)]\tLoss: 0.566952\nTrain Epoch: 1 [178000/248297 (72%)]\tLoss: 0.593238\nTrain Epoch: 1 [179000/248297 (72%)]\tLoss: 0.581319\nTrain Epoch: 1 [180000/248297 (73%)]\tLoss: 0.645005\nTrain Epoch: 1 [181000/248297 (73%)]\tLoss: 0.556860\nTrain Epoch: 1 [182000/248297 (73%)]\tLoss: 0.556258\nTrain Epoch: 1 [183000/248297 (74%)]\tLoss: 0.566821\nTrain Epoch: 1 [184000/248297 (74%)]\tLoss: 0.562236\nTrain Epoch: 1 [185000/248297 (75%)]\tLoss: 0.564719\nTrain Epoch: 1 [186000/248297 (75%)]\tLoss: 0.509330\nTrain Epoch: 1 [187000/248297 (75%)]\tLoss: 0.573578\nTrain Epoch: 1 [188000/248297 (76%)]\tLoss: 0.602454\nTrain Epoch: 1 [189000/248297 (76%)]\tLoss: 0.574957\nTrain Epoch: 1 [190000/248297 (77%)]\tLoss: 0.557999\nTrain Epoch: 1 [191000/248297 (77%)]\tLoss: 0.587030\nTrain Epoch: 1 [192000/248297 (77%)]\tLoss: 0.512851\nTrain Epoch: 1 [193000/248297 (78%)]\tLoss: 0.516180\nTrain Epoch: 1 [194000/248297 (78%)]\tLoss: 0.477477\nTrain Epoch: 1 [195000/248297 (79%)]\tLoss: 0.628990\nTrain Epoch: 1 [196000/248297 (79%)]\tLoss: 0.539101\nTrain Epoch: 1 [197000/248297 (79%)]\tLoss: 0.606985\nTrain Epoch: 1 [198000/248297 (80%)]\tLoss: 0.625556\nTrain Epoch: 1 [199000/248297 (80%)]\tLoss: 0.531422\nTrain Epoch: 1 [200000/248297 (81%)]\tLoss: 0.681452\nTrain Epoch: 1 [201000/248297 (81%)]\tLoss: 0.518642\nTrain Epoch: 1 [202000/248297 (81%)]\tLoss: 0.602248\nTrain Epoch: 1 [203000/248297 (82%)]\tLoss: 0.592468\nTrain Epoch: 1 [204000/248297 (82%)]\tLoss: 0.532669\nTrain Epoch: 1 [205000/248297 (83%)]\tLoss: 0.572547\nTrain Epoch: 1 [206000/248297 (83%)]\tLoss: 0.550254\nTrain Epoch: 1 [207000/248297 (83%)]\tLoss: 0.609085\nTrain Epoch: 1 [208000/248297 (84%)]\tLoss: 0.589281\nTrain Epoch: 1 [209000/248297 (84%)]\tLoss: 0.579940\nTrain Epoch: 1 [210000/248297 (85%)]\tLoss: 0.535160\nTrain Epoch: 1 [211000/248297 (85%)]\tLoss: 0.607162\nTrain Epoch: 1 [212000/248297 (85%)]\tLoss: 0.656973\nTrain Epoch: 1 [213000/248297 (86%)]\tLoss: 0.574501\nTrain Epoch: 1 [214000/248297 (86%)]\tLoss: 0.440902\nTrain Epoch: 1 [215000/248297 (87%)]\tLoss: 0.584649\nTrain Epoch: 1 [216000/248297 (87%)]\tLoss: 0.557154\nTrain Epoch: 1 [217000/248297 (87%)]\tLoss: 0.639086\nTrain Epoch: 1 [218000/248297 (88%)]\tLoss: 0.544591\nTrain Epoch: 1 [219000/248297 (88%)]\tLoss: 0.578744\nTrain Epoch: 1 [220000/248297 (89%)]\tLoss: 0.549869\nTrain Epoch: 1 [221000/248297 (89%)]\tLoss: 0.538435\nTrain Epoch: 1 [222000/248297 (89%)]\tLoss: 0.537035\nTrain Epoch: 1 [223000/248297 (90%)]\tLoss: 0.535119\nTrain Epoch: 1 [224000/248297 (90%)]\tLoss: 0.595842\nTrain Epoch: 1 [225000/248297 (91%)]\tLoss: 0.606012\nTrain Epoch: 1 [226000/248297 (91%)]\tLoss: 0.625467\nTrain Epoch: 1 [227000/248297 (91%)]\tLoss: 0.559155\nTrain Epoch: 1 [228000/248297 (92%)]\tLoss: 0.572470\nTrain Epoch: 1 [229000/248297 (92%)]\tLoss: 0.518571\nTrain Epoch: 1 [230000/248297 (93%)]\tLoss: 0.587049\nTrain Epoch: 1 [231000/248297 (93%)]\tLoss: 0.506603\nTrain Epoch: 1 [232000/248297 (93%)]\tLoss: 0.500407\nTrain Epoch: 1 [233000/248297 (94%)]\tLoss: 0.606708\nTrain Epoch: 1 [234000/248297 (94%)]\tLoss: 0.533842\nTrain Epoch: 1 [235000/248297 (95%)]\tLoss: 0.614525\nTrain Epoch: 1 [236000/248297 (95%)]\tLoss: 0.509352\nTrain Epoch: 1 [237000/248297 (95%)]\tLoss: 0.614875\nTrain Epoch: 1 [238000/248297 (96%)]\tLoss: 0.534993\nTrain Epoch: 1 [239000/248297 (96%)]\tLoss: 0.411873\nTrain Epoch: 1 [240000/248297 (97%)]\tLoss: 0.508787\nTrain Epoch: 1 [241000/248297 (97%)]\tLoss: 0.515356\nTrain Epoch: 1 [242000/248297 (98%)]\tLoss: 0.564659\nTrain Epoch: 1 [243000/248297 (98%)]\tLoss: 0.491834\nTrain Epoch: 1 [244000/248297 (98%)]\tLoss: 0.564641\nTrain Epoch: 1 [245000/248297 (99%)]\tLoss: 0.567691\nTrain Epoch: 1 [246000/248297 (99%)]\tLoss: 0.562436\nTrain Epoch: 1 [247000/248297 (100%)]\tLoss: 0.519809\nTrain Epoch: 1 [248000/248297 (100%)]\tLoss: 0.583060\n\nTest set: Average loss: 0.0054, Accuracy: 19714/27589 (71%)\n\nTrain Epoch: 2 [0/248297 (0%)]\tLoss: 0.517603\nTrain Epoch: 2 [1000/248297 (0%)]\tLoss: 0.511054\nTrain Epoch: 2 [2000/248297 (1%)]\tLoss: 0.575755\nTrain Epoch: 2 [3000/248297 (1%)]\tLoss: 0.598783\nTrain Epoch: 2 [4000/248297 (2%)]\tLoss: 0.576275\nTrain Epoch: 2 [5000/248297 (2%)]\tLoss: 0.515999\nTrain Epoch: 2 [6000/248297 (2%)]\tLoss: 0.496899\nTrain Epoch: 2 [7000/248297 (3%)]\tLoss: 0.608505\nTrain Epoch: 2 [8000/248297 (3%)]\tLoss: 0.586316\nTrain Epoch: 2 [9000/248297 (4%)]\tLoss: 0.642650\nTrain Epoch: 2 [10000/248297 (4%)]\tLoss: 0.511247\nTrain Epoch: 2 [11000/248297 (4%)]\tLoss: 0.580325\nTrain Epoch: 2 [12000/248297 (5%)]\tLoss: 0.554954\nTrain Epoch: 2 [13000/248297 (5%)]\tLoss: 0.528349\nTrain Epoch: 2 [14000/248297 (6%)]\tLoss: 0.499268\nTrain Epoch: 2 [15000/248297 (6%)]\tLoss: 0.601374\nTrain Epoch: 2 [16000/248297 (6%)]\tLoss: 0.513856\nTrain Epoch: 2 [17000/248297 (7%)]\tLoss: 0.587620\nTrain Epoch: 2 [18000/248297 (7%)]\tLoss: 0.560460\nTrain Epoch: 2 [19000/248297 (8%)]\tLoss: 0.492712\nTrain Epoch: 2 [20000/248297 (8%)]\tLoss: 0.441073\nTrain Epoch: 2 [21000/248297 (8%)]\tLoss: 0.504930\nTrain Epoch: 2 [22000/248297 (9%)]\tLoss: 0.501219\nTrain Epoch: 2 [23000/248297 (9%)]\tLoss: 0.562278\nTrain Epoch: 2 [24000/248297 (10%)]\tLoss: 0.609499\nTrain Epoch: 2 [25000/248297 (10%)]\tLoss: 0.550441\nTrain Epoch: 2 [26000/248297 (10%)]\tLoss: 0.593458\nTrain Epoch: 2 [27000/248297 (11%)]\tLoss: 0.542333\nTrain Epoch: 2 [28000/248297 (11%)]\tLoss: 0.543647\nTrain Epoch: 2 [29000/248297 (12%)]\tLoss: 0.519930\nTrain Epoch: 2 [30000/248297 (12%)]\tLoss: 0.571619\nTrain Epoch: 2 [31000/248297 (12%)]\tLoss: 0.588398\nTrain Epoch: 2 [32000/248297 (13%)]\tLoss: 0.498103\nTrain Epoch: 2 [33000/248297 (13%)]\tLoss: 0.642604\nTrain Epoch: 2 [34000/248297 (14%)]\tLoss: 0.518651\nTrain Epoch: 2 [35000/248297 (14%)]\tLoss: 0.537535\nTrain Epoch: 2 [36000/248297 (15%)]\tLoss: 0.574238\nTrain Epoch: 2 [37000/248297 (15%)]\tLoss: 0.519377\nTrain Epoch: 2 [38000/248297 (15%)]\tLoss: 0.551529\nTrain Epoch: 2 [39000/248297 (16%)]\tLoss: 0.469169\nTrain Epoch: 2 [40000/248297 (16%)]\tLoss: 0.580350\nTrain Epoch: 2 [41000/248297 (17%)]\tLoss: 0.596699\nTrain Epoch: 2 [42000/248297 (17%)]\tLoss: 0.462104\nTrain Epoch: 2 [43000/248297 (17%)]\tLoss: 0.516521\nTrain Epoch: 2 [44000/248297 (18%)]\tLoss: 0.533423\nTrain Epoch: 2 [45000/248297 (18%)]\tLoss: 0.577956\nTrain Epoch: 2 [46000/248297 (19%)]\tLoss: 0.523694\nTrain Epoch: 2 [47000/248297 (19%)]\tLoss: 0.516939\nTrain Epoch: 2 [48000/248297 (19%)]\tLoss: 0.593343\nTrain Epoch: 2 [49000/248297 (20%)]\tLoss: 0.531841\nTrain Epoch: 2 [50000/248297 (20%)]\tLoss: 0.461478\nTrain Epoch: 2 [51000/248297 (21%)]\tLoss: 0.609091\nTrain Epoch: 2 [52000/248297 (21%)]\tLoss: 0.574681\nTrain Epoch: 2 [53000/248297 (21%)]\tLoss: 0.528655\nTrain Epoch: 2 [54000/248297 (22%)]\tLoss: 0.480726\nTrain Epoch: 2 [55000/248297 (22%)]\tLoss: 0.498788\nTrain Epoch: 2 [56000/248297 (23%)]\tLoss: 0.464916\nTrain Epoch: 2 [57000/248297 (23%)]\tLoss: 0.629401\nTrain Epoch: 2 [58000/248297 (23%)]\tLoss: 0.552953\nTrain Epoch: 2 [59000/248297 (24%)]\tLoss: 0.504638\nTrain Epoch: 2 [60000/248297 (24%)]\tLoss: 0.642288\nTrain Epoch: 2 [61000/248297 (25%)]\tLoss: 0.542145\nTrain Epoch: 2 [62000/248297 (25%)]\tLoss: 0.502291\nTrain Epoch: 2 [63000/248297 (25%)]\tLoss: 0.606412\nTrain Epoch: 2 [64000/248297 (26%)]\tLoss: 0.602732\nTrain Epoch: 2 [65000/248297 (26%)]\tLoss: 0.504991\nTrain Epoch: 2 [66000/248297 (27%)]\tLoss: 0.521448\nTrain Epoch: 2 [67000/248297 (27%)]\tLoss: 0.475482\nTrain Epoch: 2 [68000/248297 (27%)]\tLoss: 0.509762\nTrain Epoch: 2 [69000/248297 (28%)]\tLoss: 0.574209\nTrain Epoch: 2 [70000/248297 (28%)]\tLoss: 0.526743\nTrain Epoch: 2 [71000/248297 (29%)]\tLoss: 0.593189\nTrain Epoch: 2 [72000/248297 (29%)]\tLoss: 0.609950\nTrain Epoch: 2 [73000/248297 (29%)]\tLoss: 0.503533\nTrain Epoch: 2 [74000/248297 (30%)]\tLoss: 0.556626\nTrain Epoch: 2 [75000/248297 (30%)]\tLoss: 0.499871\nTrain Epoch: 2 [76000/248297 (31%)]\tLoss: 0.599170\nTrain Epoch: 2 [77000/248297 (31%)]\tLoss: 0.598641\nTrain Epoch: 2 [78000/248297 (31%)]\tLoss: 0.511440\nTrain Epoch: 2 [79000/248297 (32%)]\tLoss: 0.470901\nTrain Epoch: 2 [80000/248297 (32%)]\tLoss: 0.586802\nTrain Epoch: 2 [81000/248297 (33%)]\tLoss: 0.499152\nTrain Epoch: 2 [82000/248297 (33%)]\tLoss: 0.497308\nTrain Epoch: 2 [83000/248297 (33%)]\tLoss: 0.548364\nTrain Epoch: 2 [84000/248297 (34%)]\tLoss: 0.522079\nTrain Epoch: 2 [85000/248297 (34%)]\tLoss: 0.513013\nTrain Epoch: 2 [86000/248297 (35%)]\tLoss: 0.639511\nTrain Epoch: 2 [87000/248297 (35%)]\tLoss: 0.585783\nTrain Epoch: 2 [88000/248297 (35%)]\tLoss: 0.509348\nTrain Epoch: 2 [89000/248297 (36%)]\tLoss: 0.573141\nTrain Epoch: 2 [90000/248297 (36%)]\tLoss: 0.571066\nTrain Epoch: 2 [91000/248297 (37%)]\tLoss: 0.569488\nTrain Epoch: 2 [92000/248297 (37%)]\tLoss: 0.521213\nTrain Epoch: 2 [93000/248297 (37%)]\tLoss: 0.460106\nTrain Epoch: 2 [94000/248297 (38%)]\tLoss: 0.513806\nTrain Epoch: 2 [95000/248297 (38%)]\tLoss: 0.578664\nTrain Epoch: 2 [96000/248297 (39%)]\tLoss: 0.433453\nTrain Epoch: 2 [97000/248297 (39%)]\tLoss: 0.519827\nTrain Epoch: 2 [98000/248297 (39%)]\tLoss: 0.667201\nTrain Epoch: 2 [99000/248297 (40%)]\tLoss: 0.533561\nTrain Epoch: 2 [100000/248297 (40%)]\tLoss: 0.557301\nTrain Epoch: 2 [101000/248297 (41%)]\tLoss: 0.511501\nTrain Epoch: 2 [102000/248297 (41%)]\tLoss: 0.627916\nTrain Epoch: 2 [103000/248297 (41%)]\tLoss: 0.537783\nTrain Epoch: 2 [104000/248297 (42%)]\tLoss: 0.528196\nTrain Epoch: 2 [105000/248297 (42%)]\tLoss: 0.510975\nTrain Epoch: 2 [106000/248297 (43%)]\tLoss: 0.552271\nTrain Epoch: 2 [107000/248297 (43%)]\tLoss: 0.529370\nTrain Epoch: 2 [108000/248297 (44%)]\tLoss: 0.533322\nTrain Epoch: 2 [109000/248297 (44%)]\tLoss: 0.571697\nTrain Epoch: 2 [110000/248297 (44%)]\tLoss: 0.600393\nTrain Epoch: 2 [111000/248297 (45%)]\tLoss: 0.578505\nTrain Epoch: 2 [112000/248297 (45%)]\tLoss: 0.585735\nTrain Epoch: 2 [113000/248297 (46%)]\tLoss: 0.524891\nTrain Epoch: 2 [114000/248297 (46%)]\tLoss: 0.548372\nTrain Epoch: 2 [115000/248297 (46%)]\tLoss: 0.716596\nTrain Epoch: 2 [116000/248297 (47%)]\tLoss: 0.525620\nTrain Epoch: 2 [117000/248297 (47%)]\tLoss: 0.480879\nTrain Epoch: 2 [118000/248297 (48%)]\tLoss: 0.506584\nTrain Epoch: 2 [119000/248297 (48%)]\tLoss: 0.598446\nTrain Epoch: 2 [120000/248297 (48%)]\tLoss: 0.477404\nTrain Epoch: 2 [121000/248297 (49%)]\tLoss: 0.482441\nTrain Epoch: 2 [122000/248297 (49%)]\tLoss: 0.545248\nTrain Epoch: 2 [123000/248297 (50%)]\tLoss: 0.455343\nTrain Epoch: 2 [124000/248297 (50%)]\tLoss: 0.502698\nTrain Epoch: 2 [125000/248297 (50%)]\tLoss: 0.577712\nTrain Epoch: 2 [126000/248297 (51%)]\tLoss: 0.572659\nTrain Epoch: 2 [127000/248297 (51%)]\tLoss: 0.566609\nTrain Epoch: 2 [128000/248297 (52%)]\tLoss: 0.535818\nTrain Epoch: 2 [129000/248297 (52%)]\tLoss: 0.611115\nTrain Epoch: 2 [130000/248297 (52%)]\tLoss: 0.515428\nTrain Epoch: 2 [131000/248297 (53%)]\tLoss: 0.591755\nTrain Epoch: 2 [132000/248297 (53%)]\tLoss: 0.507962\nTrain Epoch: 2 [133000/248297 (54%)]\tLoss: 0.515705\nTrain Epoch: 2 [134000/248297 (54%)]\tLoss: 0.615863\nTrain Epoch: 2 [135000/248297 (54%)]\tLoss: 0.517489\nTrain Epoch: 2 [136000/248297 (55%)]\tLoss: 0.545836\nTrain Epoch: 2 [137000/248297 (55%)]\tLoss: 0.553540\nTrain Epoch: 2 [138000/248297 (56%)]\tLoss: 0.520727\nTrain Epoch: 2 [139000/248297 (56%)]\tLoss: 0.630272\nTrain Epoch: 2 [140000/248297 (56%)]\tLoss: 0.487652\nTrain Epoch: 2 [141000/248297 (57%)]\tLoss: 0.541532\nTrain Epoch: 2 [142000/248297 (57%)]\tLoss: 0.535604\nTrain Epoch: 2 [143000/248297 (58%)]\tLoss: 0.594231\nTrain Epoch: 2 [144000/248297 (58%)]\tLoss: 0.485681\nTrain Epoch: 2 [145000/248297 (58%)]\tLoss: 0.580837\nTrain Epoch: 2 [146000/248297 (59%)]\tLoss: 0.528372\nTrain Epoch: 2 [147000/248297 (59%)]\tLoss: 0.509577\nTrain Epoch: 2 [148000/248297 (60%)]\tLoss: 0.523517\nTrain Epoch: 2 [149000/248297 (60%)]\tLoss: 0.577642\nTrain Epoch: 2 [150000/248297 (60%)]\tLoss: 0.579556\nTrain Epoch: 2 [151000/248297 (61%)]\tLoss: 0.565735\nTrain Epoch: 2 [152000/248297 (61%)]\tLoss: 0.558739\nTrain Epoch: 2 [153000/248297 (62%)]\tLoss: 0.529675\nTrain Epoch: 2 [154000/248297 (62%)]\tLoss: 0.626914\nTrain Epoch: 2 [155000/248297 (62%)]\tLoss: 0.465343\nTrain Epoch: 2 [156000/248297 (63%)]\tLoss: 0.525033\nTrain Epoch: 2 [157000/248297 (63%)]\tLoss: 0.539229\nTrain Epoch: 2 [158000/248297 (64%)]\tLoss: 0.642926\nTrain Epoch: 2 [159000/248297 (64%)]\tLoss: 0.536843\nTrain Epoch: 2 [160000/248297 (64%)]\tLoss: 0.583103\nTrain Epoch: 2 [161000/248297 (65%)]\tLoss: 0.484643\nTrain Epoch: 2 [162000/248297 (65%)]\tLoss: 0.582975\nTrain Epoch: 2 [163000/248297 (66%)]\tLoss: 0.598012\nTrain Epoch: 2 [164000/248297 (66%)]\tLoss: 0.540472\nTrain Epoch: 2 [165000/248297 (66%)]\tLoss: 0.499118\nTrain Epoch: 2 [166000/248297 (67%)]\tLoss: 0.546452\nTrain Epoch: 2 [167000/248297 (67%)]\tLoss: 0.426864\nTrain Epoch: 2 [168000/248297 (68%)]\tLoss: 0.513669\nTrain Epoch: 2 [169000/248297 (68%)]\tLoss: 0.493576\nTrain Epoch: 2 [170000/248297 (68%)]\tLoss: 0.563196\nTrain Epoch: 2 [171000/248297 (69%)]\tLoss: 0.533161\nTrain Epoch: 2 [172000/248297 (69%)]\tLoss: 0.498498\nTrain Epoch: 2 [173000/248297 (70%)]\tLoss: 0.459003\nTrain Epoch: 2 [174000/248297 (70%)]\tLoss: 0.524834\nTrain Epoch: 2 [175000/248297 (71%)]\tLoss: 0.503770\nTrain Epoch: 2 [176000/248297 (71%)]\tLoss: 0.490823\nTrain Epoch: 2 [177000/248297 (71%)]\tLoss: 0.572983\nTrain Epoch: 2 [178000/248297 (72%)]\tLoss: 0.531606\nTrain Epoch: 2 [179000/248297 (72%)]\tLoss: 0.554522\nTrain Epoch: 2 [180000/248297 (73%)]\tLoss: 0.546508\nTrain Epoch: 2 [181000/248297 (73%)]\tLoss: 0.505764\nTrain Epoch: 2 [182000/248297 (73%)]\tLoss: 0.631346\nTrain Epoch: 2 [183000/248297 (74%)]\tLoss: 0.533549\nTrain Epoch: 2 [184000/248297 (74%)]\tLoss: 0.546973\nTrain Epoch: 2 [185000/248297 (75%)]\tLoss: 0.574160\nTrain Epoch: 2 [186000/248297 (75%)]\tLoss: 0.620264\nTrain Epoch: 2 [187000/248297 (75%)]\tLoss: 0.606179\nTrain Epoch: 2 [188000/248297 (76%)]\tLoss: 0.479127\nTrain Epoch: 2 [189000/248297 (76%)]\tLoss: 0.545612\nTrain Epoch: 2 [190000/248297 (77%)]\tLoss: 0.519693\nTrain Epoch: 2 [191000/248297 (77%)]\tLoss: 0.529684\nTrain Epoch: 2 [192000/248297 (77%)]\tLoss: 0.556323\nTrain Epoch: 2 [193000/248297 (78%)]\tLoss: 0.574530\nTrain Epoch: 2 [194000/248297 (78%)]\tLoss: 0.626667\nTrain Epoch: 2 [195000/248297 (79%)]\tLoss: 0.573259\nTrain Epoch: 2 [196000/248297 (79%)]\tLoss: 0.548429\nTrain Epoch: 2 [197000/248297 (79%)]\tLoss: 0.511395\nTrain Epoch: 2 [198000/248297 (80%)]\tLoss: 0.663203\nTrain Epoch: 2 [199000/248297 (80%)]\tLoss: 0.521158\nTrain Epoch: 2 [200000/248297 (81%)]\tLoss: 0.547217\nTrain Epoch: 2 [201000/248297 (81%)]\tLoss: 0.540298\nTrain Epoch: 2 [202000/248297 (81%)]\tLoss: 0.464025\nTrain Epoch: 2 [203000/248297 (82%)]\tLoss: 0.504405\nTrain Epoch: 2 [204000/248297 (82%)]\tLoss: 0.543986\nTrain Epoch: 2 [205000/248297 (83%)]\tLoss: 0.499568\nTrain Epoch: 2 [206000/248297 (83%)]\tLoss: 0.512252\nTrain Epoch: 2 [207000/248297 (83%)]\tLoss: 0.532474\nTrain Epoch: 2 [208000/248297 (84%)]\tLoss: 0.617016\nTrain Epoch: 2 [209000/248297 (84%)]\tLoss: 0.525027\nTrain Epoch: 2 [210000/248297 (85%)]\tLoss: 0.548468\nTrain Epoch: 2 [211000/248297 (85%)]\tLoss: 0.557215\nTrain Epoch: 2 [212000/248297 (85%)]\tLoss: 0.566162\nTrain Epoch: 2 [213000/248297 (86%)]\tLoss: 0.571184\nTrain Epoch: 2 [214000/248297 (86%)]\tLoss: 0.486490\nTrain Epoch: 2 [215000/248297 (87%)]\tLoss: 0.581873\nTrain Epoch: 2 [216000/248297 (87%)]\tLoss: 0.512822\nTrain Epoch: 2 [217000/248297 (87%)]\tLoss: 0.514456\nTrain Epoch: 2 [218000/248297 (88%)]\tLoss: 0.552749\nTrain Epoch: 2 [219000/248297 (88%)]\tLoss: 0.550220\nTrain Epoch: 2 [220000/248297 (89%)]\tLoss: 0.611598\nTrain Epoch: 2 [221000/248297 (89%)]\tLoss: 0.537029\nTrain Epoch: 2 [222000/248297 (89%)]\tLoss: 0.577229\nTrain Epoch: 2 [223000/248297 (90%)]\tLoss: 0.499963\nTrain Epoch: 2 [224000/248297 (90%)]\tLoss: 0.540791\nTrain Epoch: 2 [225000/248297 (91%)]\tLoss: 0.490270\nTrain Epoch: 2 [226000/248297 (91%)]\tLoss: 0.513350\nTrain Epoch: 2 [227000/248297 (91%)]\tLoss: 0.527635\nTrain Epoch: 2 [228000/248297 (92%)]\tLoss: 0.530102\nTrain Epoch: 2 [229000/248297 (92%)]\tLoss: 0.553402\nTrain Epoch: 2 [230000/248297 (93%)]\tLoss: 0.469905\nTrain Epoch: 2 [231000/248297 (93%)]\tLoss: 0.534613\nTrain Epoch: 2 [232000/248297 (93%)]\tLoss: 0.459123\nTrain Epoch: 2 [233000/248297 (94%)]\tLoss: 0.638710\nTrain Epoch: 2 [234000/248297 (94%)]\tLoss: 0.540872\nTrain Epoch: 2 [235000/248297 (95%)]\tLoss: 0.666520\nTrain Epoch: 2 [236000/248297 (95%)]\tLoss: 0.613005\nTrain Epoch: 2 [237000/248297 (95%)]\tLoss: 0.630117\nTrain Epoch: 2 [238000/248297 (96%)]\tLoss: 0.531437\nTrain Epoch: 2 [239000/248297 (96%)]\tLoss: 0.560260\nTrain Epoch: 2 [240000/248297 (97%)]\tLoss: 0.634091\nTrain Epoch: 2 [241000/248297 (97%)]\tLoss: 0.492231\nTrain Epoch: 2 [242000/248297 (98%)]\tLoss: 0.467723\nTrain Epoch: 2 [243000/248297 (98%)]\tLoss: 0.602904\nTrain Epoch: 2 [244000/248297 (98%)]\tLoss: 0.457278\nTrain Epoch: 2 [245000/248297 (99%)]\tLoss: 0.540924\nTrain Epoch: 2 [246000/248297 (99%)]\tLoss: 0.507883\nTrain Epoch: 2 [247000/248297 (100%)]\tLoss: 0.591139\nTrain Epoch: 2 [248000/248297 (100%)]\tLoss: 0.524149\n\nTest set: Average loss: 0.0053, Accuracy: 20131/27589 (73%)\n\nTrain Epoch: 3 [0/248297 (0%)]\tLoss: 0.563653\nTrain Epoch: 3 [1000/248297 (0%)]\tLoss: 0.494471\nTrain Epoch: 3 [2000/248297 (1%)]\tLoss: 0.563240\nTrain Epoch: 3 [3000/248297 (1%)]\tLoss: 0.516083\nTrain Epoch: 3 [4000/248297 (2%)]\tLoss: 0.549108\nTrain Epoch: 3 [5000/248297 (2%)]\tLoss: 0.410571\nTrain Epoch: 3 [6000/248297 (2%)]\tLoss: 0.574777\nTrain Epoch: 3 [7000/248297 (3%)]\tLoss: 0.541810\nTrain Epoch: 3 [8000/248297 (3%)]\tLoss: 0.547230\nTrain Epoch: 3 [9000/248297 (4%)]\tLoss: 0.469457\nTrain Epoch: 3 [10000/248297 (4%)]\tLoss: 0.546934\nTrain Epoch: 3 [11000/248297 (4%)]\tLoss: 0.549663\nTrain Epoch: 3 [12000/248297 (5%)]\tLoss: 0.532934\nTrain Epoch: 3 [13000/248297 (5%)]\tLoss: 0.527021\nTrain Epoch: 3 [14000/248297 (6%)]\tLoss: 0.479373\nTrain Epoch: 3 [15000/248297 (6%)]\tLoss: 0.509970\nTrain Epoch: 3 [16000/248297 (6%)]\tLoss: 0.572439\nTrain Epoch: 3 [17000/248297 (7%)]\tLoss: 0.510321\nTrain Epoch: 3 [18000/248297 (7%)]\tLoss: 0.521822\nTrain Epoch: 3 [19000/248297 (8%)]\tLoss: 0.436504\nTrain Epoch: 3 [20000/248297 (8%)]\tLoss: 0.483680\nTrain Epoch: 3 [21000/248297 (8%)]\tLoss: 0.604868\nTrain Epoch: 3 [22000/248297 (9%)]\tLoss: 0.531673\nTrain Epoch: 3 [23000/248297 (9%)]\tLoss: 0.504699\nTrain Epoch: 3 [24000/248297 (10%)]\tLoss: 0.528121\nTrain Epoch: 3 [25000/248297 (10%)]\tLoss: 0.470675\nTrain Epoch: 3 [26000/248297 (10%)]\tLoss: 0.524408\nTrain Epoch: 3 [27000/248297 (11%)]\tLoss: 0.545577\nTrain Epoch: 3 [28000/248297 (11%)]\tLoss: 0.527522\nTrain Epoch: 3 [29000/248297 (12%)]\tLoss: 0.503063\nTrain Epoch: 3 [30000/248297 (12%)]\tLoss: 0.541079\nTrain Epoch: 3 [31000/248297 (12%)]\tLoss: 0.495498\nTrain Epoch: 3 [32000/248297 (13%)]\tLoss: 0.566668\nTrain Epoch: 3 [33000/248297 (13%)]\tLoss: 0.611955\nTrain Epoch: 3 [34000/248297 (14%)]\tLoss: 0.495907\nTrain Epoch: 3 [35000/248297 (14%)]\tLoss: 0.615932\nTrain Epoch: 3 [36000/248297 (15%)]\tLoss: 0.553130\nTrain Epoch: 3 [37000/248297 (15%)]\tLoss: 0.544840\nTrain Epoch: 3 [38000/248297 (15%)]\tLoss: 0.533374\nTrain Epoch: 3 [39000/248297 (16%)]\tLoss: 0.482673\nTrain Epoch: 3 [40000/248297 (16%)]\tLoss: 0.520374\nTrain Epoch: 3 [41000/248297 (17%)]\tLoss: 0.518848\nTrain Epoch: 3 [42000/248297 (17%)]\tLoss: 0.536560\nTrain Epoch: 3 [43000/248297 (17%)]\tLoss: 0.491842\nTrain Epoch: 3 [44000/248297 (18%)]\tLoss: 0.536375\nTrain Epoch: 3 [45000/248297 (18%)]\tLoss: 0.503936\nTrain Epoch: 3 [46000/248297 (19%)]\tLoss: 0.499936\nTrain Epoch: 3 [47000/248297 (19%)]\tLoss: 0.501251\nTrain Epoch: 3 [48000/248297 (19%)]\tLoss: 0.572103\nTrain Epoch: 3 [49000/248297 (20%)]\tLoss: 0.558608\nTrain Epoch: 3 [50000/248297 (20%)]\tLoss: 0.673230\nTrain Epoch: 3 [51000/248297 (21%)]\tLoss: 0.526584\nTrain Epoch: 3 [52000/248297 (21%)]\tLoss: 0.567932\nTrain Epoch: 3 [53000/248297 (21%)]\tLoss: 0.505202\nTrain Epoch: 3 [54000/248297 (22%)]\tLoss: 0.527324\nTrain Epoch: 3 [55000/248297 (22%)]\tLoss: 0.400437\nTrain Epoch: 3 [56000/248297 (23%)]\tLoss: 0.527809\nTrain Epoch: 3 [57000/248297 (23%)]\tLoss: 0.452969\nTrain Epoch: 3 [58000/248297 (23%)]\tLoss: 0.630842\nTrain Epoch: 3 [59000/248297 (24%)]\tLoss: 0.630422\nTrain Epoch: 3 [60000/248297 (24%)]\tLoss: 0.412763\nTrain Epoch: 3 [61000/248297 (25%)]\tLoss: 0.546296\nTrain Epoch: 3 [62000/248297 (25%)]\tLoss: 0.515309\nTrain Epoch: 3 [63000/248297 (25%)]\tLoss: 0.472765\nTrain Epoch: 3 [64000/248297 (26%)]\tLoss: 0.502878\nTrain Epoch: 3 [65000/248297 (26%)]\tLoss: 0.683280\nTrain Epoch: 3 [66000/248297 (27%)]\tLoss: 0.588023\nTrain Epoch: 3 [67000/248297 (27%)]\tLoss: 0.506767\nTrain Epoch: 3 [68000/248297 (27%)]\tLoss: 0.572929\nTrain Epoch: 3 [69000/248297 (28%)]\tLoss: 0.456018\nTrain Epoch: 3 [70000/248297 (28%)]\tLoss: 0.538519\nTrain Epoch: 3 [71000/248297 (29%)]\tLoss: 0.543833\nTrain Epoch: 3 [72000/248297 (29%)]\tLoss: 0.568896\nTrain Epoch: 3 [73000/248297 (29%)]\tLoss: 0.537913\nTrain Epoch: 3 [74000/248297 (30%)]\tLoss: 0.539547\nTrain Epoch: 3 [75000/248297 (30%)]\tLoss: 0.466645\nTrain Epoch: 3 [76000/248297 (31%)]\tLoss: 0.480785\nTrain Epoch: 3 [77000/248297 (31%)]\tLoss: 0.525314\nTrain Epoch: 3 [78000/248297 (31%)]\tLoss: 0.513454\nTrain Epoch: 3 [79000/248297 (32%)]\tLoss: 0.570808\nTrain Epoch: 3 [80000/248297 (32%)]\tLoss: 0.540744\nTrain Epoch: 3 [81000/248297 (33%)]\tLoss: 0.489015\nTrain Epoch: 3 [82000/248297 (33%)]\tLoss: 0.608158\nTrain Epoch: 3 [83000/248297 (33%)]\tLoss: 0.488729\nTrain Epoch: 3 [84000/248297 (34%)]\tLoss: 0.583096\nTrain Epoch: 3 [85000/248297 (34%)]\tLoss: 0.574195\nTrain Epoch: 3 [86000/248297 (35%)]\tLoss: 0.527801\nTrain Epoch: 3 [87000/248297 (35%)]\tLoss: 0.488773\nTrain Epoch: 3 [88000/248297 (35%)]\tLoss: 0.470319\nTrain Epoch: 3 [89000/248297 (36%)]\tLoss: 0.609223\nTrain Epoch: 3 [90000/248297 (36%)]\tLoss: 0.537618\nTrain Epoch: 3 [91000/248297 (37%)]\tLoss: 0.550890\nTrain Epoch: 3 [92000/248297 (37%)]\tLoss: 0.526688\nTrain Epoch: 3 [93000/248297 (37%)]\tLoss: 0.556912\nTrain Epoch: 3 [94000/248297 (38%)]\tLoss: 0.513928\nTrain Epoch: 3 [95000/248297 (38%)]\tLoss: 0.568746\nTrain Epoch: 3 [96000/248297 (39%)]\tLoss: 0.516409\nTrain Epoch: 3 [97000/248297 (39%)]\tLoss: 0.491482\nTrain Epoch: 3 [98000/248297 (39%)]\tLoss: 0.533299\nTrain Epoch: 3 [99000/248297 (40%)]\tLoss: 0.507307\nTrain Epoch: 3 [100000/248297 (40%)]\tLoss: 0.521332\nTrain Epoch: 3 [101000/248297 (41%)]\tLoss: 0.566901\nTrain Epoch: 3 [102000/248297 (41%)]\tLoss: 0.566757\nTrain Epoch: 3 [103000/248297 (41%)]\tLoss: 0.539995\nTrain Epoch: 3 [104000/248297 (42%)]\tLoss: 0.545996\nTrain Epoch: 3 [105000/248297 (42%)]\tLoss: 0.527389\nTrain Epoch: 3 [106000/248297 (43%)]\tLoss: 0.562577\nTrain Epoch: 3 [107000/248297 (43%)]\tLoss: 0.538369\nTrain Epoch: 3 [108000/248297 (44%)]\tLoss: 0.542300\nTrain Epoch: 3 [109000/248297 (44%)]\tLoss: 0.604410\nTrain Epoch: 3 [110000/248297 (44%)]\tLoss: 0.496385\nTrain Epoch: 3 [111000/248297 (45%)]\tLoss: 0.444288\nTrain Epoch: 3 [112000/248297 (45%)]\tLoss: 0.501219\nTrain Epoch: 3 [113000/248297 (46%)]\tLoss: 0.555595\nTrain Epoch: 3 [114000/248297 (46%)]\tLoss: 0.613782\nTrain Epoch: 3 [115000/248297 (46%)]\tLoss: 0.452637\nTrain Epoch: 3 [116000/248297 (47%)]\tLoss: 0.539125\nTrain Epoch: 3 [117000/248297 (47%)]\tLoss: 0.561591\nTrain Epoch: 3 [118000/248297 (48%)]\tLoss: 0.522117\nTrain Epoch: 3 [119000/248297 (48%)]\tLoss: 0.519871\nTrain Epoch: 3 [120000/248297 (48%)]\tLoss: 0.493264\nTrain Epoch: 3 [121000/248297 (49%)]\tLoss: 0.470105\nTrain Epoch: 3 [122000/248297 (49%)]\tLoss: 0.453282\nTrain Epoch: 3 [123000/248297 (50%)]\tLoss: 0.425259\nTrain Epoch: 3 [124000/248297 (50%)]\tLoss: 0.573029\nTrain Epoch: 3 [125000/248297 (50%)]\tLoss: 0.525623\nTrain Epoch: 3 [126000/248297 (51%)]\tLoss: 0.526834\nTrain Epoch: 3 [127000/248297 (51%)]\tLoss: 0.540720\nTrain Epoch: 3 [128000/248297 (52%)]\tLoss: 0.568279\nTrain Epoch: 3 [129000/248297 (52%)]\tLoss: 0.477483\nTrain Epoch: 3 [130000/248297 (52%)]\tLoss: 0.513138\nTrain Epoch: 3 [131000/248297 (53%)]\tLoss: 0.525128\nTrain Epoch: 3 [132000/248297 (53%)]\tLoss: 0.478472\nTrain Epoch: 3 [133000/248297 (54%)]\tLoss: 0.454711\nTrain Epoch: 3 [134000/248297 (54%)]\tLoss: 0.520253\nTrain Epoch: 3 [135000/248297 (54%)]\tLoss: 0.526002\nTrain Epoch: 3 [136000/248297 (55%)]\tLoss: 0.544948\nTrain Epoch: 3 [137000/248297 (55%)]\tLoss: 0.469485\nTrain Epoch: 3 [138000/248297 (56%)]\tLoss: 0.545479\nTrain Epoch: 3 [139000/248297 (56%)]\tLoss: 0.514540\nTrain Epoch: 3 [140000/248297 (56%)]\tLoss: 0.476198\nTrain Epoch: 3 [141000/248297 (57%)]\tLoss: 0.493399\nTrain Epoch: 3 [142000/248297 (57%)]\tLoss: 0.544238\nTrain Epoch: 3 [143000/248297 (58%)]\tLoss: 0.584045\nTrain Epoch: 3 [144000/248297 (58%)]\tLoss: 0.561707\nTrain Epoch: 3 [145000/248297 (58%)]\tLoss: 0.549775\nTrain Epoch: 3 [146000/248297 (59%)]\tLoss: 0.429418\nTrain Epoch: 3 [147000/248297 (59%)]\tLoss: 0.490514\nTrain Epoch: 3 [148000/248297 (60%)]\tLoss: 0.484074\nTrain Epoch: 3 [149000/248297 (60%)]\tLoss: 0.517477\nTrain Epoch: 3 [150000/248297 (60%)]\tLoss: 0.448117\nTrain Epoch: 3 [151000/248297 (61%)]\tLoss: 0.422751\nTrain Epoch: 3 [152000/248297 (61%)]\tLoss: 0.551702\nTrain Epoch: 3 [153000/248297 (62%)]\tLoss: 0.525275\nTrain Epoch: 3 [154000/248297 (62%)]\tLoss: 0.543417\nTrain Epoch: 3 [155000/248297 (62%)]\tLoss: 0.519956\nTrain Epoch: 3 [156000/248297 (63%)]\tLoss: 0.440876\nTrain Epoch: 3 [157000/248297 (63%)]\tLoss: 0.528958\nTrain Epoch: 3 [158000/248297 (64%)]\tLoss: 0.565677\nTrain Epoch: 3 [159000/248297 (64%)]\tLoss: 0.514345\nTrain Epoch: 3 [160000/248297 (64%)]\tLoss: 0.514436\nTrain Epoch: 3 [161000/248297 (65%)]\tLoss: 0.543190\nTrain Epoch: 3 [162000/248297 (65%)]\tLoss: 0.459881\nTrain Epoch: 3 [163000/248297 (66%)]\tLoss: 0.447348\nTrain Epoch: 3 [164000/248297 (66%)]\tLoss: 0.554462\nTrain Epoch: 3 [165000/248297 (66%)]\tLoss: 0.568025\nTrain Epoch: 3 [166000/248297 (67%)]\tLoss: 0.582285\nTrain Epoch: 3 [167000/248297 (67%)]\tLoss: 0.534224\nTrain Epoch: 3 [168000/248297 (68%)]\tLoss: 0.425563\nTrain Epoch: 3 [169000/248297 (68%)]\tLoss: 0.541607\nTrain Epoch: 3 [170000/248297 (68%)]\tLoss: 0.539794\nTrain Epoch: 3 [171000/248297 (69%)]\tLoss: 0.421637\nTrain Epoch: 3 [172000/248297 (69%)]\tLoss: 0.585321\nTrain Epoch: 3 [173000/248297 (70%)]\tLoss: 0.522380\nTrain Epoch: 3 [174000/248297 (70%)]\tLoss: 0.505380\nTrain Epoch: 3 [175000/248297 (71%)]\tLoss: 0.571967\nTrain Epoch: 3 [176000/248297 (71%)]\tLoss: 0.515806\nTrain Epoch: 3 [177000/248297 (71%)]\tLoss: 0.497601\nTrain Epoch: 3 [178000/248297 (72%)]\tLoss: 0.494125\nTrain Epoch: 3 [179000/248297 (72%)]\tLoss: 0.541797\nTrain Epoch: 3 [180000/248297 (73%)]\tLoss: 0.500995\nTrain Epoch: 3 [181000/248297 (73%)]\tLoss: 0.516318\nTrain Epoch: 3 [182000/248297 (73%)]\tLoss: 0.505371\nTrain Epoch: 3 [183000/248297 (74%)]\tLoss: 0.529150\nTrain Epoch: 3 [184000/248297 (74%)]\tLoss: 0.524549\nTrain Epoch: 3 [185000/248297 (75%)]\tLoss: 0.487346\nTrain Epoch: 3 [186000/248297 (75%)]\tLoss: 0.494140\nTrain Epoch: 3 [187000/248297 (75%)]\tLoss: 0.575412\nTrain Epoch: 3 [188000/248297 (76%)]\tLoss: 0.457902\nTrain Epoch: 3 [189000/248297 (76%)]\tLoss: 0.586689\nTrain Epoch: 3 [190000/248297 (77%)]\tLoss: 0.554805\nTrain Epoch: 3 [191000/248297 (77%)]\tLoss: 0.531903\nTrain Epoch: 3 [192000/248297 (77%)]\tLoss: 0.505144\nTrain Epoch: 3 [193000/248297 (78%)]\tLoss: 0.563211\nTrain Epoch: 3 [194000/248297 (78%)]\tLoss: 0.639562\nTrain Epoch: 3 [195000/248297 (79%)]\tLoss: 0.523349\nTrain Epoch: 3 [196000/248297 (79%)]\tLoss: 0.531193\nTrain Epoch: 3 [197000/248297 (79%)]\tLoss: 0.529159\nTrain Epoch: 3 [198000/248297 (80%)]\tLoss: 0.535939\nTrain Epoch: 3 [199000/248297 (80%)]\tLoss: 0.590268\nTrain Epoch: 3 [200000/248297 (81%)]\tLoss: 0.553130\nTrain Epoch: 3 [201000/248297 (81%)]\tLoss: 0.425741\nTrain Epoch: 3 [202000/248297 (81%)]\tLoss: 0.462842\nTrain Epoch: 3 [203000/248297 (82%)]\tLoss: 0.626067\nTrain Epoch: 3 [204000/248297 (82%)]\tLoss: 0.470558\nTrain Epoch: 3 [205000/248297 (83%)]\tLoss: 0.513172\nTrain Epoch: 3 [206000/248297 (83%)]\tLoss: 0.484395\nTrain Epoch: 3 [207000/248297 (83%)]\tLoss: 0.508402\nTrain Epoch: 3 [208000/248297 (84%)]\tLoss: 0.602763\nTrain Epoch: 3 [209000/248297 (84%)]\tLoss: 0.657123\nTrain Epoch: 3 [210000/248297 (85%)]\tLoss: 0.434985\nTrain Epoch: 3 [211000/248297 (85%)]\tLoss: 0.483202\nTrain Epoch: 3 [212000/248297 (85%)]\tLoss: 0.557166\nTrain Epoch: 3 [213000/248297 (86%)]\tLoss: 0.597865\nTrain Epoch: 3 [214000/248297 (86%)]\tLoss: 0.468782\nTrain Epoch: 3 [215000/248297 (87%)]\tLoss: 0.581058\nTrain Epoch: 3 [216000/248297 (87%)]\tLoss: 0.513639\nTrain Epoch: 3 [217000/248297 (87%)]\tLoss: 0.472629\nTrain Epoch: 3 [218000/248297 (88%)]\tLoss: 0.490867\nTrain Epoch: 3 [219000/248297 (88%)]\tLoss: 0.578505\nTrain Epoch: 3 [220000/248297 (89%)]\tLoss: 0.518279\nTrain Epoch: 3 [221000/248297 (89%)]\tLoss: 0.501159\nTrain Epoch: 3 [222000/248297 (89%)]\tLoss: 0.535952\nTrain Epoch: 3 [223000/248297 (90%)]\tLoss: 0.563105\nTrain Epoch: 3 [224000/248297 (90%)]\tLoss: 0.461427\nTrain Epoch: 3 [225000/248297 (91%)]\tLoss: 0.431675\nTrain Epoch: 3 [226000/248297 (91%)]\tLoss: 0.553660\nTrain Epoch: 3 [227000/248297 (91%)]\tLoss: 0.503710\nTrain Epoch: 3 [228000/248297 (92%)]\tLoss: 0.529040\nTrain Epoch: 3 [229000/248297 (92%)]\tLoss: 0.566841\nTrain Epoch: 3 [230000/248297 (93%)]\tLoss: 0.529900\nTrain Epoch: 3 [231000/248297 (93%)]\tLoss: 0.425426\nTrain Epoch: 3 [232000/248297 (93%)]\tLoss: 0.543709\nTrain Epoch: 3 [233000/248297 (94%)]\tLoss: 0.442443\nTrain Epoch: 3 [234000/248297 (94%)]\tLoss: 0.491919\nTrain Epoch: 3 [235000/248297 (95%)]\tLoss: 0.530717\nTrain Epoch: 3 [236000/248297 (95%)]\tLoss: 0.450019\nTrain Epoch: 3 [237000/248297 (95%)]\tLoss: 0.459309\nTrain Epoch: 3 [238000/248297 (96%)]\tLoss: 0.452774\nTrain Epoch: 3 [239000/248297 (96%)]\tLoss: 0.506321\nTrain Epoch: 3 [240000/248297 (97%)]\tLoss: 0.548745\nTrain Epoch: 3 [241000/248297 (97%)]\tLoss: 0.498195\nTrain Epoch: 3 [242000/248297 (98%)]\tLoss: 0.548951\nTrain Epoch: 3 [243000/248297 (98%)]\tLoss: 0.495695\nTrain Epoch: 3 [244000/248297 (98%)]\tLoss: 0.505169\nTrain Epoch: 3 [245000/248297 (99%)]\tLoss: 0.577437\nTrain Epoch: 3 [246000/248297 (99%)]\tLoss: 0.476071\nTrain Epoch: 3 [247000/248297 (100%)]\tLoss: 0.543191\nTrain Epoch: 3 [248000/248297 (100%)]\tLoss: 0.519221\n\nTest set: Average loss: 0.0052, Accuracy: 20244/27589 (73%)\n\nTrain Epoch: 4 [0/248297 (0%)]\tLoss: 0.501944\nTrain Epoch: 4 [1000/248297 (0%)]\tLoss: 0.507708\nTrain Epoch: 4 [2000/248297 (1%)]\tLoss: 0.522527\nTrain Epoch: 4 [3000/248297 (1%)]\tLoss: 0.426582\nTrain Epoch: 4 [4000/248297 (2%)]\tLoss: 0.545767\nTrain Epoch: 4 [5000/248297 (2%)]\tLoss: 0.531934\nTrain Epoch: 4 [6000/248297 (2%)]\tLoss: 0.478154\nTrain Epoch: 4 [7000/248297 (3%)]\tLoss: 0.555744\nTrain Epoch: 4 [8000/248297 (3%)]\tLoss: 0.399837\nTrain Epoch: 4 [9000/248297 (4%)]\tLoss: 0.529020\nTrain Epoch: 4 [10000/248297 (4%)]\tLoss: 0.528121\nTrain Epoch: 4 [11000/248297 (4%)]\tLoss: 0.544840\nTrain Epoch: 4 [12000/248297 (5%)]\tLoss: 0.498247\nTrain Epoch: 4 [13000/248297 (5%)]\tLoss: 0.527327\nTrain Epoch: 4 [14000/248297 (6%)]\tLoss: 0.485848\nTrain Epoch: 4 [15000/248297 (6%)]\tLoss: 0.637807\nTrain Epoch: 4 [16000/248297 (6%)]\tLoss: 0.504771\nTrain Epoch: 4 [17000/248297 (7%)]\tLoss: 0.491530\nTrain Epoch: 4 [18000/248297 (7%)]\tLoss: 0.529298\nTrain Epoch: 4 [19000/248297 (8%)]\tLoss: 0.479752\nTrain Epoch: 4 [20000/248297 (8%)]\tLoss: 0.487145\nTrain Epoch: 4 [21000/248297 (8%)]\tLoss: 0.456017\nTrain Epoch: 4 [22000/248297 (9%)]\tLoss: 0.507156\nTrain Epoch: 4 [23000/248297 (9%)]\tLoss: 0.559076\nTrain Epoch: 4 [24000/248297 (10%)]\tLoss: 0.597410\nTrain Epoch: 4 [25000/248297 (10%)]\tLoss: 0.496675\nTrain Epoch: 4 [26000/248297 (10%)]\tLoss: 0.651088\nTrain Epoch: 4 [27000/248297 (11%)]\tLoss: 0.481544\nTrain Epoch: 4 [28000/248297 (11%)]\tLoss: 0.496411\nTrain Epoch: 4 [29000/248297 (12%)]\tLoss: 0.502106\nTrain Epoch: 4 [30000/248297 (12%)]\tLoss: 0.578652\nTrain Epoch: 4 [31000/248297 (12%)]\tLoss: 0.515015\nTrain Epoch: 4 [32000/248297 (13%)]\tLoss: 0.461918\nTrain Epoch: 4 [33000/248297 (13%)]\tLoss: 0.534044\nTrain Epoch: 4 [34000/248297 (14%)]\tLoss: 0.535264\nTrain Epoch: 4 [35000/248297 (14%)]\tLoss: 0.567517\nTrain Epoch: 4 [36000/248297 (15%)]\tLoss: 0.666362\nTrain Epoch: 4 [37000/248297 (15%)]\tLoss: 0.625029\nTrain Epoch: 4 [38000/248297 (15%)]\tLoss: 0.442037\nTrain Epoch: 4 [39000/248297 (16%)]\tLoss: 0.589533\nTrain Epoch: 4 [40000/248297 (16%)]\tLoss: 0.445524\nTrain Epoch: 4 [41000/248297 (17%)]\tLoss: 0.483954\nTrain Epoch: 4 [42000/248297 (17%)]\tLoss: 0.496212\nTrain Epoch: 4 [43000/248297 (17%)]\tLoss: 0.466876\nTrain Epoch: 4 [44000/248297 (18%)]\tLoss: 0.539861\nTrain Epoch: 4 [45000/248297 (18%)]\tLoss: 0.494516\nTrain Epoch: 4 [46000/248297 (19%)]\tLoss: 0.467778\nTrain Epoch: 4 [47000/248297 (19%)]\tLoss: 0.482250\nTrain Epoch: 4 [48000/248297 (19%)]\tLoss: 0.427817\nTrain Epoch: 4 [49000/248297 (20%)]\tLoss: 0.587243\nTrain Epoch: 4 [50000/248297 (20%)]\tLoss: 0.535140\nTrain Epoch: 4 [51000/248297 (21%)]\tLoss: 0.478643\nTrain Epoch: 4 [52000/248297 (21%)]\tLoss: 0.522556\nTrain Epoch: 4 [53000/248297 (21%)]\tLoss: 0.518149\nTrain Epoch: 4 [54000/248297 (22%)]\tLoss: 0.432634\nTrain Epoch: 4 [55000/248297 (22%)]\tLoss: 0.434110\nTrain Epoch: 4 [56000/248297 (23%)]\tLoss: 0.465795\nTrain Epoch: 4 [57000/248297 (23%)]\tLoss: 0.527314\nTrain Epoch: 4 [58000/248297 (23%)]\tLoss: 0.504985\nTrain Epoch: 4 [59000/248297 (24%)]\tLoss: 0.486356\nTrain Epoch: 4 [60000/248297 (24%)]\tLoss: 0.544356\nTrain Epoch: 4 [61000/248297 (25%)]\tLoss: 0.578182\nTrain Epoch: 4 [62000/248297 (25%)]\tLoss: 0.529254\nTrain Epoch: 4 [63000/248297 (25%)]\tLoss: 0.595028\nTrain Epoch: 4 [64000/248297 (26%)]\tLoss: 0.462356\nTrain Epoch: 4 [65000/248297 (26%)]\tLoss: 0.445952\nTrain Epoch: 4 [66000/248297 (27%)]\tLoss: 0.422627\nTrain Epoch: 4 [67000/248297 (27%)]\tLoss: 0.521914\nTrain Epoch: 4 [68000/248297 (27%)]\tLoss: 0.575098\nTrain Epoch: 4 [69000/248297 (28%)]\tLoss: 0.605388\nTrain Epoch: 4 [70000/248297 (28%)]\tLoss: 0.485006\nTrain Epoch: 4 [71000/248297 (29%)]\tLoss: 0.485674\nTrain Epoch: 4 [72000/248297 (29%)]\tLoss: 0.584981\nTrain Epoch: 4 [73000/248297 (29%)]\tLoss: 0.438279\nTrain Epoch: 4 [74000/248297 (30%)]\tLoss: 0.528667\nTrain Epoch: 4 [75000/248297 (30%)]\tLoss: 0.526195\nTrain Epoch: 4 [76000/248297 (31%)]\tLoss: 0.466236\nTrain Epoch: 4 [77000/248297 (31%)]\tLoss: 0.649223\nTrain Epoch: 4 [78000/248297 (31%)]\tLoss: 0.440454\nTrain Epoch: 4 [79000/248297 (32%)]\tLoss: 0.528242\nTrain Epoch: 4 [80000/248297 (32%)]\tLoss: 0.543367\nTrain Epoch: 4 [81000/248297 (33%)]\tLoss: 0.583610\nTrain Epoch: 4 [82000/248297 (33%)]\tLoss: 0.419428\nTrain Epoch: 4 [83000/248297 (33%)]\tLoss: 0.449841\nTrain Epoch: 4 [84000/248297 (34%)]\tLoss: 0.545249\nTrain Epoch: 4 [85000/248297 (34%)]\tLoss: 0.566316\nTrain Epoch: 4 [86000/248297 (35%)]\tLoss: 0.463347\nTrain Epoch: 4 [87000/248297 (35%)]\tLoss: 0.518163\nTrain Epoch: 4 [88000/248297 (35%)]\tLoss: 0.530742\nTrain Epoch: 4 [89000/248297 (36%)]\tLoss: 0.638904\nTrain Epoch: 4 [90000/248297 (36%)]\tLoss: 0.578021\nTrain Epoch: 4 [91000/248297 (37%)]\tLoss: 0.503046\nTrain Epoch: 4 [92000/248297 (37%)]\tLoss: 0.498886\nTrain Epoch: 4 [93000/248297 (37%)]\tLoss: 0.540805\nTrain Epoch: 4 [94000/248297 (38%)]\tLoss: 0.542667\nTrain Epoch: 4 [95000/248297 (38%)]\tLoss: 0.548400\nTrain Epoch: 4 [96000/248297 (39%)]\tLoss: 0.496170\nTrain Epoch: 4 [97000/248297 (39%)]\tLoss: 0.461087\nTrain Epoch: 4 [98000/248297 (39%)]\tLoss: 0.418959\nTrain Epoch: 4 [99000/248297 (40%)]\tLoss: 0.596120\nTrain Epoch: 4 [100000/248297 (40%)]\tLoss: 0.458795\nTrain Epoch: 4 [101000/248297 (41%)]\tLoss: 0.484061\nTrain Epoch: 4 [102000/248297 (41%)]\tLoss: 0.495128\nTrain Epoch: 4 [103000/248297 (41%)]\tLoss: 0.465765\nTrain Epoch: 4 [104000/248297 (42%)]\tLoss: 0.596035\nTrain Epoch: 4 [105000/248297 (42%)]\tLoss: 0.508873\nTrain Epoch: 4 [106000/248297 (43%)]\tLoss: 0.562584\nTrain Epoch: 4 [107000/248297 (43%)]\tLoss: 0.541594\nTrain Epoch: 4 [108000/248297 (44%)]\tLoss: 0.528669\nTrain Epoch: 4 [109000/248297 (44%)]\tLoss: 0.393773\nTrain Epoch: 4 [110000/248297 (44%)]\tLoss: 0.451269\nTrain Epoch: 4 [111000/248297 (45%)]\tLoss: 0.507901\nTrain Epoch: 4 [112000/248297 (45%)]\tLoss: 0.533276\nTrain Epoch: 4 [113000/248297 (46%)]\tLoss: 0.511013\nTrain Epoch: 4 [114000/248297 (46%)]\tLoss: 0.533866\nTrain Epoch: 4 [115000/248297 (46%)]\tLoss: 0.478516\nTrain Epoch: 4 [116000/248297 (47%)]\tLoss: 0.540367\nTrain Epoch: 4 [117000/248297 (47%)]\tLoss: 0.612176\nTrain Epoch: 4 [118000/248297 (48%)]\tLoss: 0.467846\nTrain Epoch: 4 [119000/248297 (48%)]\tLoss: 0.550412\nTrain Epoch: 4 [120000/248297 (48%)]\tLoss: 0.532867\nTrain Epoch: 4 [121000/248297 (49%)]\tLoss: 0.463526\nTrain Epoch: 4 [122000/248297 (49%)]\tLoss: 0.622182\nTrain Epoch: 4 [123000/248297 (50%)]\tLoss: 0.572874\nTrain Epoch: 4 [124000/248297 (50%)]\tLoss: 0.515501\nTrain Epoch: 4 [125000/248297 (50%)]\tLoss: 0.454234\nTrain Epoch: 4 [126000/248297 (51%)]\tLoss: 0.513901\nTrain Epoch: 4 [127000/248297 (51%)]\tLoss: 0.573621\nTrain Epoch: 4 [128000/248297 (52%)]\tLoss: 0.540787\nTrain Epoch: 4 [129000/248297 (52%)]\tLoss: 0.566040\nTrain Epoch: 4 [130000/248297 (52%)]\tLoss: 0.614908\nTrain Epoch: 4 [131000/248297 (53%)]\tLoss: 0.435104\nTrain Epoch: 4 [132000/248297 (53%)]\tLoss: 0.501147\nTrain Epoch: 4 [133000/248297 (54%)]\tLoss: 0.475154\nTrain Epoch: 4 [134000/248297 (54%)]\tLoss: 0.484546\nTrain Epoch: 4 [135000/248297 (54%)]\tLoss: 0.510795\nTrain Epoch: 4 [136000/248297 (55%)]\tLoss: 0.566751\nTrain Epoch: 4 [137000/248297 (55%)]\tLoss: 0.557437\nTrain Epoch: 4 [138000/248297 (56%)]\tLoss: 0.439553\nTrain Epoch: 4 [139000/248297 (56%)]\tLoss: 0.519792\nTrain Epoch: 4 [140000/248297 (56%)]\tLoss: 0.468173\nTrain Epoch: 4 [141000/248297 (57%)]\tLoss: 0.470145\nTrain Epoch: 4 [142000/248297 (57%)]\tLoss: 0.712834\nTrain Epoch: 4 [143000/248297 (58%)]\tLoss: 0.601613\nTrain Epoch: 4 [144000/248297 (58%)]\tLoss: 0.514600\nTrain Epoch: 4 [145000/248297 (58%)]\tLoss: 0.442090\nTrain Epoch: 4 [146000/248297 (59%)]\tLoss: 0.474187\nTrain Epoch: 4 [147000/248297 (59%)]\tLoss: 0.495926\nTrain Epoch: 4 [148000/248297 (60%)]\tLoss: 0.513771\nTrain Epoch: 4 [149000/248297 (60%)]\tLoss: 0.500720\nTrain Epoch: 4 [150000/248297 (60%)]\tLoss: 0.515648\nTrain Epoch: 4 [151000/248297 (61%)]\tLoss: 0.514776\nTrain Epoch: 4 [152000/248297 (61%)]\tLoss: 0.535628\nTrain Epoch: 4 [153000/248297 (62%)]\tLoss: 0.583997\nTrain Epoch: 4 [154000/248297 (62%)]\tLoss: 0.514638\nTrain Epoch: 4 [155000/248297 (62%)]\tLoss: 0.493338\nTrain Epoch: 4 [156000/248297 (63%)]\tLoss: 0.479871\nTrain Epoch: 4 [157000/248297 (63%)]\tLoss: 0.534511\nTrain Epoch: 4 [158000/248297 (64%)]\tLoss: 0.508496\nTrain Epoch: 4 [159000/248297 (64%)]\tLoss: 0.476759\nTrain Epoch: 4 [160000/248297 (64%)]\tLoss: 0.541409\nTrain Epoch: 4 [161000/248297 (65%)]\tLoss: 0.463074\nTrain Epoch: 4 [162000/248297 (65%)]\tLoss: 0.478240\nTrain Epoch: 4 [163000/248297 (66%)]\tLoss: 0.498182\nTrain Epoch: 4 [164000/248297 (66%)]\tLoss: 0.583694\nTrain Epoch: 4 [165000/248297 (66%)]\tLoss: 0.553948\nTrain Epoch: 4 [166000/248297 (67%)]\tLoss: 0.475329\nTrain Epoch: 4 [167000/248297 (67%)]\tLoss: 0.529685\nTrain Epoch: 4 [168000/248297 (68%)]\tLoss: 0.423780\nTrain Epoch: 4 [169000/248297 (68%)]\tLoss: 0.481375\nTrain Epoch: 4 [170000/248297 (68%)]\tLoss: 0.464760\nTrain Epoch: 4 [171000/248297 (69%)]\tLoss: 0.530533\nTrain Epoch: 4 [172000/248297 (69%)]\tLoss: 0.519401\nTrain Epoch: 4 [173000/248297 (70%)]\tLoss: 0.502408\nTrain Epoch: 4 [174000/248297 (70%)]\tLoss: 0.525732\nTrain Epoch: 4 [175000/248297 (71%)]\tLoss: 0.509761\nTrain Epoch: 4 [176000/248297 (71%)]\tLoss: 0.491356\nTrain Epoch: 4 [177000/248297 (71%)]\tLoss: 0.481171\nTrain Epoch: 4 [178000/248297 (72%)]\tLoss: 0.484578\nTrain Epoch: 4 [179000/248297 (72%)]\tLoss: 0.523965\nTrain Epoch: 4 [180000/248297 (73%)]\tLoss: 0.683003\nTrain Epoch: 4 [181000/248297 (73%)]\tLoss: 0.482590\nTrain Epoch: 4 [182000/248297 (73%)]\tLoss: 0.483029\nTrain Epoch: 4 [183000/248297 (74%)]\tLoss: 0.488750\nTrain Epoch: 4 [184000/248297 (74%)]\tLoss: 0.518258\nTrain Epoch: 4 [185000/248297 (75%)]\tLoss: 0.524988\nTrain Epoch: 4 [186000/248297 (75%)]\tLoss: 0.536235\nTrain Epoch: 4 [187000/248297 (75%)]\tLoss: 0.563610\nTrain Epoch: 4 [188000/248297 (76%)]\tLoss: 0.463267\nTrain Epoch: 4 [189000/248297 (76%)]\tLoss: 0.531637\nTrain Epoch: 4 [190000/248297 (77%)]\tLoss: 0.531210\nTrain Epoch: 4 [191000/248297 (77%)]\tLoss: 0.491554\nTrain Epoch: 4 [192000/248297 (77%)]\tLoss: 0.494542\nTrain Epoch: 4 [193000/248297 (78%)]\tLoss: 0.558749\nTrain Epoch: 4 [194000/248297 (78%)]\tLoss: 0.512550\nTrain Epoch: 4 [195000/248297 (79%)]\tLoss: 0.484858\nTrain Epoch: 4 [196000/248297 (79%)]\tLoss: 0.553472\nTrain Epoch: 4 [197000/248297 (79%)]\tLoss: 0.510061\nTrain Epoch: 4 [198000/248297 (80%)]\tLoss: 0.564366\nTrain Epoch: 4 [199000/248297 (80%)]\tLoss: 0.481105\nTrain Epoch: 4 [200000/248297 (81%)]\tLoss: 0.559040\nTrain Epoch: 4 [201000/248297 (81%)]\tLoss: 0.499507\nTrain Epoch: 4 [202000/248297 (81%)]\tLoss: 0.515359\nTrain Epoch: 4 [203000/248297 (82%)]\tLoss: 0.512552\nTrain Epoch: 4 [204000/248297 (82%)]\tLoss: 0.483247\nTrain Epoch: 4 [205000/248297 (83%)]\tLoss: 0.451242\nTrain Epoch: 4 [206000/248297 (83%)]\tLoss: 0.623289\nTrain Epoch: 4 [207000/248297 (83%)]\tLoss: 0.425911\nTrain Epoch: 4 [208000/248297 (84%)]\tLoss: 0.515589\nTrain Epoch: 4 [209000/248297 (84%)]\tLoss: 0.490214\nTrain Epoch: 4 [210000/248297 (85%)]\tLoss: 0.507211\nTrain Epoch: 4 [211000/248297 (85%)]\tLoss: 0.551786\nTrain Epoch: 4 [212000/248297 (85%)]\tLoss: 0.496654\nTrain Epoch: 4 [213000/248297 (86%)]\tLoss: 0.532645\nTrain Epoch: 4 [214000/248297 (86%)]\tLoss: 0.510227\nTrain Epoch: 4 [215000/248297 (87%)]\tLoss: 0.560362\nTrain Epoch: 4 [216000/248297 (87%)]\tLoss: 0.585220\nTrain Epoch: 4 [217000/248297 (87%)]\tLoss: 0.490126\nTrain Epoch: 4 [218000/248297 (88%)]\tLoss: 0.528863\nTrain Epoch: 4 [219000/248297 (88%)]\tLoss: 0.457649\nTrain Epoch: 4 [220000/248297 (89%)]\tLoss: 0.490209\nTrain Epoch: 4 [221000/248297 (89%)]\tLoss: 0.633714\nTrain Epoch: 4 [222000/248297 (89%)]\tLoss: 0.461818\nTrain Epoch: 4 [223000/248297 (90%)]\tLoss: 0.544731\nTrain Epoch: 4 [224000/248297 (90%)]\tLoss: 0.411262\nTrain Epoch: 4 [225000/248297 (91%)]\tLoss: 0.520712\nTrain Epoch: 4 [226000/248297 (91%)]\tLoss: 0.451065\nTrain Epoch: 4 [227000/248297 (91%)]\tLoss: 0.612179\nTrain Epoch: 4 [228000/248297 (92%)]\tLoss: 0.502692\nTrain Epoch: 4 [229000/248297 (92%)]\tLoss: 0.507675\nTrain Epoch: 4 [230000/248297 (93%)]\tLoss: 0.587812\nTrain Epoch: 4 [231000/248297 (93%)]\tLoss: 0.533703\nTrain Epoch: 4 [232000/248297 (93%)]\tLoss: 0.501195\nTrain Epoch: 4 [233000/248297 (94%)]\tLoss: 0.602686\nTrain Epoch: 4 [234000/248297 (94%)]\tLoss: 0.443729\nTrain Epoch: 4 [235000/248297 (95%)]\tLoss: 0.512263\nTrain Epoch: 4 [236000/248297 (95%)]\tLoss: 0.538112\nTrain Epoch: 4 [237000/248297 (95%)]\tLoss: 0.512335\nTrain Epoch: 4 [238000/248297 (96%)]\tLoss: 0.515028\nTrain Epoch: 4 [239000/248297 (96%)]\tLoss: 0.516703\nTrain Epoch: 4 [240000/248297 (97%)]\tLoss: 0.504659\nTrain Epoch: 4 [241000/248297 (97%)]\tLoss: 0.435273\nTrain Epoch: 4 [242000/248297 (98%)]\tLoss: 0.414209\nTrain Epoch: 4 [243000/248297 (98%)]\tLoss: 0.493872\nTrain Epoch: 4 [244000/248297 (98%)]\tLoss: 0.457355\nTrain Epoch: 4 [245000/248297 (99%)]\tLoss: 0.433577\nTrain Epoch: 4 [246000/248297 (99%)]\tLoss: 0.603998\nTrain Epoch: 4 [247000/248297 (100%)]\tLoss: 0.664481\nTrain Epoch: 4 [248000/248297 (100%)]\tLoss: 0.558815\n\nTest set: Average loss: 0.0052, Accuracy: 20419/27589 (74%)\n\nTrain Epoch: 5 [0/248297 (0%)]\tLoss: 0.599481\nTrain Epoch: 5 [1000/248297 (0%)]\tLoss: 0.533917\nTrain Epoch: 5 [2000/248297 (1%)]\tLoss: 0.454518\nTrain Epoch: 5 [3000/248297 (1%)]\tLoss: 0.486067\nTrain Epoch: 5 [4000/248297 (2%)]\tLoss: 0.482938\nTrain Epoch: 5 [5000/248297 (2%)]\tLoss: 0.512534\nTrain Epoch: 5 [6000/248297 (2%)]\tLoss: 0.445849\nTrain Epoch: 5 [7000/248297 (3%)]\tLoss: 0.558520\nTrain Epoch: 5 [8000/248297 (3%)]\tLoss: 0.482069\nTrain Epoch: 5 [9000/248297 (4%)]\tLoss: 0.522082\nTrain Epoch: 5 [10000/248297 (4%)]\tLoss: 0.486211\nTrain Epoch: 5 [11000/248297 (4%)]\tLoss: 0.527478\nTrain Epoch: 5 [12000/248297 (5%)]\tLoss: 0.502419\nTrain Epoch: 5 [13000/248297 (5%)]\tLoss: 0.444820\nTrain Epoch: 5 [14000/248297 (6%)]\tLoss: 0.555796\nTrain Epoch: 5 [15000/248297 (6%)]\tLoss: 0.410935\nTrain Epoch: 5 [16000/248297 (6%)]\tLoss: 0.484049\nTrain Epoch: 5 [17000/248297 (7%)]\tLoss: 0.556557\nTrain Epoch: 5 [18000/248297 (7%)]\tLoss: 0.507757\nTrain Epoch: 5 [19000/248297 (8%)]\tLoss: 0.495283\nTrain Epoch: 5 [20000/248297 (8%)]\tLoss: 0.546842\nTrain Epoch: 5 [21000/248297 (8%)]\tLoss: 0.453117\nTrain Epoch: 5 [22000/248297 (9%)]\tLoss: 0.506538\nTrain Epoch: 5 [23000/248297 (9%)]\tLoss: 0.623743\nTrain Epoch: 5 [24000/248297 (10%)]\tLoss: 0.493210\nTrain Epoch: 5 [25000/248297 (10%)]\tLoss: 0.497669\nTrain Epoch: 5 [26000/248297 (10%)]\tLoss: 0.506772\nTrain Epoch: 5 [27000/248297 (11%)]\tLoss: 0.478157\nTrain Epoch: 5 [28000/248297 (11%)]\tLoss: 0.515138\nTrain Epoch: 5 [29000/248297 (12%)]\tLoss: 0.506951\nTrain Epoch: 5 [30000/248297 (12%)]\tLoss: 0.528687\nTrain Epoch: 5 [31000/248297 (12%)]\tLoss: 0.632286\nTrain Epoch: 5 [32000/248297 (13%)]\tLoss: 0.464304\nTrain Epoch: 5 [33000/248297 (13%)]\tLoss: 0.423880\nTrain Epoch: 5 [34000/248297 (14%)]\tLoss: 0.579656\nTrain Epoch: 5 [35000/248297 (14%)]\tLoss: 0.407406\nTrain Epoch: 5 [36000/248297 (15%)]\tLoss: 0.493749\nTrain Epoch: 5 [37000/248297 (15%)]\tLoss: 0.524521\nTrain Epoch: 5 [38000/248297 (15%)]\tLoss: 0.527987\nTrain Epoch: 5 [39000/248297 (16%)]\tLoss: 0.463194\nTrain Epoch: 5 [40000/248297 (16%)]\tLoss: 0.532681\nTrain Epoch: 5 [41000/248297 (17%)]\tLoss: 0.540357\nTrain Epoch: 5 [42000/248297 (17%)]\tLoss: 0.598586\nTrain Epoch: 5 [43000/248297 (17%)]\tLoss: 0.656363\nTrain Epoch: 5 [44000/248297 (18%)]\tLoss: 0.514078\nTrain Epoch: 5 [45000/248297 (18%)]\tLoss: 0.494345\nTrain Epoch: 5 [46000/248297 (19%)]\tLoss: 0.482175\nTrain Epoch: 5 [47000/248297 (19%)]\tLoss: 0.552946\nTrain Epoch: 5 [48000/248297 (19%)]\tLoss: 0.494980\nTrain Epoch: 5 [49000/248297 (20%)]\tLoss: 0.427824\nTrain Epoch: 5 [50000/248297 (20%)]\tLoss: 0.538686\nTrain Epoch: 5 [51000/248297 (21%)]\tLoss: 0.572249\nTrain Epoch: 5 [52000/248297 (21%)]\tLoss: 0.455020\nTrain Epoch: 5 [53000/248297 (21%)]\tLoss: 0.616899\nTrain Epoch: 5 [54000/248297 (22%)]\tLoss: 0.574638\nTrain Epoch: 5 [55000/248297 (22%)]\tLoss: 0.462755\nTrain Epoch: 5 [56000/248297 (23%)]\tLoss: 0.578284\nTrain Epoch: 5 [57000/248297 (23%)]\tLoss: 0.508738\nTrain Epoch: 5 [58000/248297 (23%)]\tLoss: 0.450460\nTrain Epoch: 5 [59000/248297 (24%)]\tLoss: 0.435841\nTrain Epoch: 5 [60000/248297 (24%)]\tLoss: 0.533706\nTrain Epoch: 5 [61000/248297 (25%)]\tLoss: 0.556077\nTrain Epoch: 5 [62000/248297 (25%)]\tLoss: 0.397791\nTrain Epoch: 5 [63000/248297 (25%)]\tLoss: 0.466864\nTrain Epoch: 5 [64000/248297 (26%)]\tLoss: 0.504085\nTrain Epoch: 5 [65000/248297 (26%)]\tLoss: 0.506798\nTrain Epoch: 5 [66000/248297 (27%)]\tLoss: 0.558160\nTrain Epoch: 5 [67000/248297 (27%)]\tLoss: 0.507921\nTrain Epoch: 5 [68000/248297 (27%)]\tLoss: 0.572970\nTrain Epoch: 5 [69000/248297 (28%)]\tLoss: 0.507262\nTrain Epoch: 5 [70000/248297 (28%)]\tLoss: 0.515511\nTrain Epoch: 5 [71000/248297 (29%)]\tLoss: 0.561593\nTrain Epoch: 5 [72000/248297 (29%)]\tLoss: 0.537001\nTrain Epoch: 5 [73000/248297 (29%)]\tLoss: 0.512091\nTrain Epoch: 5 [74000/248297 (30%)]\tLoss: 0.472066\nTrain Epoch: 5 [75000/248297 (30%)]\tLoss: 0.488874\nTrain Epoch: 5 [76000/248297 (31%)]\tLoss: 0.507291\nTrain Epoch: 5 [77000/248297 (31%)]\tLoss: 0.596647\nTrain Epoch: 5 [78000/248297 (31%)]\tLoss: 0.586379\nTrain Epoch: 5 [79000/248297 (32%)]\tLoss: 0.587377\nTrain Epoch: 5 [80000/248297 (32%)]\tLoss: 0.473764\nTrain Epoch: 5 [81000/248297 (33%)]\tLoss: 0.557481\nTrain Epoch: 5 [82000/248297 (33%)]\tLoss: 0.456951\nTrain Epoch: 5 [83000/248297 (33%)]\tLoss: 0.533270\nTrain Epoch: 5 [84000/248297 (34%)]\tLoss: 0.454675\nTrain Epoch: 5 [85000/248297 (34%)]\tLoss: 0.520347\nTrain Epoch: 5 [86000/248297 (35%)]\tLoss: 0.477003\nTrain Epoch: 5 [87000/248297 (35%)]\tLoss: 0.526017\nTrain Epoch: 5 [88000/248297 (35%)]\tLoss: 0.494235\nTrain Epoch: 5 [89000/248297 (36%)]\tLoss: 0.575837\nTrain Epoch: 5 [90000/248297 (36%)]\tLoss: 0.502317\nTrain Epoch: 5 [91000/248297 (37%)]\tLoss: 0.492947\nTrain Epoch: 5 [92000/248297 (37%)]\tLoss: 0.550422\nTrain Epoch: 5 [93000/248297 (37%)]\tLoss: 0.503986\nTrain Epoch: 5 [94000/248297 (38%)]\tLoss: 0.502663\nTrain Epoch: 5 [95000/248297 (38%)]\tLoss: 0.585029\nTrain Epoch: 5 [96000/248297 (39%)]\tLoss: 0.477215\nTrain Epoch: 5 [97000/248297 (39%)]\tLoss: 0.384800\nTrain Epoch: 5 [98000/248297 (39%)]\tLoss: 0.485060\nTrain Epoch: 5 [99000/248297 (40%)]\tLoss: 0.409169\nTrain Epoch: 5 [100000/248297 (40%)]\tLoss: 0.457490\nTrain Epoch: 5 [101000/248297 (41%)]\tLoss: 0.494697\nTrain Epoch: 5 [102000/248297 (41%)]\tLoss: 0.488416\nTrain Epoch: 5 [103000/248297 (41%)]\tLoss: 0.487098\nTrain Epoch: 5 [104000/248297 (42%)]\tLoss: 0.510716\nTrain Epoch: 5 [105000/248297 (42%)]\tLoss: 0.518783\nTrain Epoch: 5 [106000/248297 (43%)]\tLoss: 0.472679\nTrain Epoch: 5 [107000/248297 (43%)]\tLoss: 0.369434\nTrain Epoch: 5 [108000/248297 (44%)]\tLoss: 0.429751\nTrain Epoch: 5 [109000/248297 (44%)]\tLoss: 0.547378\nTrain Epoch: 5 [110000/248297 (44%)]\tLoss: 0.521139\nTrain Epoch: 5 [111000/248297 (45%)]\tLoss: 0.599297\nTrain Epoch: 5 [112000/248297 (45%)]\tLoss: 0.500390\nTrain Epoch: 5 [113000/248297 (46%)]\tLoss: 0.527204\nTrain Epoch: 5 [114000/248297 (46%)]\tLoss: 0.523428\nTrain Epoch: 5 [115000/248297 (46%)]\tLoss: 0.582199\nTrain Epoch: 5 [116000/248297 (47%)]\tLoss: 0.512118\nTrain Epoch: 5 [117000/248297 (47%)]\tLoss: 0.522809\nTrain Epoch: 5 [118000/248297 (48%)]\tLoss: 0.482963\nTrain Epoch: 5 [119000/248297 (48%)]\tLoss: 0.519128\nTrain Epoch: 5 [120000/248297 (48%)]\tLoss: 0.481605\nTrain Epoch: 5 [121000/248297 (49%)]\tLoss: 0.464694\nTrain Epoch: 5 [122000/248297 (49%)]\tLoss: 0.523604\nTrain Epoch: 5 [123000/248297 (50%)]\tLoss: 0.498201\nTrain Epoch: 5 [124000/248297 (50%)]\tLoss: 0.445072\nTrain Epoch: 5 [125000/248297 (50%)]\tLoss: 0.463034\nTrain Epoch: 5 [126000/248297 (51%)]\tLoss: 0.504642\nTrain Epoch: 5 [127000/248297 (51%)]\tLoss: 0.602172\nTrain Epoch: 5 [128000/248297 (52%)]\tLoss: 0.485104\nTrain Epoch: 5 [129000/248297 (52%)]\tLoss: 0.563205\nTrain Epoch: 5 [130000/248297 (52%)]\tLoss: 0.517895\nTrain Epoch: 5 [131000/248297 (53%)]\tLoss: 0.510708\nTrain Epoch: 5 [132000/248297 (53%)]\tLoss: 0.420531\nTrain Epoch: 5 [133000/248297 (54%)]\tLoss: 0.496042\nTrain Epoch: 5 [134000/248297 (54%)]\tLoss: 0.496236\nTrain Epoch: 5 [135000/248297 (54%)]\tLoss: 0.420414\nTrain Epoch: 5 [136000/248297 (55%)]\tLoss: 0.596790\nTrain Epoch: 5 [137000/248297 (55%)]\tLoss: 0.528282\nTrain Epoch: 5 [138000/248297 (56%)]\tLoss: 0.546910\nTrain Epoch: 5 [139000/248297 (56%)]\tLoss: 0.498737\nTrain Epoch: 5 [140000/248297 (56%)]\tLoss: 0.531047\nTrain Epoch: 5 [141000/248297 (57%)]\tLoss: 0.522950\nTrain Epoch: 5 [142000/248297 (57%)]\tLoss: 0.496218\nTrain Epoch: 5 [143000/248297 (58%)]\tLoss: 0.508682\nTrain Epoch: 5 [144000/248297 (58%)]\tLoss: 0.553477\nTrain Epoch: 5 [145000/248297 (58%)]\tLoss: 0.529104\nTrain Epoch: 5 [146000/248297 (59%)]\tLoss: 0.589171\nTrain Epoch: 5 [147000/248297 (59%)]\tLoss: 0.502449\nTrain Epoch: 5 [148000/248297 (60%)]\tLoss: 0.515982\nTrain Epoch: 5 [149000/248297 (60%)]\tLoss: 0.556830\nTrain Epoch: 5 [150000/248297 (60%)]\tLoss: 0.499823\nTrain Epoch: 5 [151000/248297 (61%)]\tLoss: 0.523040\nTrain Epoch: 5 [152000/248297 (61%)]\tLoss: 0.537050\nTrain Epoch: 5 [153000/248297 (62%)]\tLoss: 0.569324\nTrain Epoch: 5 [154000/248297 (62%)]\tLoss: 0.412204\nTrain Epoch: 5 [155000/248297 (62%)]\tLoss: 0.540260\nTrain Epoch: 5 [156000/248297 (63%)]\tLoss: 0.626517\nTrain Epoch: 5 [157000/248297 (63%)]\tLoss: 0.458996\nTrain Epoch: 5 [158000/248297 (64%)]\tLoss: 0.418051\nTrain Epoch: 5 [159000/248297 (64%)]\tLoss: 0.521704\nTrain Epoch: 5 [160000/248297 (64%)]\tLoss: 0.505006\nTrain Epoch: 5 [161000/248297 (65%)]\tLoss: 0.516026\nTrain Epoch: 5 [162000/248297 (65%)]\tLoss: 0.495424\nTrain Epoch: 5 [163000/248297 (66%)]\tLoss: 0.438629\nTrain Epoch: 5 [164000/248297 (66%)]\tLoss: 0.474596\nTrain Epoch: 5 [165000/248297 (66%)]\tLoss: 0.567293\nTrain Epoch: 5 [166000/248297 (67%)]\tLoss: 0.494236\nTrain Epoch: 5 [167000/248297 (67%)]\tLoss: 0.425188\nTrain Epoch: 5 [168000/248297 (68%)]\tLoss: 0.594558\nTrain Epoch: 5 [169000/248297 (68%)]\tLoss: 0.507478\nTrain Epoch: 5 [170000/248297 (68%)]\tLoss: 0.543991\nTrain Epoch: 5 [171000/248297 (69%)]\tLoss: 0.557095\nTrain Epoch: 5 [172000/248297 (69%)]\tLoss: 0.489053\nTrain Epoch: 5 [173000/248297 (70%)]\tLoss: 0.486063\nTrain Epoch: 5 [174000/248297 (70%)]\tLoss: 0.513135\nTrain Epoch: 5 [175000/248297 (71%)]\tLoss: 0.473951\nTrain Epoch: 5 [176000/248297 (71%)]\tLoss: 0.496427\nTrain Epoch: 5 [177000/248297 (71%)]\tLoss: 0.474024\nTrain Epoch: 5 [178000/248297 (72%)]\tLoss: 0.464717\nTrain Epoch: 5 [179000/248297 (72%)]\tLoss: 0.437241\nTrain Epoch: 5 [180000/248297 (73%)]\tLoss: 0.450778\nTrain Epoch: 5 [181000/248297 (73%)]\tLoss: 0.540639\nTrain Epoch: 5 [182000/248297 (73%)]\tLoss: 0.479518\nTrain Epoch: 5 [183000/248297 (74%)]\tLoss: 0.472425\nTrain Epoch: 5 [184000/248297 (74%)]\tLoss: 0.492880\nTrain Epoch: 5 [185000/248297 (75%)]\tLoss: 0.553227\nTrain Epoch: 5 [186000/248297 (75%)]\tLoss: 0.560894\nTrain Epoch: 5 [187000/248297 (75%)]\tLoss: 0.467462\nTrain Epoch: 5 [188000/248297 (76%)]\tLoss: 0.528551\nTrain Epoch: 5 [189000/248297 (76%)]\tLoss: 0.454864\nTrain Epoch: 5 [190000/248297 (77%)]\tLoss: 0.462474\nTrain Epoch: 5 [191000/248297 (77%)]\tLoss: 0.493436\nTrain Epoch: 5 [192000/248297 (77%)]\tLoss: 0.507318\nTrain Epoch: 5 [193000/248297 (78%)]\tLoss: 0.549864\nTrain Epoch: 5 [194000/248297 (78%)]\tLoss: 0.500564\nTrain Epoch: 5 [195000/248297 (79%)]\tLoss: 0.484549\nTrain Epoch: 5 [196000/248297 (79%)]\tLoss: 0.532315\nTrain Epoch: 5 [197000/248297 (79%)]\tLoss: 0.508586\nTrain Epoch: 5 [198000/248297 (80%)]\tLoss: 0.567628\nTrain Epoch: 5 [199000/248297 (80%)]\tLoss: 0.510647\nTrain Epoch: 5 [200000/248297 (81%)]\tLoss: 0.465632\nTrain Epoch: 5 [201000/248297 (81%)]\tLoss: 0.547381\nTrain Epoch: 5 [202000/248297 (81%)]\tLoss: 0.448382\nTrain Epoch: 5 [203000/248297 (82%)]\tLoss: 0.536250\nTrain Epoch: 5 [204000/248297 (82%)]\tLoss: 0.496481\nTrain Epoch: 5 [205000/248297 (83%)]\tLoss: 0.530065\nTrain Epoch: 5 [206000/248297 (83%)]\tLoss: 0.538491\nTrain Epoch: 5 [207000/248297 (83%)]\tLoss: 0.490265\nTrain Epoch: 5 [208000/248297 (84%)]\tLoss: 0.560453\nTrain Epoch: 5 [209000/248297 (84%)]\tLoss: 0.525906\nTrain Epoch: 5 [210000/248297 (85%)]\tLoss: 0.536847\nTrain Epoch: 5 [211000/248297 (85%)]\tLoss: 0.531645\nTrain Epoch: 5 [212000/248297 (85%)]\tLoss: 0.515077\nTrain Epoch: 5 [213000/248297 (86%)]\tLoss: 0.602206\nTrain Epoch: 5 [214000/248297 (86%)]\tLoss: 0.487554\nTrain Epoch: 5 [215000/248297 (87%)]\tLoss: 0.555473\nTrain Epoch: 5 [216000/248297 (87%)]\tLoss: 0.448169\nTrain Epoch: 5 [217000/248297 (87%)]\tLoss: 0.599826\nTrain Epoch: 5 [218000/248297 (88%)]\tLoss: 0.600137\nTrain Epoch: 5 [219000/248297 (88%)]\tLoss: 0.527498\nTrain Epoch: 5 [220000/248297 (89%)]\tLoss: 0.458142\nTrain Epoch: 5 [221000/248297 (89%)]\tLoss: 0.468472\nTrain Epoch: 5 [222000/248297 (89%)]\tLoss: 0.510597\nTrain Epoch: 5 [223000/248297 (90%)]\tLoss: 0.483713\nTrain Epoch: 5 [224000/248297 (90%)]\tLoss: 0.431638\nTrain Epoch: 5 [225000/248297 (91%)]\tLoss: 0.444590\nTrain Epoch: 5 [226000/248297 (91%)]\tLoss: 0.537031\nTrain Epoch: 5 [227000/248297 (91%)]\tLoss: 0.503621\nTrain Epoch: 5 [228000/248297 (92%)]\tLoss: 0.459235\nTrain Epoch: 5 [229000/248297 (92%)]\tLoss: 0.518707\nTrain Epoch: 5 [230000/248297 (93%)]\tLoss: 0.459531\nTrain Epoch: 5 [231000/248297 (93%)]\tLoss: 0.523618\nTrain Epoch: 5 [232000/248297 (93%)]\tLoss: 0.511943\nTrain Epoch: 5 [233000/248297 (94%)]\tLoss: 0.456096\nTrain Epoch: 5 [234000/248297 (94%)]\tLoss: 0.563289\nTrain Epoch: 5 [235000/248297 (95%)]\tLoss: 0.480266\nTrain Epoch: 5 [236000/248297 (95%)]\tLoss: 0.485696\nTrain Epoch: 5 [237000/248297 (95%)]\tLoss: 0.457750\nTrain Epoch: 5 [238000/248297 (96%)]\tLoss: 0.534650\nTrain Epoch: 5 [239000/248297 (96%)]\tLoss: 0.468228\nTrain Epoch: 5 [240000/248297 (97%)]\tLoss: 0.479785\nTrain Epoch: 5 [241000/248297 (97%)]\tLoss: 0.485917\nTrain Epoch: 5 [242000/248297 (98%)]\tLoss: 0.482943\nTrain Epoch: 5 [243000/248297 (98%)]\tLoss: 0.557271\nTrain Epoch: 5 [244000/248297 (98%)]\tLoss: 0.457710\nTrain Epoch: 5 [245000/248297 (99%)]\tLoss: 0.512610\nTrain Epoch: 5 [246000/248297 (99%)]\tLoss: 0.468634\nTrain Epoch: 5 [247000/248297 (100%)]\tLoss: 0.478709\nTrain Epoch: 5 [248000/248297 (100%)]\tLoss: 0.580963\n\nTest set: Average loss: 0.0051, Accuracy: 20521/27589 (74%)\n\nTrain Epoch: 6 [0/248297 (0%)]\tLoss: 0.389020\nTrain Epoch: 6 [1000/248297 (0%)]\tLoss: 0.445080\nTrain Epoch: 6 [2000/248297 (1%)]\tLoss: 0.480589\nTrain Epoch: 6 [3000/248297 (1%)]\tLoss: 0.421198\nTrain Epoch: 6 [4000/248297 (2%)]\tLoss: 0.517374\nTrain Epoch: 6 [5000/248297 (2%)]\tLoss: 0.520619\nTrain Epoch: 6 [6000/248297 (2%)]\tLoss: 0.477996\nTrain Epoch: 6 [7000/248297 (3%)]\tLoss: 0.642719\nTrain Epoch: 6 [8000/248297 (3%)]\tLoss: 0.463582\nTrain Epoch: 6 [9000/248297 (4%)]\tLoss: 0.495762\nTrain Epoch: 6 [10000/248297 (4%)]\tLoss: 0.510879\nTrain Epoch: 6 [11000/248297 (4%)]\tLoss: 0.498674\nTrain Epoch: 6 [12000/248297 (5%)]\tLoss: 0.513927\nTrain Epoch: 6 [13000/248297 (5%)]\tLoss: 0.451099\nTrain Epoch: 6 [14000/248297 (6%)]\tLoss: 0.508114\nTrain Epoch: 6 [15000/248297 (6%)]\tLoss: 0.404413\nTrain Epoch: 6 [16000/248297 (6%)]\tLoss: 0.591082\nTrain Epoch: 6 [17000/248297 (7%)]\tLoss: 0.558075\nTrain Epoch: 6 [18000/248297 (7%)]\tLoss: 0.534727\nTrain Epoch: 6 [19000/248297 (8%)]\tLoss: 0.421885\nTrain Epoch: 6 [20000/248297 (8%)]\tLoss: 0.410360\nTrain Epoch: 6 [21000/248297 (8%)]\tLoss: 0.503295\nTrain Epoch: 6 [22000/248297 (9%)]\tLoss: 0.500675\nTrain Epoch: 6 [23000/248297 (9%)]\tLoss: 0.613846\nTrain Epoch: 6 [24000/248297 (10%)]\tLoss: 0.441186\nTrain Epoch: 6 [25000/248297 (10%)]\tLoss: 0.523628\nTrain Epoch: 6 [26000/248297 (10%)]\tLoss: 0.528745\nTrain Epoch: 6 [27000/248297 (11%)]\tLoss: 0.448440\nTrain Epoch: 6 [28000/248297 (11%)]\tLoss: 0.461381\nTrain Epoch: 6 [29000/248297 (12%)]\tLoss: 0.470794\nTrain Epoch: 6 [30000/248297 (12%)]\tLoss: 0.518104\nTrain Epoch: 6 [31000/248297 (12%)]\tLoss: 0.544812\nTrain Epoch: 6 [32000/248297 (13%)]\tLoss: 0.455837\nTrain Epoch: 6 [33000/248297 (13%)]\tLoss: 0.469276\nTrain Epoch: 6 [34000/248297 (14%)]\tLoss: 0.548891\nTrain Epoch: 6 [35000/248297 (14%)]\tLoss: 0.461071\nTrain Epoch: 6 [36000/248297 (15%)]\tLoss: 0.554143\nTrain Epoch: 6 [37000/248297 (15%)]\tLoss: 0.496116\nTrain Epoch: 6 [38000/248297 (15%)]\tLoss: 0.483301\nTrain Epoch: 6 [39000/248297 (16%)]\tLoss: 0.530426\nTrain Epoch: 6 [40000/248297 (16%)]\tLoss: 0.474426\nTrain Epoch: 6 [41000/248297 (17%)]\tLoss: 0.459874\nTrain Epoch: 6 [42000/248297 (17%)]\tLoss: 0.494333\nTrain Epoch: 6 [43000/248297 (17%)]\tLoss: 0.555400\nTrain Epoch: 6 [44000/248297 (18%)]\tLoss: 0.468452\nTrain Epoch: 6 [45000/248297 (18%)]\tLoss: 0.542251\nTrain Epoch: 6 [46000/248297 (19%)]\tLoss: 0.515103\nTrain Epoch: 6 [47000/248297 (19%)]\tLoss: 0.506214\nTrain Epoch: 6 [48000/248297 (19%)]\tLoss: 0.503723\nTrain Epoch: 6 [49000/248297 (20%)]\tLoss: 0.463169\nTrain Epoch: 6 [50000/248297 (20%)]\tLoss: 0.593608\nTrain Epoch: 6 [51000/248297 (21%)]\tLoss: 0.523989\nTrain Epoch: 6 [52000/248297 (21%)]\tLoss: 0.433734\nTrain Epoch: 6 [53000/248297 (21%)]\tLoss: 0.527840\nTrain Epoch: 6 [54000/248297 (22%)]\tLoss: 0.499758\nTrain Epoch: 6 [55000/248297 (22%)]\tLoss: 0.480044\nTrain Epoch: 6 [56000/248297 (23%)]\tLoss: 0.406391\nTrain Epoch: 6 [57000/248297 (23%)]\tLoss: 0.559136\nTrain Epoch: 6 [58000/248297 (23%)]\tLoss: 0.494657\nTrain Epoch: 6 [59000/248297 (24%)]\tLoss: 0.467389\nTrain Epoch: 6 [60000/248297 (24%)]\tLoss: 0.427897\nTrain Epoch: 6 [61000/248297 (25%)]\tLoss: 0.479996\nTrain Epoch: 6 [62000/248297 (25%)]\tLoss: 0.440515\nTrain Epoch: 6 [63000/248297 (25%)]\tLoss: 0.470080\nTrain Epoch: 6 [64000/248297 (26%)]\tLoss: 0.436602\nTrain Epoch: 6 [65000/248297 (26%)]\tLoss: 0.448329\nTrain Epoch: 6 [66000/248297 (27%)]\tLoss: 0.594976\nTrain Epoch: 6 [67000/248297 (27%)]\tLoss: 0.513590\nTrain Epoch: 6 [68000/248297 (27%)]\tLoss: 0.388100\nTrain Epoch: 6 [69000/248297 (28%)]\tLoss: 0.522571\nTrain Epoch: 6 [70000/248297 (28%)]\tLoss: 0.506578\nTrain Epoch: 6 [71000/248297 (29%)]\tLoss: 0.515433\nTrain Epoch: 6 [72000/248297 (29%)]\tLoss: 0.497732\nTrain Epoch: 6 [73000/248297 (29%)]\tLoss: 0.516596\nTrain Epoch: 6 [74000/248297 (30%)]\tLoss: 0.591699\nTrain Epoch: 6 [75000/248297 (30%)]\tLoss: 0.561355\nTrain Epoch: 6 [76000/248297 (31%)]\tLoss: 0.514190\nTrain Epoch: 6 [77000/248297 (31%)]\tLoss: 0.530295\nTrain Epoch: 6 [78000/248297 (31%)]\tLoss: 0.555427\nTrain Epoch: 6 [79000/248297 (32%)]\tLoss: 0.443463\nTrain Epoch: 6 [80000/248297 (32%)]\tLoss: 0.546109\nTrain Epoch: 6 [81000/248297 (33%)]\tLoss: 0.461983\nTrain Epoch: 6 [82000/248297 (33%)]\tLoss: 0.523980\nTrain Epoch: 6 [83000/248297 (33%)]\tLoss: 0.570533\nTrain Epoch: 6 [84000/248297 (34%)]\tLoss: 0.480968\nTrain Epoch: 6 [85000/248297 (34%)]\tLoss: 0.540886\nTrain Epoch: 6 [86000/248297 (35%)]\tLoss: 0.588496\nTrain Epoch: 6 [87000/248297 (35%)]\tLoss: 0.436697\nTrain Epoch: 6 [88000/248297 (35%)]\tLoss: 0.477032\nTrain Epoch: 6 [89000/248297 (36%)]\tLoss: 0.501167\nTrain Epoch: 6 [90000/248297 (36%)]\tLoss: 0.560381\nTrain Epoch: 6 [91000/248297 (37%)]\tLoss: 0.540928\nTrain Epoch: 6 [92000/248297 (37%)]\tLoss: 0.476629\nTrain Epoch: 6 [93000/248297 (37%)]\tLoss: 0.492151\nTrain Epoch: 6 [94000/248297 (38%)]\tLoss: 0.490921\nTrain Epoch: 6 [95000/248297 (38%)]\tLoss: 0.469849\nTrain Epoch: 6 [96000/248297 (39%)]\tLoss: 0.518627\nTrain Epoch: 6 [97000/248297 (39%)]\tLoss: 0.479783\nTrain Epoch: 6 [98000/248297 (39%)]\tLoss: 0.538683\nTrain Epoch: 6 [99000/248297 (40%)]\tLoss: 0.479653\nTrain Epoch: 6 [100000/248297 (40%)]\tLoss: 0.501541\nTrain Epoch: 6 [101000/248297 (41%)]\tLoss: 0.564285\nTrain Epoch: 6 [102000/248297 (41%)]\tLoss: 0.488954\nTrain Epoch: 6 [103000/248297 (41%)]\tLoss: 0.449716\nTrain Epoch: 6 [104000/248297 (42%)]\tLoss: 0.508696\nTrain Epoch: 6 [105000/248297 (42%)]\tLoss: 0.489200\nTrain Epoch: 6 [106000/248297 (43%)]\tLoss: 0.540903\nTrain Epoch: 6 [107000/248297 (43%)]\tLoss: 0.398631\nTrain Epoch: 6 [108000/248297 (44%)]\tLoss: 0.558849\nTrain Epoch: 6 [109000/248297 (44%)]\tLoss: 0.436564\nTrain Epoch: 6 [110000/248297 (44%)]\tLoss: 0.442119\nTrain Epoch: 6 [111000/248297 (45%)]\tLoss: 0.467359\nTrain Epoch: 6 [112000/248297 (45%)]\tLoss: 0.561994\nTrain Epoch: 6 [113000/248297 (46%)]\tLoss: 0.496562\nTrain Epoch: 6 [114000/248297 (46%)]\tLoss: 0.522788\nTrain Epoch: 6 [115000/248297 (46%)]\tLoss: 0.474591\nTrain Epoch: 6 [116000/248297 (47%)]\tLoss: 0.497044\nTrain Epoch: 6 [117000/248297 (47%)]\tLoss: 0.461134\nTrain Epoch: 6 [118000/248297 (48%)]\tLoss: 0.478409\nTrain Epoch: 6 [119000/248297 (48%)]\tLoss: 0.526947\nTrain Epoch: 6 [120000/248297 (48%)]\tLoss: 0.511803\nTrain Epoch: 6 [121000/248297 (49%)]\tLoss: 0.484079\nTrain Epoch: 6 [122000/248297 (49%)]\tLoss: 0.432234\nTrain Epoch: 6 [123000/248297 (50%)]\tLoss: 0.543854\nTrain Epoch: 6 [124000/248297 (50%)]\tLoss: 0.551005\nTrain Epoch: 6 [125000/248297 (50%)]\tLoss: 0.541804\nTrain Epoch: 6 [126000/248297 (51%)]\tLoss: 0.581901\nTrain Epoch: 6 [127000/248297 (51%)]\tLoss: 0.472589\nTrain Epoch: 6 [128000/248297 (52%)]\tLoss: 0.552747\nTrain Epoch: 6 [129000/248297 (52%)]\tLoss: 0.549002\nTrain Epoch: 6 [130000/248297 (52%)]\tLoss: 0.542100\nTrain Epoch: 6 [131000/248297 (53%)]\tLoss: 0.536799\nTrain Epoch: 6 [132000/248297 (53%)]\tLoss: 0.557820\nTrain Epoch: 6 [133000/248297 (54%)]\tLoss: 0.369580\nTrain Epoch: 6 [134000/248297 (54%)]\tLoss: 0.434681\nTrain Epoch: 6 [135000/248297 (54%)]\tLoss: 0.456385\nTrain Epoch: 6 [136000/248297 (55%)]\tLoss: 0.528899\nTrain Epoch: 6 [137000/248297 (55%)]\tLoss: 0.564845\nTrain Epoch: 6 [138000/248297 (56%)]\tLoss: 0.490854\nTrain Epoch: 6 [139000/248297 (56%)]\tLoss: 0.482274\nTrain Epoch: 6 [140000/248297 (56%)]\tLoss: 0.574838\nTrain Epoch: 6 [141000/248297 (57%)]\tLoss: 0.496327\nTrain Epoch: 6 [142000/248297 (57%)]\tLoss: 0.531912\nTrain Epoch: 6 [143000/248297 (58%)]\tLoss: 0.489235\nTrain Epoch: 6 [144000/248297 (58%)]\tLoss: 0.543959\nTrain Epoch: 6 [145000/248297 (58%)]\tLoss: 0.473796\nTrain Epoch: 6 [146000/248297 (59%)]\tLoss: 0.471812\nTrain Epoch: 6 [147000/248297 (59%)]\tLoss: 0.467826\nTrain Epoch: 6 [148000/248297 (60%)]\tLoss: 0.443836\nTrain Epoch: 6 [149000/248297 (60%)]\tLoss: 0.485928\nTrain Epoch: 6 [150000/248297 (60%)]\tLoss: 0.466254\nTrain Epoch: 6 [151000/248297 (61%)]\tLoss: 0.471628\nTrain Epoch: 6 [152000/248297 (61%)]\tLoss: 0.574929\nTrain Epoch: 6 [153000/248297 (62%)]\tLoss: 0.548109\nTrain Epoch: 6 [154000/248297 (62%)]\tLoss: 0.524355\nTrain Epoch: 6 [155000/248297 (62%)]\tLoss: 0.485787\nTrain Epoch: 6 [156000/248297 (63%)]\tLoss: 0.524460\nTrain Epoch: 6 [157000/248297 (63%)]\tLoss: 0.591983\nTrain Epoch: 6 [158000/248297 (64%)]\tLoss: 0.436974\nTrain Epoch: 6 [159000/248297 (64%)]\tLoss: 0.500142\nTrain Epoch: 6 [160000/248297 (64%)]\tLoss: 0.503423\nTrain Epoch: 6 [161000/248297 (65%)]\tLoss: 0.455451\nTrain Epoch: 6 [162000/248297 (65%)]\tLoss: 0.501083\nTrain Epoch: 6 [163000/248297 (66%)]\tLoss: 0.501007\nTrain Epoch: 6 [164000/248297 (66%)]\tLoss: 0.550885\nTrain Epoch: 6 [165000/248297 (66%)]\tLoss: 0.545236\nTrain Epoch: 6 [166000/248297 (67%)]\tLoss: 0.486589\nTrain Epoch: 6 [167000/248297 (67%)]\tLoss: 0.476022\nTrain Epoch: 6 [168000/248297 (68%)]\tLoss: 0.527135\nTrain Epoch: 6 [169000/248297 (68%)]\tLoss: 0.465874\nTrain Epoch: 6 [170000/248297 (68%)]\tLoss: 0.543759\nTrain Epoch: 6 [171000/248297 (69%)]\tLoss: 0.474246\nTrain Epoch: 6 [172000/248297 (69%)]\tLoss: 0.536201\nTrain Epoch: 6 [173000/248297 (70%)]\tLoss: 0.519008\nTrain Epoch: 6 [174000/248297 (70%)]\tLoss: 0.446374\nTrain Epoch: 6 [175000/248297 (71%)]\tLoss: 0.442660\nTrain Epoch: 6 [176000/248297 (71%)]\tLoss: 0.471845\nTrain Epoch: 6 [177000/248297 (71%)]\tLoss: 0.476576\nTrain Epoch: 6 [178000/248297 (72%)]\tLoss: 0.406999\nTrain Epoch: 6 [179000/248297 (72%)]\tLoss: 0.505082\nTrain Epoch: 6 [180000/248297 (73%)]\tLoss: 0.550638\nTrain Epoch: 6 [181000/248297 (73%)]\tLoss: 0.400301\nTrain Epoch: 6 [182000/248297 (73%)]\tLoss: 0.495231\nTrain Epoch: 6 [183000/248297 (74%)]\tLoss: 0.503438\nTrain Epoch: 6 [184000/248297 (74%)]\tLoss: 0.506388\nTrain Epoch: 6 [185000/248297 (75%)]\tLoss: 0.552732\nTrain Epoch: 6 [186000/248297 (75%)]\tLoss: 0.498284\nTrain Epoch: 6 [187000/248297 (75%)]\tLoss: 0.517431\nTrain Epoch: 6 [188000/248297 (76%)]\tLoss: 0.442890\nTrain Epoch: 6 [189000/248297 (76%)]\tLoss: 0.466491\nTrain Epoch: 6 [190000/248297 (77%)]\tLoss: 0.525236\nTrain Epoch: 6 [191000/248297 (77%)]\tLoss: 0.573245\nTrain Epoch: 6 [192000/248297 (77%)]\tLoss: 0.436098\nTrain Epoch: 6 [193000/248297 (78%)]\tLoss: 0.479829\nTrain Epoch: 6 [194000/248297 (78%)]\tLoss: 0.450543\nTrain Epoch: 6 [195000/248297 (79%)]\tLoss: 0.457824\nTrain Epoch: 6 [196000/248297 (79%)]\tLoss: 0.450930\nTrain Epoch: 6 [197000/248297 (79%)]\tLoss: 0.431900\nTrain Epoch: 6 [198000/248297 (80%)]\tLoss: 0.440111\nTrain Epoch: 6 [199000/248297 (80%)]\tLoss: 0.475742\nTrain Epoch: 6 [200000/248297 (81%)]\tLoss: 0.512292\nTrain Epoch: 6 [201000/248297 (81%)]\tLoss: 0.497886\nTrain Epoch: 6 [202000/248297 (81%)]\tLoss: 0.586166\nTrain Epoch: 6 [203000/248297 (82%)]\tLoss: 0.483403\nTrain Epoch: 6 [204000/248297 (82%)]\tLoss: 0.480453\nTrain Epoch: 6 [205000/248297 (83%)]\tLoss: 0.502130\nTrain Epoch: 6 [206000/248297 (83%)]\tLoss: 0.424671\nTrain Epoch: 6 [207000/248297 (83%)]\tLoss: 0.474271\nTrain Epoch: 6 [208000/248297 (84%)]\tLoss: 0.415563\nTrain Epoch: 6 [209000/248297 (84%)]\tLoss: 0.498041\nTrain Epoch: 6 [210000/248297 (85%)]\tLoss: 0.457954\nTrain Epoch: 6 [211000/248297 (85%)]\tLoss: 0.427609\nTrain Epoch: 6 [212000/248297 (85%)]\tLoss: 0.507760\nTrain Epoch: 6 [213000/248297 (86%)]\tLoss: 0.462625\nTrain Epoch: 6 [214000/248297 (86%)]\tLoss: 0.518562\nTrain Epoch: 6 [215000/248297 (87%)]\tLoss: 0.483852\nTrain Epoch: 6 [216000/248297 (87%)]\tLoss: 0.607378\nTrain Epoch: 6 [217000/248297 (87%)]\tLoss: 0.437167\nTrain Epoch: 6 [218000/248297 (88%)]\tLoss: 0.422543\nTrain Epoch: 6 [219000/248297 (88%)]\tLoss: 0.575963\nTrain Epoch: 6 [220000/248297 (89%)]\tLoss: 0.456581\nTrain Epoch: 6 [221000/248297 (89%)]\tLoss: 0.495514\nTrain Epoch: 6 [222000/248297 (89%)]\tLoss: 0.524557\nTrain Epoch: 6 [223000/248297 (90%)]\tLoss: 0.461041\nTrain Epoch: 6 [224000/248297 (90%)]\tLoss: 0.489583\nTrain Epoch: 6 [225000/248297 (91%)]\tLoss: 0.450688\nTrain Epoch: 6 [226000/248297 (91%)]\tLoss: 0.580305\nTrain Epoch: 6 [227000/248297 (91%)]\tLoss: 0.477968\nTrain Epoch: 6 [228000/248297 (92%)]\tLoss: 0.491040\nTrain Epoch: 6 [229000/248297 (92%)]\tLoss: 0.589581\nTrain Epoch: 6 [230000/248297 (93%)]\tLoss: 0.478524\nTrain Epoch: 6 [231000/248297 (93%)]\tLoss: 0.516239\nTrain Epoch: 6 [232000/248297 (93%)]\tLoss: 0.489841\nTrain Epoch: 6 [233000/248297 (94%)]\tLoss: 0.474636\nTrain Epoch: 6 [234000/248297 (94%)]\tLoss: 0.461667\nTrain Epoch: 6 [235000/248297 (95%)]\tLoss: 0.523812\nTrain Epoch: 6 [236000/248297 (95%)]\tLoss: 0.555521\nTrain Epoch: 6 [237000/248297 (95%)]\tLoss: 0.527156\nTrain Epoch: 6 [238000/248297 (96%)]\tLoss: 0.529928\nTrain Epoch: 6 [239000/248297 (96%)]\tLoss: 0.532066\nTrain Epoch: 6 [240000/248297 (97%)]\tLoss: 0.458934\nTrain Epoch: 6 [241000/248297 (97%)]\tLoss: 0.467645\nTrain Epoch: 6 [242000/248297 (98%)]\tLoss: 0.475465\nTrain Epoch: 6 [243000/248297 (98%)]\tLoss: 0.534199\nTrain Epoch: 6 [244000/248297 (98%)]\tLoss: 0.462961\nTrain Epoch: 6 [245000/248297 (99%)]\tLoss: 0.504152\nTrain Epoch: 6 [246000/248297 (99%)]\tLoss: 0.497307\nTrain Epoch: 6 [247000/248297 (100%)]\tLoss: 0.520736\nTrain Epoch: 6 [248000/248297 (100%)]\tLoss: 0.614120\n\nTest set: Average loss: 0.0051, Accuracy: 20569/27589 (75%)\n\nTrain Epoch: 7 [0/248297 (0%)]\tLoss: 0.530002\nTrain Epoch: 7 [1000/248297 (0%)]\tLoss: 0.483221\nTrain Epoch: 7 [2000/248297 (1%)]\tLoss: 0.467531\nTrain Epoch: 7 [3000/248297 (1%)]\tLoss: 0.365203\nTrain Epoch: 7 [4000/248297 (2%)]\tLoss: 0.466918\nTrain Epoch: 7 [5000/248297 (2%)]\tLoss: 0.494501\nTrain Epoch: 7 [6000/248297 (2%)]\tLoss: 0.407357\nTrain Epoch: 7 [7000/248297 (3%)]\tLoss: 0.394706\nTrain Epoch: 7 [8000/248297 (3%)]\tLoss: 0.540398\nTrain Epoch: 7 [9000/248297 (4%)]\tLoss: 0.584076\nTrain Epoch: 7 [10000/248297 (4%)]\tLoss: 0.522543\nTrain Epoch: 7 [11000/248297 (4%)]\tLoss: 0.511629\nTrain Epoch: 7 [12000/248297 (5%)]\tLoss: 0.519160\nTrain Epoch: 7 [13000/248297 (5%)]\tLoss: 0.571554\nTrain Epoch: 7 [14000/248297 (6%)]\tLoss: 0.444737\nTrain Epoch: 7 [15000/248297 (6%)]\tLoss: 0.472873\nTrain Epoch: 7 [16000/248297 (6%)]\tLoss: 0.472692\nTrain Epoch: 7 [17000/248297 (7%)]\tLoss: 0.531599\nTrain Epoch: 7 [18000/248297 (7%)]\tLoss: 0.508224\nTrain Epoch: 7 [19000/248297 (8%)]\tLoss: 0.430794\nTrain Epoch: 7 [20000/248297 (8%)]\tLoss: 0.469589\nTrain Epoch: 7 [21000/248297 (8%)]\tLoss: 0.490701\nTrain Epoch: 7 [22000/248297 (9%)]\tLoss: 0.483942\nTrain Epoch: 7 [23000/248297 (9%)]\tLoss: 0.403095\nTrain Epoch: 7 [24000/248297 (10%)]\tLoss: 0.426192\nTrain Epoch: 7 [25000/248297 (10%)]\tLoss: 0.520613\nTrain Epoch: 7 [26000/248297 (10%)]\tLoss: 0.459607\nTrain Epoch: 7 [27000/248297 (11%)]\tLoss: 0.524735\nTrain Epoch: 7 [28000/248297 (11%)]\tLoss: 0.593739\nTrain Epoch: 7 [29000/248297 (12%)]\tLoss: 0.473201\nTrain Epoch: 7 [30000/248297 (12%)]\tLoss: 0.488462\nTrain Epoch: 7 [31000/248297 (12%)]\tLoss: 0.603215\nTrain Epoch: 7 [32000/248297 (13%)]\tLoss: 0.487736\nTrain Epoch: 7 [33000/248297 (13%)]\tLoss: 0.501546\nTrain Epoch: 7 [34000/248297 (14%)]\tLoss: 0.484383\nTrain Epoch: 7 [35000/248297 (14%)]\tLoss: 0.499154\nTrain Epoch: 7 [36000/248297 (15%)]\tLoss: 0.451011\nTrain Epoch: 7 [37000/248297 (15%)]\tLoss: 0.485335\nTrain Epoch: 7 [38000/248297 (15%)]\tLoss: 0.521005\nTrain Epoch: 7 [39000/248297 (16%)]\tLoss: 0.503053\nTrain Epoch: 7 [40000/248297 (16%)]\tLoss: 0.409392\nTrain Epoch: 7 [41000/248297 (17%)]\tLoss: 0.500568\nTrain Epoch: 7 [42000/248297 (17%)]\tLoss: 0.597106\nTrain Epoch: 7 [43000/248297 (17%)]\tLoss: 0.452810\nTrain Epoch: 7 [44000/248297 (18%)]\tLoss: 0.428523\nTrain Epoch: 7 [45000/248297 (18%)]\tLoss: 0.539019\nTrain Epoch: 7 [46000/248297 (19%)]\tLoss: 0.496544\nTrain Epoch: 7 [47000/248297 (19%)]\tLoss: 0.485750\nTrain Epoch: 7 [48000/248297 (19%)]\tLoss: 0.417924\nTrain Epoch: 7 [49000/248297 (20%)]\tLoss: 0.515592\nTrain Epoch: 7 [50000/248297 (20%)]\tLoss: 0.455792\nTrain Epoch: 7 [51000/248297 (21%)]\tLoss: 0.547295\nTrain Epoch: 7 [52000/248297 (21%)]\tLoss: 0.434237\nTrain Epoch: 7 [53000/248297 (21%)]\tLoss: 0.488582\nTrain Epoch: 7 [54000/248297 (22%)]\tLoss: 0.516391\nTrain Epoch: 7 [55000/248297 (22%)]\tLoss: 0.448682\nTrain Epoch: 7 [56000/248297 (23%)]\tLoss: 0.559679\nTrain Epoch: 7 [57000/248297 (23%)]\tLoss: 0.486941\nTrain Epoch: 7 [58000/248297 (23%)]\tLoss: 0.537362\nTrain Epoch: 7 [59000/248297 (24%)]\tLoss: 0.524065\nTrain Epoch: 7 [60000/248297 (24%)]\tLoss: 0.537858\nTrain Epoch: 7 [61000/248297 (25%)]\tLoss: 0.458128\nTrain Epoch: 7 [62000/248297 (25%)]\tLoss: 0.599252\nTrain Epoch: 7 [63000/248297 (25%)]\tLoss: 0.518481\nTrain Epoch: 7 [64000/248297 (26%)]\tLoss: 0.530268\nTrain Epoch: 7 [65000/248297 (26%)]\tLoss: 0.453605\nTrain Epoch: 7 [66000/248297 (27%)]\tLoss: 0.492310\nTrain Epoch: 7 [67000/248297 (27%)]\tLoss: 0.482063\nTrain Epoch: 7 [68000/248297 (27%)]\tLoss: 0.494998\nTrain Epoch: 7 [69000/248297 (28%)]\tLoss: 0.427010\nTrain Epoch: 7 [70000/248297 (28%)]\tLoss: 0.506965\nTrain Epoch: 7 [71000/248297 (29%)]\tLoss: 0.476135\nTrain Epoch: 7 [72000/248297 (29%)]\tLoss: 0.541224\nTrain Epoch: 7 [73000/248297 (29%)]\tLoss: 0.503537\nTrain Epoch: 7 [74000/248297 (30%)]\tLoss: 0.440094\nTrain Epoch: 7 [75000/248297 (30%)]\tLoss: 0.640144\nTrain Epoch: 7 [76000/248297 (31%)]\tLoss: 0.453876\nTrain Epoch: 7 [77000/248297 (31%)]\tLoss: 0.383620\nTrain Epoch: 7 [78000/248297 (31%)]\tLoss: 0.499483\nTrain Epoch: 7 [79000/248297 (32%)]\tLoss: 0.487594\nTrain Epoch: 7 [80000/248297 (32%)]\tLoss: 0.411102\nTrain Epoch: 7 [81000/248297 (33%)]\tLoss: 0.489160\nTrain Epoch: 7 [82000/248297 (33%)]\tLoss: 0.407009\nTrain Epoch: 7 [83000/248297 (33%)]\tLoss: 0.444110\nTrain Epoch: 7 [84000/248297 (34%)]\tLoss: 0.478633\nTrain Epoch: 7 [85000/248297 (34%)]\tLoss: 0.495682\nTrain Epoch: 7 [86000/248297 (35%)]\tLoss: 0.595568\nTrain Epoch: 7 [87000/248297 (35%)]\tLoss: 0.477261\nTrain Epoch: 7 [88000/248297 (35%)]\tLoss: 0.410623\nTrain Epoch: 7 [89000/248297 (36%)]\tLoss: 0.525021\nTrain Epoch: 7 [90000/248297 (36%)]\tLoss: 0.586063\nTrain Epoch: 7 [91000/248297 (37%)]\tLoss: 0.531140\nTrain Epoch: 7 [92000/248297 (37%)]\tLoss: 0.456004\nTrain Epoch: 7 [93000/248297 (37%)]\tLoss: 0.502620\nTrain Epoch: 7 [94000/248297 (38%)]\tLoss: 0.486326\nTrain Epoch: 7 [95000/248297 (38%)]\tLoss: 0.466942\nTrain Epoch: 7 [96000/248297 (39%)]\tLoss: 0.482929\nTrain Epoch: 7 [97000/248297 (39%)]\tLoss: 0.520748\nTrain Epoch: 7 [98000/248297 (39%)]\tLoss: 0.386540\nTrain Epoch: 7 [99000/248297 (40%)]\tLoss: 0.468332\nTrain Epoch: 7 [100000/248297 (40%)]\tLoss: 0.563116\nTrain Epoch: 7 [101000/248297 (41%)]\tLoss: 0.484497\nTrain Epoch: 7 [102000/248297 (41%)]\tLoss: 0.472674\nTrain Epoch: 7 [103000/248297 (41%)]\tLoss: 0.389046\nTrain Epoch: 7 [104000/248297 (42%)]\tLoss: 0.495099\nTrain Epoch: 7 [105000/248297 (42%)]\tLoss: 0.494356\nTrain Epoch: 7 [106000/248297 (43%)]\tLoss: 0.527732\nTrain Epoch: 7 [107000/248297 (43%)]\tLoss: 0.431917\nTrain Epoch: 7 [108000/248297 (44%)]\tLoss: 0.508568\nTrain Epoch: 7 [109000/248297 (44%)]\tLoss: 0.539966\nTrain Epoch: 7 [110000/248297 (44%)]\tLoss: 0.493926\nTrain Epoch: 7 [111000/248297 (45%)]\tLoss: 0.499779\nTrain Epoch: 7 [112000/248297 (45%)]\tLoss: 0.560318\nTrain Epoch: 7 [113000/248297 (46%)]\tLoss: 0.441801\nTrain Epoch: 7 [114000/248297 (46%)]\tLoss: 0.491356\nTrain Epoch: 7 [115000/248297 (46%)]\tLoss: 0.531315\nTrain Epoch: 7 [116000/248297 (47%)]\tLoss: 0.434307\nTrain Epoch: 7 [117000/248297 (47%)]\tLoss: 0.458469\nTrain Epoch: 7 [118000/248297 (48%)]\tLoss: 0.422857\nTrain Epoch: 7 [119000/248297 (48%)]\tLoss: 0.595163\nTrain Epoch: 7 [120000/248297 (48%)]\tLoss: 0.562724\nTrain Epoch: 7 [121000/248297 (49%)]\tLoss: 0.486178\nTrain Epoch: 7 [122000/248297 (49%)]\tLoss: 0.644576\nTrain Epoch: 7 [123000/248297 (50%)]\tLoss: 0.542852\nTrain Epoch: 7 [124000/248297 (50%)]\tLoss: 0.504175\nTrain Epoch: 7 [125000/248297 (50%)]\tLoss: 0.459171\nTrain Epoch: 7 [126000/248297 (51%)]\tLoss: 0.479589\nTrain Epoch: 7 [127000/248297 (51%)]\tLoss: 0.548670\nTrain Epoch: 7 [128000/248297 (52%)]\tLoss: 0.492216\nTrain Epoch: 7 [129000/248297 (52%)]\tLoss: 0.512396\nTrain Epoch: 7 [130000/248297 (52%)]\tLoss: 0.531267\nTrain Epoch: 7 [131000/248297 (53%)]\tLoss: 0.509923\nTrain Epoch: 7 [132000/248297 (53%)]\tLoss: 0.508073\nTrain Epoch: 7 [133000/248297 (54%)]\tLoss: 0.546763\nTrain Epoch: 7 [134000/248297 (54%)]\tLoss: 0.545595\nTrain Epoch: 7 [135000/248297 (54%)]\tLoss: 0.474124\nTrain Epoch: 7 [136000/248297 (55%)]\tLoss: 0.460394\nTrain Epoch: 7 [137000/248297 (55%)]\tLoss: 0.491239\nTrain Epoch: 7 [138000/248297 (56%)]\tLoss: 0.497141\nTrain Epoch: 7 [139000/248297 (56%)]\tLoss: 0.477934\nTrain Epoch: 7 [140000/248297 (56%)]\tLoss: 0.435728\nTrain Epoch: 7 [141000/248297 (57%)]\tLoss: 0.442300\nTrain Epoch: 7 [142000/248297 (57%)]\tLoss: 0.567968\nTrain Epoch: 7 [143000/248297 (58%)]\tLoss: 0.433999\nTrain Epoch: 7 [144000/248297 (58%)]\tLoss: 0.419063\nTrain Epoch: 7 [145000/248297 (58%)]\tLoss: 0.507299\nTrain Epoch: 7 [146000/248297 (59%)]\tLoss: 0.499018\nTrain Epoch: 7 [147000/248297 (59%)]\tLoss: 0.395888\nTrain Epoch: 7 [148000/248297 (60%)]\tLoss: 0.446106\nTrain Epoch: 7 [149000/248297 (60%)]\tLoss: 0.468949\nTrain Epoch: 7 [150000/248297 (60%)]\tLoss: 0.446177\nTrain Epoch: 7 [151000/248297 (61%)]\tLoss: 0.384212\nTrain Epoch: 7 [152000/248297 (61%)]\tLoss: 0.534454\nTrain Epoch: 7 [153000/248297 (62%)]\tLoss: 0.495309\nTrain Epoch: 7 [154000/248297 (62%)]\tLoss: 0.528193\nTrain Epoch: 7 [155000/248297 (62%)]\tLoss: 0.604158\nTrain Epoch: 7 [156000/248297 (63%)]\tLoss: 0.461099\nTrain Epoch: 7 [157000/248297 (63%)]\tLoss: 0.472957\nTrain Epoch: 7 [158000/248297 (64%)]\tLoss: 0.526629\nTrain Epoch: 7 [159000/248297 (64%)]\tLoss: 0.610946\nTrain Epoch: 7 [160000/248297 (64%)]\tLoss: 0.493854\nTrain Epoch: 7 [161000/248297 (65%)]\tLoss: 0.448961\nTrain Epoch: 7 [162000/248297 (65%)]\tLoss: 0.576747\nTrain Epoch: 7 [163000/248297 (66%)]\tLoss: 0.566545\nTrain Epoch: 7 [164000/248297 (66%)]\tLoss: 0.472280\nTrain Epoch: 7 [165000/248297 (66%)]\tLoss: 0.474386\nTrain Epoch: 7 [166000/248297 (67%)]\tLoss: 0.429123\nTrain Epoch: 7 [167000/248297 (67%)]\tLoss: 0.587944\nTrain Epoch: 7 [168000/248297 (68%)]\tLoss: 0.437533\nTrain Epoch: 7 [169000/248297 (68%)]\tLoss: 0.554672\nTrain Epoch: 7 [170000/248297 (68%)]\tLoss: 0.495406\nTrain Epoch: 7 [171000/248297 (69%)]\tLoss: 0.544713\nTrain Epoch: 7 [172000/248297 (69%)]\tLoss: 0.539750\nTrain Epoch: 7 [173000/248297 (70%)]\tLoss: 0.422447\nTrain Epoch: 7 [174000/248297 (70%)]\tLoss: 0.490985\nTrain Epoch: 7 [175000/248297 (71%)]\tLoss: 0.451186\nTrain Epoch: 7 [176000/248297 (71%)]\tLoss: 0.513668\nTrain Epoch: 7 [177000/248297 (71%)]\tLoss: 0.446244\nTrain Epoch: 7 [178000/248297 (72%)]\tLoss: 0.571169\nTrain Epoch: 7 [179000/248297 (72%)]\tLoss: 0.395423\nTrain Epoch: 7 [180000/248297 (73%)]\tLoss: 0.523833\nTrain Epoch: 7 [181000/248297 (73%)]\tLoss: 0.498839\nTrain Epoch: 7 [182000/248297 (73%)]\tLoss: 0.556906\nTrain Epoch: 7 [183000/248297 (74%)]\tLoss: 0.509313\nTrain Epoch: 7 [184000/248297 (74%)]\tLoss: 0.443513\nTrain Epoch: 7 [185000/248297 (75%)]\tLoss: 0.487236\nTrain Epoch: 7 [186000/248297 (75%)]\tLoss: 0.465531\nTrain Epoch: 7 [187000/248297 (75%)]\tLoss: 0.558236\nTrain Epoch: 7 [188000/248297 (76%)]\tLoss: 0.467238\nTrain Epoch: 7 [189000/248297 (76%)]\tLoss: 0.534160\nTrain Epoch: 7 [190000/248297 (77%)]\tLoss: 0.482290\nTrain Epoch: 7 [191000/248297 (77%)]\tLoss: 0.523762\nTrain Epoch: 7 [192000/248297 (77%)]\tLoss: 0.499415\nTrain Epoch: 7 [193000/248297 (78%)]\tLoss: 0.465399\nTrain Epoch: 7 [194000/248297 (78%)]\tLoss: 0.445912\nTrain Epoch: 7 [195000/248297 (79%)]\tLoss: 0.510046\nTrain Epoch: 7 [196000/248297 (79%)]\tLoss: 0.527832\nTrain Epoch: 7 [197000/248297 (79%)]\tLoss: 0.533856\nTrain Epoch: 7 [198000/248297 (80%)]\tLoss: 0.492181\nTrain Epoch: 7 [199000/248297 (80%)]\tLoss: 0.468309\nTrain Epoch: 7 [200000/248297 (81%)]\tLoss: 0.454725\nTrain Epoch: 7 [201000/248297 (81%)]\tLoss: 0.495689\nTrain Epoch: 7 [202000/248297 (81%)]\tLoss: 0.539134\nTrain Epoch: 7 [203000/248297 (82%)]\tLoss: 0.544516\nTrain Epoch: 7 [204000/248297 (82%)]\tLoss: 0.415354\nTrain Epoch: 7 [205000/248297 (83%)]\tLoss: 0.459430\nTrain Epoch: 7 [206000/248297 (83%)]\tLoss: 0.437773\nTrain Epoch: 7 [207000/248297 (83%)]\tLoss: 0.546876\nTrain Epoch: 7 [208000/248297 (84%)]\tLoss: 0.427732\nTrain Epoch: 7 [209000/248297 (84%)]\tLoss: 0.551985\nTrain Epoch: 7 [210000/248297 (85%)]\tLoss: 0.459802\nTrain Epoch: 7 [211000/248297 (85%)]\tLoss: 0.511652\nTrain Epoch: 7 [212000/248297 (85%)]\tLoss: 0.487791\nTrain Epoch: 7 [213000/248297 (86%)]\tLoss: 0.549303\nTrain Epoch: 7 [214000/248297 (86%)]\tLoss: 0.425466\nTrain Epoch: 7 [215000/248297 (87%)]\tLoss: 0.453932\nTrain Epoch: 7 [216000/248297 (87%)]\tLoss: 0.540935\nTrain Epoch: 7 [217000/248297 (87%)]\tLoss: 0.446928\nTrain Epoch: 7 [218000/248297 (88%)]\tLoss: 0.558070\nTrain Epoch: 7 [219000/248297 (88%)]\tLoss: 0.476046\nTrain Epoch: 7 [220000/248297 (89%)]\tLoss: 0.553799\nTrain Epoch: 7 [221000/248297 (89%)]\tLoss: 0.500822\nTrain Epoch: 7 [222000/248297 (89%)]\tLoss: 0.475445\nTrain Epoch: 7 [223000/248297 (90%)]\tLoss: 0.476839\nTrain Epoch: 7 [224000/248297 (90%)]\tLoss: 0.401718\nTrain Epoch: 7 [225000/248297 (91%)]\tLoss: 0.497413\nTrain Epoch: 7 [226000/248297 (91%)]\tLoss: 0.507520\nTrain Epoch: 7 [227000/248297 (91%)]\tLoss: 0.553374\nTrain Epoch: 7 [228000/248297 (92%)]\tLoss: 0.393620\nTrain Epoch: 7 [229000/248297 (92%)]\tLoss: 0.468015\nTrain Epoch: 7 [230000/248297 (93%)]\tLoss: 0.508974\nTrain Epoch: 7 [231000/248297 (93%)]\tLoss: 0.514755\nTrain Epoch: 7 [232000/248297 (93%)]\tLoss: 0.478546\nTrain Epoch: 7 [233000/248297 (94%)]\tLoss: 0.464551\nTrain Epoch: 7 [234000/248297 (94%)]\tLoss: 0.527561\nTrain Epoch: 7 [235000/248297 (95%)]\tLoss: 0.456194\nTrain Epoch: 7 [236000/248297 (95%)]\tLoss: 0.447029\nTrain Epoch: 7 [237000/248297 (95%)]\tLoss: 0.498262\nTrain Epoch: 7 [238000/248297 (96%)]\tLoss: 0.416831\nTrain Epoch: 7 [239000/248297 (96%)]\tLoss: 0.495075\nTrain Epoch: 7 [240000/248297 (97%)]\tLoss: 0.576457\nTrain Epoch: 7 [241000/248297 (97%)]\tLoss: 0.530942\nTrain Epoch: 7 [242000/248297 (98%)]\tLoss: 0.533668\nTrain Epoch: 7 [243000/248297 (98%)]\tLoss: 0.463547\nTrain Epoch: 7 [244000/248297 (98%)]\tLoss: 0.490267\nTrain Epoch: 7 [245000/248297 (99%)]\tLoss: 0.476278\nTrain Epoch: 7 [246000/248297 (99%)]\tLoss: 0.625213\nTrain Epoch: 7 [247000/248297 (100%)]\tLoss: 0.566437\nTrain Epoch: 7 [248000/248297 (100%)]\tLoss: 0.498157\n\nTest set: Average loss: 0.0051, Accuracy: 20596/27589 (75%)\n\nTrain Epoch: 8 [0/248297 (0%)]\tLoss: 0.564171\nTrain Epoch: 8 [1000/248297 (0%)]\tLoss: 0.457882\nTrain Epoch: 8 [2000/248297 (1%)]\tLoss: 0.484026\nTrain Epoch: 8 [3000/248297 (1%)]\tLoss: 0.469761\nTrain Epoch: 8 [4000/248297 (2%)]\tLoss: 0.477569\nTrain Epoch: 8 [5000/248297 (2%)]\tLoss: 0.493214\nTrain Epoch: 8 [6000/248297 (2%)]\tLoss: 0.473060\nTrain Epoch: 8 [7000/248297 (3%)]\tLoss: 0.543089\nTrain Epoch: 8 [8000/248297 (3%)]\tLoss: 0.479402\nTrain Epoch: 8 [9000/248297 (4%)]\tLoss: 0.541595\nTrain Epoch: 8 [10000/248297 (4%)]\tLoss: 0.564748\nTrain Epoch: 8 [11000/248297 (4%)]\tLoss: 0.564372\nTrain Epoch: 8 [12000/248297 (5%)]\tLoss: 0.557339\nTrain Epoch: 8 [13000/248297 (5%)]\tLoss: 0.423560\nTrain Epoch: 8 [14000/248297 (6%)]\tLoss: 0.457403\nTrain Epoch: 8 [15000/248297 (6%)]\tLoss: 0.488755\nTrain Epoch: 8 [16000/248297 (6%)]\tLoss: 0.489682\nTrain Epoch: 8 [17000/248297 (7%)]\tLoss: 0.483554\nTrain Epoch: 8 [18000/248297 (7%)]\tLoss: 0.439215\nTrain Epoch: 8 [19000/248297 (8%)]\tLoss: 0.433038\nTrain Epoch: 8 [20000/248297 (8%)]\tLoss: 0.569256\nTrain Epoch: 8 [21000/248297 (8%)]\tLoss: 0.469114\nTrain Epoch: 8 [22000/248297 (9%)]\tLoss: 0.459188\nTrain Epoch: 8 [23000/248297 (9%)]\tLoss: 0.550233\nTrain Epoch: 8 [24000/248297 (10%)]\tLoss: 0.457707\nTrain Epoch: 8 [25000/248297 (10%)]\tLoss: 0.517157\nTrain Epoch: 8 [26000/248297 (10%)]\tLoss: 0.550700\nTrain Epoch: 8 [27000/248297 (11%)]\tLoss: 0.475762\nTrain Epoch: 8 [28000/248297 (11%)]\tLoss: 0.446959\nTrain Epoch: 8 [29000/248297 (12%)]\tLoss: 0.551216\nTrain Epoch: 8 [30000/248297 (12%)]\tLoss: 0.546634\nTrain Epoch: 8 [31000/248297 (12%)]\tLoss: 0.525546\nTrain Epoch: 8 [32000/248297 (13%)]\tLoss: 0.543956\nTrain Epoch: 8 [33000/248297 (13%)]\tLoss: 0.410765\nTrain Epoch: 8 [34000/248297 (14%)]\tLoss: 0.484600\nTrain Epoch: 8 [35000/248297 (14%)]\tLoss: 0.463460\nTrain Epoch: 8 [36000/248297 (15%)]\tLoss: 0.530830\nTrain Epoch: 8 [37000/248297 (15%)]\tLoss: 0.476889\nTrain Epoch: 8 [38000/248297 (15%)]\tLoss: 0.417670\nTrain Epoch: 8 [39000/248297 (16%)]\tLoss: 0.547453\nTrain Epoch: 8 [40000/248297 (16%)]\tLoss: 0.530530\nTrain Epoch: 8 [41000/248297 (17%)]\tLoss: 0.406685\nTrain Epoch: 8 [42000/248297 (17%)]\tLoss: 0.504858\nTrain Epoch: 8 [43000/248297 (17%)]\tLoss: 0.492561\nTrain Epoch: 8 [44000/248297 (18%)]\tLoss: 0.529734\nTrain Epoch: 8 [45000/248297 (18%)]\tLoss: 0.324110\nTrain Epoch: 8 [46000/248297 (19%)]\tLoss: 0.434145\nTrain Epoch: 8 [47000/248297 (19%)]\tLoss: 0.455756\nTrain Epoch: 8 [48000/248297 (19%)]\tLoss: 0.476688\nTrain Epoch: 8 [49000/248297 (20%)]\tLoss: 0.465436\nTrain Epoch: 8 [50000/248297 (20%)]\tLoss: 0.461883\nTrain Epoch: 8 [51000/248297 (21%)]\tLoss: 0.438098\nTrain Epoch: 8 [52000/248297 (21%)]\tLoss: 0.482331\nTrain Epoch: 8 [53000/248297 (21%)]\tLoss: 0.479899\nTrain Epoch: 8 [54000/248297 (22%)]\tLoss: 0.463249\nTrain Epoch: 8 [55000/248297 (22%)]\tLoss: 0.528367\nTrain Epoch: 8 [56000/248297 (23%)]\tLoss: 0.495662\nTrain Epoch: 8 [57000/248297 (23%)]\tLoss: 0.442689\nTrain Epoch: 8 [58000/248297 (23%)]\tLoss: 0.411485\nTrain Epoch: 8 [59000/248297 (24%)]\tLoss: 0.482175\nTrain Epoch: 8 [60000/248297 (24%)]\tLoss: 0.467004\nTrain Epoch: 8 [61000/248297 (25%)]\tLoss: 0.528288\nTrain Epoch: 8 [62000/248297 (25%)]\tLoss: 0.459643\nTrain Epoch: 8 [63000/248297 (25%)]\tLoss: 0.441402\nTrain Epoch: 8 [64000/248297 (26%)]\tLoss: 0.373768\nTrain Epoch: 8 [65000/248297 (26%)]\tLoss: 0.445827\nTrain Epoch: 8 [66000/248297 (27%)]\tLoss: 0.526730\nTrain Epoch: 8 [67000/248297 (27%)]\tLoss: 0.461448\nTrain Epoch: 8 [68000/248297 (27%)]\tLoss: 0.622594\nTrain Epoch: 8 [69000/248297 (28%)]\tLoss: 0.423500\nTrain Epoch: 8 [70000/248297 (28%)]\tLoss: 0.507439\nTrain Epoch: 8 [71000/248297 (29%)]\tLoss: 0.546791\nTrain Epoch: 8 [72000/248297 (29%)]\tLoss: 0.425962\nTrain Epoch: 8 [73000/248297 (29%)]\tLoss: 0.491978\nTrain Epoch: 8 [74000/248297 (30%)]\tLoss: 0.452801\nTrain Epoch: 8 [75000/248297 (30%)]\tLoss: 0.540498\nTrain Epoch: 8 [76000/248297 (31%)]\tLoss: 0.539097\nTrain Epoch: 8 [77000/248297 (31%)]\tLoss: 0.478900\nTrain Epoch: 8 [78000/248297 (31%)]\tLoss: 0.461244\nTrain Epoch: 8 [79000/248297 (32%)]\tLoss: 0.523345\nTrain Epoch: 8 [80000/248297 (32%)]\tLoss: 0.402557\nTrain Epoch: 8 [81000/248297 (33%)]\tLoss: 0.498876\nTrain Epoch: 8 [82000/248297 (33%)]\tLoss: 0.467330\nTrain Epoch: 8 [83000/248297 (33%)]\tLoss: 0.441554\nTrain Epoch: 8 [84000/248297 (34%)]\tLoss: 0.508242\nTrain Epoch: 8 [85000/248297 (34%)]\tLoss: 0.541637\nTrain Epoch: 8 [86000/248297 (35%)]\tLoss: 0.524877\nTrain Epoch: 8 [87000/248297 (35%)]\tLoss: 0.417724\nTrain Epoch: 8 [88000/248297 (35%)]\tLoss: 0.537614\nTrain Epoch: 8 [89000/248297 (36%)]\tLoss: 0.494902\nTrain Epoch: 8 [90000/248297 (36%)]\tLoss: 0.551969\nTrain Epoch: 8 [91000/248297 (37%)]\tLoss: 0.490896\nTrain Epoch: 8 [92000/248297 (37%)]\tLoss: 0.490758\nTrain Epoch: 8 [93000/248297 (37%)]\tLoss: 0.483402\nTrain Epoch: 8 [94000/248297 (38%)]\tLoss: 0.508866\nTrain Epoch: 8 [95000/248297 (38%)]\tLoss: 0.499068\nTrain Epoch: 8 [96000/248297 (39%)]\tLoss: 0.517899\nTrain Epoch: 8 [97000/248297 (39%)]\tLoss: 0.524677\nTrain Epoch: 8 [98000/248297 (39%)]\tLoss: 0.535114\nTrain Epoch: 8 [99000/248297 (40%)]\tLoss: 0.393969\nTrain Epoch: 8 [100000/248297 (40%)]\tLoss: 0.500359\nTrain Epoch: 8 [101000/248297 (41%)]\tLoss: 0.486399\nTrain Epoch: 8 [102000/248297 (41%)]\tLoss: 0.523819\nTrain Epoch: 8 [103000/248297 (41%)]\tLoss: 0.462778\nTrain Epoch: 8 [104000/248297 (42%)]\tLoss: 0.487487\nTrain Epoch: 8 [105000/248297 (42%)]\tLoss: 0.478441\nTrain Epoch: 8 [106000/248297 (43%)]\tLoss: 0.454193\nTrain Epoch: 8 [107000/248297 (43%)]\tLoss: 0.441817\nTrain Epoch: 8 [108000/248297 (44%)]\tLoss: 0.541878\nTrain Epoch: 8 [109000/248297 (44%)]\tLoss: 0.550663\nTrain Epoch: 8 [110000/248297 (44%)]\tLoss: 0.463628\nTrain Epoch: 8 [111000/248297 (45%)]\tLoss: 0.573400\nTrain Epoch: 8 [112000/248297 (45%)]\tLoss: 0.466231\nTrain Epoch: 8 [113000/248297 (46%)]\tLoss: 0.443095\nTrain Epoch: 8 [114000/248297 (46%)]\tLoss: 0.611686\nTrain Epoch: 8 [115000/248297 (46%)]\tLoss: 0.389038\nTrain Epoch: 8 [116000/248297 (47%)]\tLoss: 0.449603\nTrain Epoch: 8 [117000/248297 (47%)]\tLoss: 0.545758\nTrain Epoch: 8 [118000/248297 (48%)]\tLoss: 0.496448\nTrain Epoch: 8 [119000/248297 (48%)]\tLoss: 0.479210\nTrain Epoch: 8 [120000/248297 (48%)]\tLoss: 0.499986\nTrain Epoch: 8 [121000/248297 (49%)]\tLoss: 0.536552\nTrain Epoch: 8 [122000/248297 (49%)]\tLoss: 0.472689\nTrain Epoch: 8 [123000/248297 (50%)]\tLoss: 0.570508\nTrain Epoch: 8 [124000/248297 (50%)]\tLoss: 0.505148\nTrain Epoch: 8 [125000/248297 (50%)]\tLoss: 0.477567\nTrain Epoch: 8 [126000/248297 (51%)]\tLoss: 0.427733\nTrain Epoch: 8 [127000/248297 (51%)]\tLoss: 0.499186\nTrain Epoch: 8 [128000/248297 (52%)]\tLoss: 0.450898\nTrain Epoch: 8 [129000/248297 (52%)]\tLoss: 0.477613\nTrain Epoch: 8 [130000/248297 (52%)]\tLoss: 0.506147\nTrain Epoch: 8 [131000/248297 (53%)]\tLoss: 0.498967\nTrain Epoch: 8 [132000/248297 (53%)]\tLoss: 0.582033\nTrain Epoch: 8 [133000/248297 (54%)]\tLoss: 0.488760\nTrain Epoch: 8 [134000/248297 (54%)]\tLoss: 0.542590\nTrain Epoch: 8 [135000/248297 (54%)]\tLoss: 0.494250\nTrain Epoch: 8 [136000/248297 (55%)]\tLoss: 0.465180\nTrain Epoch: 8 [137000/248297 (55%)]\tLoss: 0.550891\nTrain Epoch: 8 [138000/248297 (56%)]\tLoss: 0.406376\nTrain Epoch: 8 [139000/248297 (56%)]\tLoss: 0.489376\nTrain Epoch: 8 [140000/248297 (56%)]\tLoss: 0.462688\nTrain Epoch: 8 [141000/248297 (57%)]\tLoss: 0.579292\nTrain Epoch: 8 [142000/248297 (57%)]\tLoss: 0.476711\nTrain Epoch: 8 [143000/248297 (58%)]\tLoss: 0.576519\nTrain Epoch: 8 [144000/248297 (58%)]\tLoss: 0.433156\nTrain Epoch: 8 [145000/248297 (58%)]\tLoss: 0.467941\nTrain Epoch: 8 [146000/248297 (59%)]\tLoss: 0.458475\nTrain Epoch: 8 [147000/248297 (59%)]\tLoss: 0.517106\nTrain Epoch: 8 [148000/248297 (60%)]\tLoss: 0.436752\nTrain Epoch: 8 [149000/248297 (60%)]\tLoss: 0.502553\nTrain Epoch: 8 [150000/248297 (60%)]\tLoss: 0.549424\nTrain Epoch: 8 [151000/248297 (61%)]\tLoss: 0.516989\nTrain Epoch: 8 [152000/248297 (61%)]\tLoss: 0.565414\nTrain Epoch: 8 [153000/248297 (62%)]\tLoss: 0.517491\nTrain Epoch: 8 [154000/248297 (62%)]\tLoss: 0.483025\nTrain Epoch: 8 [155000/248297 (62%)]\tLoss: 0.474522\nTrain Epoch: 8 [156000/248297 (63%)]\tLoss: 0.496480\nTrain Epoch: 8 [157000/248297 (63%)]\tLoss: 0.452586\nTrain Epoch: 8 [158000/248297 (64%)]\tLoss: 0.533390\nTrain Epoch: 8 [159000/248297 (64%)]\tLoss: 0.464975\nTrain Epoch: 8 [160000/248297 (64%)]\tLoss: 0.501768\nTrain Epoch: 8 [161000/248297 (65%)]\tLoss: 0.450983\nTrain Epoch: 8 [162000/248297 (65%)]\tLoss: 0.439341\nTrain Epoch: 8 [163000/248297 (66%)]\tLoss: 0.499153\nTrain Epoch: 8 [164000/248297 (66%)]\tLoss: 0.479000\nTrain Epoch: 8 [165000/248297 (66%)]\tLoss: 0.498638\nTrain Epoch: 8 [166000/248297 (67%)]\tLoss: 0.516225\nTrain Epoch: 8 [167000/248297 (67%)]\tLoss: 0.551344\nTrain Epoch: 8 [168000/248297 (68%)]\tLoss: 0.525523\nTrain Epoch: 8 [169000/248297 (68%)]\tLoss: 0.459890\nTrain Epoch: 8 [170000/248297 (68%)]\tLoss: 0.505873\nTrain Epoch: 8 [171000/248297 (69%)]\tLoss: 0.516518\nTrain Epoch: 8 [172000/248297 (69%)]\tLoss: 0.514204\nTrain Epoch: 8 [173000/248297 (70%)]\tLoss: 0.406377\nTrain Epoch: 8 [174000/248297 (70%)]\tLoss: 0.570385\nTrain Epoch: 8 [175000/248297 (71%)]\tLoss: 0.624850\nTrain Epoch: 8 [176000/248297 (71%)]\tLoss: 0.483883\nTrain Epoch: 8 [177000/248297 (71%)]\tLoss: 0.437750\nTrain Epoch: 8 [178000/248297 (72%)]\tLoss: 0.448461\nTrain Epoch: 8 [179000/248297 (72%)]\tLoss: 0.458604\nTrain Epoch: 8 [180000/248297 (73%)]\tLoss: 0.477526\nTrain Epoch: 8 [181000/248297 (73%)]\tLoss: 0.446262\nTrain Epoch: 8 [182000/248297 (73%)]\tLoss: 0.469037\nTrain Epoch: 8 [183000/248297 (74%)]\tLoss: 0.503681\nTrain Epoch: 8 [184000/248297 (74%)]\tLoss: 0.468874\nTrain Epoch: 8 [185000/248297 (75%)]\tLoss: 0.516796\nTrain Epoch: 8 [186000/248297 (75%)]\tLoss: 0.482112\nTrain Epoch: 8 [187000/248297 (75%)]\tLoss: 0.523733\nTrain Epoch: 8 [188000/248297 (76%)]\tLoss: 0.521019\nTrain Epoch: 8 [189000/248297 (76%)]\tLoss: 0.464506\nTrain Epoch: 8 [190000/248297 (77%)]\tLoss: 0.469987\nTrain Epoch: 8 [191000/248297 (77%)]\tLoss: 0.577501\nTrain Epoch: 8 [192000/248297 (77%)]\tLoss: 0.508441\nTrain Epoch: 8 [193000/248297 (78%)]\tLoss: 0.469064\nTrain Epoch: 8 [194000/248297 (78%)]\tLoss: 0.476026\nTrain Epoch: 8 [195000/248297 (79%)]\tLoss: 0.452039\nTrain Epoch: 8 [196000/248297 (79%)]\tLoss: 0.552548\nTrain Epoch: 8 [197000/248297 (79%)]\tLoss: 0.469603\nTrain Epoch: 8 [198000/248297 (80%)]\tLoss: 0.458643\nTrain Epoch: 8 [199000/248297 (80%)]\tLoss: 0.498460\nTrain Epoch: 8 [200000/248297 (81%)]\tLoss: 0.492551\nTrain Epoch: 8 [201000/248297 (81%)]\tLoss: 0.518600\nTrain Epoch: 8 [202000/248297 (81%)]\tLoss: 0.498893\nTrain Epoch: 8 [203000/248297 (82%)]\tLoss: 0.471734\nTrain Epoch: 8 [204000/248297 (82%)]\tLoss: 0.571698\nTrain Epoch: 8 [205000/248297 (83%)]\tLoss: 0.497957\nTrain Epoch: 8 [206000/248297 (83%)]\tLoss: 0.478751\nTrain Epoch: 8 [207000/248297 (83%)]\tLoss: 0.506644\nTrain Epoch: 8 [208000/248297 (84%)]\tLoss: 0.531547\nTrain Epoch: 8 [209000/248297 (84%)]\tLoss: 0.467757\nTrain Epoch: 8 [210000/248297 (85%)]\tLoss: 0.516442\nTrain Epoch: 8 [211000/248297 (85%)]\tLoss: 0.406945\nTrain Epoch: 8 [212000/248297 (85%)]\tLoss: 0.518424\nTrain Epoch: 8 [213000/248297 (86%)]\tLoss: 0.477199\nTrain Epoch: 8 [214000/248297 (86%)]\tLoss: 0.398198\nTrain Epoch: 8 [215000/248297 (87%)]\tLoss: 0.445514\nTrain Epoch: 8 [216000/248297 (87%)]\tLoss: 0.478583\nTrain Epoch: 8 [217000/248297 (87%)]\tLoss: 0.503846\nTrain Epoch: 8 [218000/248297 (88%)]\tLoss: 0.480151\nTrain Epoch: 8 [219000/248297 (88%)]\tLoss: 0.517046\nTrain Epoch: 8 [220000/248297 (89%)]\tLoss: 0.417520\nTrain Epoch: 8 [221000/248297 (89%)]\tLoss: 0.525865\nTrain Epoch: 8 [222000/248297 (89%)]\tLoss: 0.646506\nTrain Epoch: 8 [223000/248297 (90%)]\tLoss: 0.492629\nTrain Epoch: 8 [224000/248297 (90%)]\tLoss: 0.488704\nTrain Epoch: 8 [225000/248297 (91%)]\tLoss: 0.475360\nTrain Epoch: 8 [226000/248297 (91%)]\tLoss: 0.494835\nTrain Epoch: 8 [227000/248297 (91%)]\tLoss: 0.440730\nTrain Epoch: 8 [228000/248297 (92%)]\tLoss: 0.431463\nTrain Epoch: 8 [229000/248297 (92%)]\tLoss: 0.420800\nTrain Epoch: 8 [230000/248297 (93%)]\tLoss: 0.573817\nTrain Epoch: 8 [231000/248297 (93%)]\tLoss: 0.531310\nTrain Epoch: 8 [232000/248297 (93%)]\tLoss: 0.513098\nTrain Epoch: 8 [233000/248297 (94%)]\tLoss: 0.444072\nTrain Epoch: 8 [234000/248297 (94%)]\tLoss: 0.460926\nTrain Epoch: 8 [235000/248297 (95%)]\tLoss: 0.542324\nTrain Epoch: 8 [236000/248297 (95%)]\tLoss: 0.450526\nTrain Epoch: 8 [237000/248297 (95%)]\tLoss: 0.464568\nTrain Epoch: 8 [238000/248297 (96%)]\tLoss: 0.573834\nTrain Epoch: 8 [239000/248297 (96%)]\tLoss: 0.545653\nTrain Epoch: 8 [240000/248297 (97%)]\tLoss: 0.487274\nTrain Epoch: 8 [241000/248297 (97%)]\tLoss: 0.532538\nTrain Epoch: 8 [242000/248297 (98%)]\tLoss: 0.548668\nTrain Epoch: 8 [243000/248297 (98%)]\tLoss: 0.454551\nTrain Epoch: 8 [244000/248297 (98%)]\tLoss: 0.573797\nTrain Epoch: 8 [245000/248297 (99%)]\tLoss: 0.531465\nTrain Epoch: 8 [246000/248297 (99%)]\tLoss: 0.485615\nTrain Epoch: 8 [247000/248297 (100%)]\tLoss: 0.573148\nTrain Epoch: 8 [248000/248297 (100%)]\tLoss: 0.520579\n\nTest set: Average loss: 0.0050, Accuracy: 20610/27589 (75%)\n\nTrain Epoch: 9 [0/248297 (0%)]\tLoss: 0.519838\nTrain Epoch: 9 [1000/248297 (0%)]\tLoss: 0.559367\nTrain Epoch: 9 [2000/248297 (1%)]\tLoss: 0.430792\nTrain Epoch: 9 [3000/248297 (1%)]\tLoss: 0.454611\nTrain Epoch: 9 [4000/248297 (2%)]\tLoss: 0.515962\nTrain Epoch: 9 [5000/248297 (2%)]\tLoss: 0.413346\nTrain Epoch: 9 [6000/248297 (2%)]\tLoss: 0.470599\nTrain Epoch: 9 [7000/248297 (3%)]\tLoss: 0.390017\nTrain Epoch: 9 [8000/248297 (3%)]\tLoss: 0.502242\nTrain Epoch: 9 [9000/248297 (4%)]\tLoss: 0.512053\nTrain Epoch: 9 [10000/248297 (4%)]\tLoss: 0.506149\nTrain Epoch: 9 [11000/248297 (4%)]\tLoss: 0.526060\nTrain Epoch: 9 [12000/248297 (5%)]\tLoss: 0.437687\nTrain Epoch: 9 [13000/248297 (5%)]\tLoss: 0.472911\nTrain Epoch: 9 [14000/248297 (6%)]\tLoss: 0.549345\nTrain Epoch: 9 [15000/248297 (6%)]\tLoss: 0.488244\nTrain Epoch: 9 [16000/248297 (6%)]\tLoss: 0.439248\nTrain Epoch: 9 [17000/248297 (7%)]\tLoss: 0.429554\nTrain Epoch: 9 [18000/248297 (7%)]\tLoss: 0.530824\nTrain Epoch: 9 [19000/248297 (8%)]\tLoss: 0.467481\nTrain Epoch: 9 [20000/248297 (8%)]\tLoss: 0.440571\nTrain Epoch: 9 [21000/248297 (8%)]\tLoss: 0.562745\nTrain Epoch: 9 [22000/248297 (9%)]\tLoss: 0.448157\nTrain Epoch: 9 [23000/248297 (9%)]\tLoss: 0.487499\nTrain Epoch: 9 [24000/248297 (10%)]\tLoss: 0.474181\nTrain Epoch: 9 [25000/248297 (10%)]\tLoss: 0.467526\nTrain Epoch: 9 [26000/248297 (10%)]\tLoss: 0.562047\nTrain Epoch: 9 [27000/248297 (11%)]\tLoss: 0.402890\nTrain Epoch: 9 [28000/248297 (11%)]\tLoss: 0.552120\nTrain Epoch: 9 [29000/248297 (12%)]\tLoss: 0.519569\nTrain Epoch: 9 [30000/248297 (12%)]\tLoss: 0.423402\nTrain Epoch: 9 [31000/248297 (12%)]\tLoss: 0.459428\nTrain Epoch: 9 [32000/248297 (13%)]\tLoss: 0.397851\nTrain Epoch: 9 [33000/248297 (13%)]\tLoss: 0.543090\nTrain Epoch: 9 [34000/248297 (14%)]\tLoss: 0.610175\nTrain Epoch: 9 [35000/248297 (14%)]\tLoss: 0.542635\nTrain Epoch: 9 [36000/248297 (15%)]\tLoss: 0.502244\nTrain Epoch: 9 [37000/248297 (15%)]\tLoss: 0.520191\nTrain Epoch: 9 [38000/248297 (15%)]\tLoss: 0.450568\nTrain Epoch: 9 [39000/248297 (16%)]\tLoss: 0.411383\nTrain Epoch: 9 [40000/248297 (16%)]\tLoss: 0.463624\nTrain Epoch: 9 [41000/248297 (17%)]\tLoss: 0.439654\nTrain Epoch: 9 [42000/248297 (17%)]\tLoss: 0.484115\nTrain Epoch: 9 [43000/248297 (17%)]\tLoss: 0.476502\nTrain Epoch: 9 [44000/248297 (18%)]\tLoss: 0.450909\nTrain Epoch: 9 [45000/248297 (18%)]\tLoss: 0.489854\nTrain Epoch: 9 [46000/248297 (19%)]\tLoss: 0.527369\nTrain Epoch: 9 [47000/248297 (19%)]\tLoss: 0.514465\nTrain Epoch: 9 [48000/248297 (19%)]\tLoss: 0.467720\nTrain Epoch: 9 [49000/248297 (20%)]\tLoss: 0.474614\nTrain Epoch: 9 [50000/248297 (20%)]\tLoss: 0.463603\nTrain Epoch: 9 [51000/248297 (21%)]\tLoss: 0.502958\nTrain Epoch: 9 [52000/248297 (21%)]\tLoss: 0.372518\nTrain Epoch: 9 [53000/248297 (21%)]\tLoss: 0.436440\nTrain Epoch: 9 [54000/248297 (22%)]\tLoss: 0.472787\nTrain Epoch: 9 [55000/248297 (22%)]\tLoss: 0.481453\nTrain Epoch: 9 [56000/248297 (23%)]\tLoss: 0.578010\nTrain Epoch: 9 [57000/248297 (23%)]\tLoss: 0.538741\nTrain Epoch: 9 [58000/248297 (23%)]\tLoss: 0.523666\nTrain Epoch: 9 [59000/248297 (24%)]\tLoss: 0.504728\nTrain Epoch: 9 [60000/248297 (24%)]\tLoss: 0.496655\nTrain Epoch: 9 [61000/248297 (25%)]\tLoss: 0.495660\nTrain Epoch: 9 [62000/248297 (25%)]\tLoss: 0.458447\nTrain Epoch: 9 [63000/248297 (25%)]\tLoss: 0.514094\nTrain Epoch: 9 [64000/248297 (26%)]\tLoss: 0.522251\nTrain Epoch: 9 [65000/248297 (26%)]\tLoss: 0.481121\nTrain Epoch: 9 [66000/248297 (27%)]\tLoss: 0.562457\nTrain Epoch: 9 [67000/248297 (27%)]\tLoss: 0.516064\nTrain Epoch: 9 [68000/248297 (27%)]\tLoss: 0.432599\nTrain Epoch: 9 [69000/248297 (28%)]\tLoss: 0.516673\nTrain Epoch: 9 [70000/248297 (28%)]\tLoss: 0.501898\nTrain Epoch: 9 [71000/248297 (29%)]\tLoss: 0.597735\nTrain Epoch: 9 [72000/248297 (29%)]\tLoss: 0.434835\nTrain Epoch: 9 [73000/248297 (29%)]\tLoss: 0.479097\nTrain Epoch: 9 [74000/248297 (30%)]\tLoss: 0.494096\nTrain Epoch: 9 [75000/248297 (30%)]\tLoss: 0.454106\nTrain Epoch: 9 [76000/248297 (31%)]\tLoss: 0.546144\nTrain Epoch: 9 [77000/248297 (31%)]\tLoss: 0.432771\nTrain Epoch: 9 [78000/248297 (31%)]\tLoss: 0.444907\nTrain Epoch: 9 [79000/248297 (32%)]\tLoss: 0.499924\nTrain Epoch: 9 [80000/248297 (32%)]\tLoss: 0.499743\nTrain Epoch: 9 [81000/248297 (33%)]\tLoss: 0.435345\nTrain Epoch: 9 [82000/248297 (33%)]\tLoss: 0.532498\nTrain Epoch: 9 [83000/248297 (33%)]\tLoss: 0.414676\nTrain Epoch: 9 [84000/248297 (34%)]\tLoss: 0.482313\nTrain Epoch: 9 [85000/248297 (34%)]\tLoss: 0.519053\nTrain Epoch: 9 [86000/248297 (35%)]\tLoss: 0.461884\nTrain Epoch: 9 [87000/248297 (35%)]\tLoss: 0.448052\nTrain Epoch: 9 [88000/248297 (35%)]\tLoss: 0.474287\nTrain Epoch: 9 [89000/248297 (36%)]\tLoss: 0.568491\nTrain Epoch: 9 [90000/248297 (36%)]\tLoss: 0.509105\nTrain Epoch: 9 [91000/248297 (37%)]\tLoss: 0.431332\nTrain Epoch: 9 [92000/248297 (37%)]\tLoss: 0.572567\nTrain Epoch: 9 [93000/248297 (37%)]\tLoss: 0.548181\nTrain Epoch: 9 [94000/248297 (38%)]\tLoss: 0.560774\nTrain Epoch: 9 [95000/248297 (38%)]\tLoss: 0.365617\nTrain Epoch: 9 [96000/248297 (39%)]\tLoss: 0.444047\nTrain Epoch: 9 [97000/248297 (39%)]\tLoss: 0.535319\nTrain Epoch: 9 [98000/248297 (39%)]\tLoss: 0.574984\nTrain Epoch: 9 [99000/248297 (40%)]\tLoss: 0.478595\nTrain Epoch: 9 [100000/248297 (40%)]\tLoss: 0.489847\nTrain Epoch: 9 [101000/248297 (41%)]\tLoss: 0.524466\nTrain Epoch: 9 [102000/248297 (41%)]\tLoss: 0.579723\nTrain Epoch: 9 [103000/248297 (41%)]\tLoss: 0.569478\nTrain Epoch: 9 [104000/248297 (42%)]\tLoss: 0.543552\nTrain Epoch: 9 [105000/248297 (42%)]\tLoss: 0.415253\nTrain Epoch: 9 [106000/248297 (43%)]\tLoss: 0.575330\nTrain Epoch: 9 [107000/248297 (43%)]\tLoss: 0.486100\nTrain Epoch: 9 [108000/248297 (44%)]\tLoss: 0.462455\nTrain Epoch: 9 [109000/248297 (44%)]\tLoss: 0.462350\nTrain Epoch: 9 [110000/248297 (44%)]\tLoss: 0.500087\nTrain Epoch: 9 [111000/248297 (45%)]\tLoss: 0.525737\nTrain Epoch: 9 [112000/248297 (45%)]\tLoss: 0.528367\nTrain Epoch: 9 [113000/248297 (46%)]\tLoss: 0.421967\nTrain Epoch: 9 [114000/248297 (46%)]\tLoss: 0.497278\nTrain Epoch: 9 [115000/248297 (46%)]\tLoss: 0.450514\nTrain Epoch: 9 [116000/248297 (47%)]\tLoss: 0.404991\nTrain Epoch: 9 [117000/248297 (47%)]\tLoss: 0.522672\nTrain Epoch: 9 [118000/248297 (48%)]\tLoss: 0.500632\nTrain Epoch: 9 [119000/248297 (48%)]\tLoss: 0.483958\nTrain Epoch: 9 [120000/248297 (48%)]\tLoss: 0.466382\nTrain Epoch: 9 [121000/248297 (49%)]\tLoss: 0.569278\nTrain Epoch: 9 [122000/248297 (49%)]\tLoss: 0.557274\nTrain Epoch: 9 [123000/248297 (50%)]\tLoss: 0.537931\nTrain Epoch: 9 [124000/248297 (50%)]\tLoss: 0.509831\nTrain Epoch: 9 [125000/248297 (50%)]\tLoss: 0.442747\nTrain Epoch: 9 [126000/248297 (51%)]\tLoss: 0.541814\nTrain Epoch: 9 [127000/248297 (51%)]\tLoss: 0.426211\nTrain Epoch: 9 [128000/248297 (52%)]\tLoss: 0.493120\nTrain Epoch: 9 [129000/248297 (52%)]\tLoss: 0.467055\nTrain Epoch: 9 [130000/248297 (52%)]\tLoss: 0.428938\nTrain Epoch: 9 [131000/248297 (53%)]\tLoss: 0.519512\nTrain Epoch: 9 [132000/248297 (53%)]\tLoss: 0.555617\nTrain Epoch: 9 [133000/248297 (54%)]\tLoss: 0.535379\nTrain Epoch: 9 [134000/248297 (54%)]\tLoss: 0.504506\nTrain Epoch: 9 [135000/248297 (54%)]\tLoss: 0.454730\nTrain Epoch: 9 [136000/248297 (55%)]\tLoss: 0.472562\nTrain Epoch: 9 [137000/248297 (55%)]\tLoss: 0.504591\nTrain Epoch: 9 [138000/248297 (56%)]\tLoss: 0.454486\nTrain Epoch: 9 [139000/248297 (56%)]\tLoss: 0.525831\nTrain Epoch: 9 [140000/248297 (56%)]\tLoss: 0.561698\nTrain Epoch: 9 [141000/248297 (57%)]\tLoss: 0.593703\nTrain Epoch: 9 [142000/248297 (57%)]\tLoss: 0.479886\nTrain Epoch: 9 [143000/248297 (58%)]\tLoss: 0.573275\nTrain Epoch: 9 [144000/248297 (58%)]\tLoss: 0.471358\nTrain Epoch: 9 [145000/248297 (58%)]\tLoss: 0.604542\nTrain Epoch: 9 [146000/248297 (59%)]\tLoss: 0.441047\nTrain Epoch: 9 [147000/248297 (59%)]\tLoss: 0.500313\nTrain Epoch: 9 [148000/248297 (60%)]\tLoss: 0.509621\nTrain Epoch: 9 [149000/248297 (60%)]\tLoss: 0.563417\nTrain Epoch: 9 [150000/248297 (60%)]\tLoss: 0.480589\nTrain Epoch: 9 [151000/248297 (61%)]\tLoss: 0.587338\nTrain Epoch: 9 [152000/248297 (61%)]\tLoss: 0.536175\nTrain Epoch: 9 [153000/248297 (62%)]\tLoss: 0.528113\nTrain Epoch: 9 [154000/248297 (62%)]\tLoss: 0.592649\nTrain Epoch: 9 [155000/248297 (62%)]\tLoss: 0.507015\nTrain Epoch: 9 [156000/248297 (63%)]\tLoss: 0.534185\nTrain Epoch: 9 [157000/248297 (63%)]\tLoss: 0.542688\nTrain Epoch: 9 [158000/248297 (64%)]\tLoss: 0.559853\nTrain Epoch: 9 [159000/248297 (64%)]\tLoss: 0.472694\nTrain Epoch: 9 [160000/248297 (64%)]\tLoss: 0.516838\nTrain Epoch: 9 [161000/248297 (65%)]\tLoss: 0.521839\nTrain Epoch: 9 [162000/248297 (65%)]\tLoss: 0.498530\nTrain Epoch: 9 [163000/248297 (66%)]\tLoss: 0.513859\nTrain Epoch: 9 [164000/248297 (66%)]\tLoss: 0.441241\nTrain Epoch: 9 [165000/248297 (66%)]\tLoss: 0.489211\nTrain Epoch: 9 [166000/248297 (67%)]\tLoss: 0.532769\nTrain Epoch: 9 [167000/248297 (67%)]\tLoss: 0.564444\nTrain Epoch: 9 [168000/248297 (68%)]\tLoss: 0.466919\nTrain Epoch: 9 [169000/248297 (68%)]\tLoss: 0.477698\nTrain Epoch: 9 [170000/248297 (68%)]\tLoss: 0.547183\nTrain Epoch: 9 [171000/248297 (69%)]\tLoss: 0.480158\nTrain Epoch: 9 [172000/248297 (69%)]\tLoss: 0.534167\nTrain Epoch: 9 [173000/248297 (70%)]\tLoss: 0.512022\nTrain Epoch: 9 [174000/248297 (70%)]\tLoss: 0.488639\nTrain Epoch: 9 [175000/248297 (71%)]\tLoss: 0.556368\nTrain Epoch: 9 [176000/248297 (71%)]\tLoss: 0.420040\nTrain Epoch: 9 [177000/248297 (71%)]\tLoss: 0.471773\nTrain Epoch: 9 [178000/248297 (72%)]\tLoss: 0.481740\nTrain Epoch: 9 [179000/248297 (72%)]\tLoss: 0.542244\nTrain Epoch: 9 [180000/248297 (73%)]\tLoss: 0.488047\nTrain Epoch: 9 [181000/248297 (73%)]\tLoss: 0.452296\nTrain Epoch: 9 [182000/248297 (73%)]\tLoss: 0.521669\nTrain Epoch: 9 [183000/248297 (74%)]\tLoss: 0.483013\nTrain Epoch: 9 [184000/248297 (74%)]\tLoss: 0.541856\nTrain Epoch: 9 [185000/248297 (75%)]\tLoss: 0.531766\nTrain Epoch: 9 [186000/248297 (75%)]\tLoss: 0.480314\nTrain Epoch: 9 [187000/248297 (75%)]\tLoss: 0.392156\nTrain Epoch: 9 [188000/248297 (76%)]\tLoss: 0.379721\nTrain Epoch: 9 [189000/248297 (76%)]\tLoss: 0.542391\nTrain Epoch: 9 [190000/248297 (77%)]\tLoss: 0.504559\nTrain Epoch: 9 [191000/248297 (77%)]\tLoss: 0.442531\nTrain Epoch: 9 [192000/248297 (77%)]\tLoss: 0.561727\nTrain Epoch: 9 [193000/248297 (78%)]\tLoss: 0.542912\nTrain Epoch: 9 [194000/248297 (78%)]\tLoss: 0.562357\nTrain Epoch: 9 [195000/248297 (79%)]\tLoss: 0.490509\nTrain Epoch: 9 [196000/248297 (79%)]\tLoss: 0.534509\nTrain Epoch: 9 [197000/248297 (79%)]\tLoss: 0.517592\nTrain Epoch: 9 [198000/248297 (80%)]\tLoss: 0.611754\nTrain Epoch: 9 [199000/248297 (80%)]\tLoss: 0.512063\nTrain Epoch: 9 [200000/248297 (81%)]\tLoss: 0.489353\nTrain Epoch: 9 [201000/248297 (81%)]\tLoss: 0.464053\nTrain Epoch: 9 [202000/248297 (81%)]\tLoss: 0.451780\nTrain Epoch: 9 [203000/248297 (82%)]\tLoss: 0.501832\nTrain Epoch: 9 [204000/248297 (82%)]\tLoss: 0.541830\nTrain Epoch: 9 [205000/248297 (83%)]\tLoss: 0.427576\nTrain Epoch: 9 [206000/248297 (83%)]\tLoss: 0.496589\nTrain Epoch: 9 [207000/248297 (83%)]\tLoss: 0.501322\nTrain Epoch: 9 [208000/248297 (84%)]\tLoss: 0.549143\nTrain Epoch: 9 [209000/248297 (84%)]\tLoss: 0.543984\nTrain Epoch: 9 [210000/248297 (85%)]\tLoss: 0.466413\nTrain Epoch: 9 [211000/248297 (85%)]\tLoss: 0.462867\nTrain Epoch: 9 [212000/248297 (85%)]\tLoss: 0.535035\nTrain Epoch: 9 [213000/248297 (86%)]\tLoss: 0.544697\nTrain Epoch: 9 [214000/248297 (86%)]\tLoss: 0.496459\nTrain Epoch: 9 [215000/248297 (87%)]\tLoss: 0.485585\nTrain Epoch: 9 [216000/248297 (87%)]\tLoss: 0.479312\nTrain Epoch: 9 [217000/248297 (87%)]\tLoss: 0.466092\nTrain Epoch: 9 [218000/248297 (88%)]\tLoss: 0.448102\nTrain Epoch: 9 [219000/248297 (88%)]\tLoss: 0.470423\nTrain Epoch: 9 [220000/248297 (89%)]\tLoss: 0.517567\nTrain Epoch: 9 [221000/248297 (89%)]\tLoss: 0.463032\nTrain Epoch: 9 [222000/248297 (89%)]\tLoss: 0.430243\nTrain Epoch: 9 [223000/248297 (90%)]\tLoss: 0.426035\nTrain Epoch: 9 [224000/248297 (90%)]\tLoss: 0.469200\nTrain Epoch: 9 [225000/248297 (91%)]\tLoss: 0.582277\nTrain Epoch: 9 [226000/248297 (91%)]\tLoss: 0.489214\nTrain Epoch: 9 [227000/248297 (91%)]\tLoss: 0.462782\nTrain Epoch: 9 [228000/248297 (92%)]\tLoss: 0.471533\nTrain Epoch: 9 [229000/248297 (92%)]\tLoss: 0.498608\nTrain Epoch: 9 [230000/248297 (93%)]\tLoss: 0.468347\nTrain Epoch: 9 [231000/248297 (93%)]\tLoss: 0.490647\nTrain Epoch: 9 [232000/248297 (93%)]\tLoss: 0.526605\nTrain Epoch: 9 [233000/248297 (94%)]\tLoss: 0.533084\nTrain Epoch: 9 [234000/248297 (94%)]\tLoss: 0.471129\nTrain Epoch: 9 [235000/248297 (95%)]\tLoss: 0.475059\nTrain Epoch: 9 [236000/248297 (95%)]\tLoss: 0.603671\nTrain Epoch: 9 [237000/248297 (95%)]\tLoss: 0.544295\nTrain Epoch: 9 [238000/248297 (96%)]\tLoss: 0.517546\nTrain Epoch: 9 [239000/248297 (96%)]\tLoss: 0.489291\nTrain Epoch: 9 [240000/248297 (97%)]\tLoss: 0.441367\nTrain Epoch: 9 [241000/248297 (97%)]\tLoss: 0.451717\nTrain Epoch: 9 [242000/248297 (98%)]\tLoss: 0.574743\nTrain Epoch: 9 [243000/248297 (98%)]\tLoss: 0.497502\nTrain Epoch: 9 [244000/248297 (98%)]\tLoss: 0.457096\nTrain Epoch: 9 [245000/248297 (99%)]\tLoss: 0.515715\nTrain Epoch: 9 [246000/248297 (99%)]\tLoss: 0.579104\nTrain Epoch: 9 [247000/248297 (100%)]\tLoss: 0.539539\nTrain Epoch: 9 [248000/248297 (100%)]\tLoss: 0.506655\n\nTest set: Average loss: 0.0050, Accuracy: 20681/27589 (75%)\n\nTrain Epoch: 10 [0/248297 (0%)]\tLoss: 0.574476\nTrain Epoch: 10 [1000/248297 (0%)]\tLoss: 0.534660\nTrain Epoch: 10 [2000/248297 (1%)]\tLoss: 0.454463\nTrain Epoch: 10 [3000/248297 (1%)]\tLoss: 0.508051\nTrain Epoch: 10 [4000/248297 (2%)]\tLoss: 0.389687\nTrain Epoch: 10 [5000/248297 (2%)]\tLoss: 0.480957\nTrain Epoch: 10 [6000/248297 (2%)]\tLoss: 0.455330\nTrain Epoch: 10 [7000/248297 (3%)]\tLoss: 0.414814\nTrain Epoch: 10 [8000/248297 (3%)]\tLoss: 0.451505\nTrain Epoch: 10 [9000/248297 (4%)]\tLoss: 0.521840\nTrain Epoch: 10 [10000/248297 (4%)]\tLoss: 0.515925\nTrain Epoch: 10 [11000/248297 (4%)]\tLoss: 0.587241\nTrain Epoch: 10 [12000/248297 (5%)]\tLoss: 0.449546\nTrain Epoch: 10 [13000/248297 (5%)]\tLoss: 0.570455\nTrain Epoch: 10 [14000/248297 (6%)]\tLoss: 0.483457\nTrain Epoch: 10 [15000/248297 (6%)]\tLoss: 0.543384\nTrain Epoch: 10 [16000/248297 (6%)]\tLoss: 0.526919\nTrain Epoch: 10 [17000/248297 (7%)]\tLoss: 0.467001\nTrain Epoch: 10 [18000/248297 (7%)]\tLoss: 0.541459\nTrain Epoch: 10 [19000/248297 (8%)]\tLoss: 0.572001\nTrain Epoch: 10 [20000/248297 (8%)]\tLoss: 0.478864\nTrain Epoch: 10 [21000/248297 (8%)]\tLoss: 0.548130\nTrain Epoch: 10 [22000/248297 (9%)]\tLoss: 0.478780\nTrain Epoch: 10 [23000/248297 (9%)]\tLoss: 0.538662\nTrain Epoch: 10 [24000/248297 (10%)]\tLoss: 0.434247\nTrain Epoch: 10 [25000/248297 (10%)]\tLoss: 0.481512\nTrain Epoch: 10 [26000/248297 (10%)]\tLoss: 0.496678\nTrain Epoch: 10 [27000/248297 (11%)]\tLoss: 0.532901\nTrain Epoch: 10 [28000/248297 (11%)]\tLoss: 0.404975\nTrain Epoch: 10 [29000/248297 (12%)]\tLoss: 0.397003\nTrain Epoch: 10 [30000/248297 (12%)]\tLoss: 0.456551\nTrain Epoch: 10 [31000/248297 (12%)]\tLoss: 0.427550\nTrain Epoch: 10 [32000/248297 (13%)]\tLoss: 0.470834\nTrain Epoch: 10 [33000/248297 (13%)]\tLoss: 0.445759\nTrain Epoch: 10 [34000/248297 (14%)]\tLoss: 0.469192\nTrain Epoch: 10 [35000/248297 (14%)]\tLoss: 0.516828\nTrain Epoch: 10 [36000/248297 (15%)]\tLoss: 0.576256\nTrain Epoch: 10 [37000/248297 (15%)]\tLoss: 0.514628\nTrain Epoch: 10 [38000/248297 (15%)]\tLoss: 0.478436\nTrain Epoch: 10 [39000/248297 (16%)]\tLoss: 0.483053\nTrain Epoch: 10 [40000/248297 (16%)]\tLoss: 0.487442\nTrain Epoch: 10 [41000/248297 (17%)]\tLoss: 0.513163\nTrain Epoch: 10 [42000/248297 (17%)]\tLoss: 0.521517\nTrain Epoch: 10 [43000/248297 (17%)]\tLoss: 0.539304\nTrain Epoch: 10 [44000/248297 (18%)]\tLoss: 0.329948\nTrain Epoch: 10 [45000/248297 (18%)]\tLoss: 0.554873\nTrain Epoch: 10 [46000/248297 (19%)]\tLoss: 0.551036\nTrain Epoch: 10 [47000/248297 (19%)]\tLoss: 0.534014\nTrain Epoch: 10 [48000/248297 (19%)]\tLoss: 0.528409\nTrain Epoch: 10 [49000/248297 (20%)]\tLoss: 0.475043\nTrain Epoch: 10 [50000/248297 (20%)]\tLoss: 0.496990\nTrain Epoch: 10 [51000/248297 (21%)]\tLoss: 0.520833\nTrain Epoch: 10 [52000/248297 (21%)]\tLoss: 0.463535\nTrain Epoch: 10 [53000/248297 (21%)]\tLoss: 0.470050\nTrain Epoch: 10 [54000/248297 (22%)]\tLoss: 0.599591\nTrain Epoch: 10 [55000/248297 (22%)]\tLoss: 0.540074\nTrain Epoch: 10 [56000/248297 (23%)]\tLoss: 0.384310\nTrain Epoch: 10 [57000/248297 (23%)]\tLoss: 0.516846\nTrain Epoch: 10 [58000/248297 (23%)]\tLoss: 0.544517\nTrain Epoch: 10 [59000/248297 (24%)]\tLoss: 0.451322\nTrain Epoch: 10 [60000/248297 (24%)]\tLoss: 0.407616\nTrain Epoch: 10 [61000/248297 (25%)]\tLoss: 0.431576\nTrain Epoch: 10 [62000/248297 (25%)]\tLoss: 0.523231\nTrain Epoch: 10 [63000/248297 (25%)]\tLoss: 0.459603\nTrain Epoch: 10 [64000/248297 (26%)]\tLoss: 0.529571\nTrain Epoch: 10 [65000/248297 (26%)]\tLoss: 0.419459\nTrain Epoch: 10 [66000/248297 (27%)]\tLoss: 0.519490\nTrain Epoch: 10 [67000/248297 (27%)]\tLoss: 0.443707\nTrain Epoch: 10 [68000/248297 (27%)]\tLoss: 0.632078\nTrain Epoch: 10 [69000/248297 (28%)]\tLoss: 0.447167\nTrain Epoch: 10 [70000/248297 (28%)]\tLoss: 0.519403\nTrain Epoch: 10 [71000/248297 (29%)]\tLoss: 0.491175\nTrain Epoch: 10 [72000/248297 (29%)]\tLoss: 0.446249\nTrain Epoch: 10 [73000/248297 (29%)]\tLoss: 0.548666\nTrain Epoch: 10 [74000/248297 (30%)]\tLoss: 0.468746\nTrain Epoch: 10 [75000/248297 (30%)]\tLoss: 0.516210\nTrain Epoch: 10 [76000/248297 (31%)]\tLoss: 0.518875\nTrain Epoch: 10 [77000/248297 (31%)]\tLoss: 0.502120\nTrain Epoch: 10 [78000/248297 (31%)]\tLoss: 0.441215\nTrain Epoch: 10 [79000/248297 (32%)]\tLoss: 0.539879\nTrain Epoch: 10 [80000/248297 (32%)]\tLoss: 0.421259\nTrain Epoch: 10 [81000/248297 (33%)]\tLoss: 0.452151\nTrain Epoch: 10 [82000/248297 (33%)]\tLoss: 0.503029\nTrain Epoch: 10 [83000/248297 (33%)]\tLoss: 0.489294\nTrain Epoch: 10 [84000/248297 (34%)]\tLoss: 0.442433\nTrain Epoch: 10 [85000/248297 (34%)]\tLoss: 0.590159\nTrain Epoch: 10 [86000/248297 (35%)]\tLoss: 0.404274\nTrain Epoch: 10 [87000/248297 (35%)]\tLoss: 0.480725\nTrain Epoch: 10 [88000/248297 (35%)]\tLoss: 0.539843\nTrain Epoch: 10 [89000/248297 (36%)]\tLoss: 0.569647\nTrain Epoch: 10 [90000/248297 (36%)]\tLoss: 0.628724\nTrain Epoch: 10 [91000/248297 (37%)]\tLoss: 0.484084\nTrain Epoch: 10 [92000/248297 (37%)]\tLoss: 0.425642\nTrain Epoch: 10 [93000/248297 (37%)]\tLoss: 0.505136\nTrain Epoch: 10 [94000/248297 (38%)]\tLoss: 0.536046\nTrain Epoch: 10 [95000/248297 (38%)]\tLoss: 0.451486\nTrain Epoch: 10 [96000/248297 (39%)]\tLoss: 0.468208\nTrain Epoch: 10 [97000/248297 (39%)]\tLoss: 0.401276\nTrain Epoch: 10 [98000/248297 (39%)]\tLoss: 0.507770\nTrain Epoch: 10 [99000/248297 (40%)]\tLoss: 0.509503\nTrain Epoch: 10 [100000/248297 (40%)]\tLoss: 0.587164\nTrain Epoch: 10 [101000/248297 (41%)]\tLoss: 0.483467\nTrain Epoch: 10 [102000/248297 (41%)]\tLoss: 0.422512\nTrain Epoch: 10 [103000/248297 (41%)]\tLoss: 0.530678\nTrain Epoch: 10 [104000/248297 (42%)]\tLoss: 0.424351\nTrain Epoch: 10 [105000/248297 (42%)]\tLoss: 0.466739\nTrain Epoch: 10 [106000/248297 (43%)]\tLoss: 0.423525\nTrain Epoch: 10 [107000/248297 (43%)]\tLoss: 0.519413\nTrain Epoch: 10 [108000/248297 (44%)]\tLoss: 0.432778\nTrain Epoch: 10 [109000/248297 (44%)]\tLoss: 0.407512\nTrain Epoch: 10 [110000/248297 (44%)]\tLoss: 0.498892\nTrain Epoch: 10 [111000/248297 (45%)]\tLoss: 0.482434\nTrain Epoch: 10 [112000/248297 (45%)]\tLoss: 0.516743\nTrain Epoch: 10 [113000/248297 (46%)]\tLoss: 0.500026\nTrain Epoch: 10 [114000/248297 (46%)]\tLoss: 0.595213\nTrain Epoch: 10 [115000/248297 (46%)]\tLoss: 0.454542\nTrain Epoch: 10 [116000/248297 (47%)]\tLoss: 0.462473\nTrain Epoch: 10 [117000/248297 (47%)]\tLoss: 0.496653\nTrain Epoch: 10 [118000/248297 (48%)]\tLoss: 0.492063\nTrain Epoch: 10 [119000/248297 (48%)]\tLoss: 0.445690\nTrain Epoch: 10 [120000/248297 (48%)]\tLoss: 0.514110\nTrain Epoch: 10 [121000/248297 (49%)]\tLoss: 0.538247\nTrain Epoch: 10 [122000/248297 (49%)]\tLoss: 0.515536\nTrain Epoch: 10 [123000/248297 (50%)]\tLoss: 0.412353\nTrain Epoch: 10 [124000/248297 (50%)]\tLoss: 0.532990\nTrain Epoch: 10 [125000/248297 (50%)]\tLoss: 0.450384\nTrain Epoch: 10 [126000/248297 (51%)]\tLoss: 0.452002\nTrain Epoch: 10 [127000/248297 (51%)]\tLoss: 0.545580\nTrain Epoch: 10 [128000/248297 (52%)]\tLoss: 0.517299\nTrain Epoch: 10 [129000/248297 (52%)]\tLoss: 0.442021\nTrain Epoch: 10 [130000/248297 (52%)]\tLoss: 0.462014\nTrain Epoch: 10 [131000/248297 (53%)]\tLoss: 0.518732\nTrain Epoch: 10 [132000/248297 (53%)]\tLoss: 0.635057\nTrain Epoch: 10 [133000/248297 (54%)]\tLoss: 0.483535\nTrain Epoch: 10 [134000/248297 (54%)]\tLoss: 0.500371\nTrain Epoch: 10 [135000/248297 (54%)]\tLoss: 0.460285\nTrain Epoch: 10 [136000/248297 (55%)]\tLoss: 0.526756\nTrain Epoch: 10 [137000/248297 (55%)]\tLoss: 0.453675\nTrain Epoch: 10 [138000/248297 (56%)]\tLoss: 0.505772\nTrain Epoch: 10 [139000/248297 (56%)]\tLoss: 0.589316\nTrain Epoch: 10 [140000/248297 (56%)]\tLoss: 0.523851\nTrain Epoch: 10 [141000/248297 (57%)]\tLoss: 0.515218\nTrain Epoch: 10 [142000/248297 (57%)]\tLoss: 0.492915\nTrain Epoch: 10 [143000/248297 (58%)]\tLoss: 0.438184\nTrain Epoch: 10 [144000/248297 (58%)]\tLoss: 0.448330\nTrain Epoch: 10 [145000/248297 (58%)]\tLoss: 0.518839\nTrain Epoch: 10 [146000/248297 (59%)]\tLoss: 0.426404\nTrain Epoch: 10 [147000/248297 (59%)]\tLoss: 0.447102\nTrain Epoch: 10 [148000/248297 (60%)]\tLoss: 0.455590\nTrain Epoch: 10 [149000/248297 (60%)]\tLoss: 0.563224\nTrain Epoch: 10 [150000/248297 (60%)]\tLoss: 0.478873\nTrain Epoch: 10 [151000/248297 (61%)]\tLoss: 0.569009\nTrain Epoch: 10 [152000/248297 (61%)]\tLoss: 0.550659\nTrain Epoch: 10 [153000/248297 (62%)]\tLoss: 0.443748\nTrain Epoch: 10 [154000/248297 (62%)]\tLoss: 0.549688\nTrain Epoch: 10 [155000/248297 (62%)]\tLoss: 0.517390\nTrain Epoch: 10 [156000/248297 (63%)]\tLoss: 0.451695\nTrain Epoch: 10 [157000/248297 (63%)]\tLoss: 0.486621\nTrain Epoch: 10 [158000/248297 (64%)]\tLoss: 0.488552\nTrain Epoch: 10 [159000/248297 (64%)]\tLoss: 0.483227\nTrain Epoch: 10 [160000/248297 (64%)]\tLoss: 0.474104\nTrain Epoch: 10 [161000/248297 (65%)]\tLoss: 0.545407\nTrain Epoch: 10 [162000/248297 (65%)]\tLoss: 0.525987\nTrain Epoch: 10 [163000/248297 (66%)]\tLoss: 0.468331\nTrain Epoch: 10 [164000/248297 (66%)]\tLoss: 0.528570\nTrain Epoch: 10 [165000/248297 (66%)]\tLoss: 0.527059\nTrain Epoch: 10 [166000/248297 (67%)]\tLoss: 0.483816\nTrain Epoch: 10 [167000/248297 (67%)]\tLoss: 0.397508\nTrain Epoch: 10 [168000/248297 (68%)]\tLoss: 0.492945\nTrain Epoch: 10 [169000/248297 (68%)]\tLoss: 0.466758\nTrain Epoch: 10 [170000/248297 (68%)]\tLoss: 0.548949\nTrain Epoch: 10 [171000/248297 (69%)]\tLoss: 0.397429\nTrain Epoch: 10 [172000/248297 (69%)]\tLoss: 0.540342\nTrain Epoch: 10 [173000/248297 (70%)]\tLoss: 0.579691\nTrain Epoch: 10 [174000/248297 (70%)]\tLoss: 0.530903\nTrain Epoch: 10 [175000/248297 (71%)]\tLoss: 0.450649\nTrain Epoch: 10 [176000/248297 (71%)]\tLoss: 0.492849\nTrain Epoch: 10 [177000/248297 (71%)]\tLoss: 0.521222\nTrain Epoch: 10 [178000/248297 (72%)]\tLoss: 0.487208\nTrain Epoch: 10 [179000/248297 (72%)]\tLoss: 0.464683\nTrain Epoch: 10 [180000/248297 (73%)]\tLoss: 0.533493\nTrain Epoch: 10 [181000/248297 (73%)]\tLoss: 0.532955\nTrain Epoch: 10 [182000/248297 (73%)]\tLoss: 0.493100\nTrain Epoch: 10 [183000/248297 (74%)]\tLoss: 0.528655\nTrain Epoch: 10 [184000/248297 (74%)]\tLoss: 0.470129\nTrain Epoch: 10 [185000/248297 (75%)]\tLoss: 0.511115\nTrain Epoch: 10 [186000/248297 (75%)]\tLoss: 0.472875\nTrain Epoch: 10 [187000/248297 (75%)]\tLoss: 0.547935\nTrain Epoch: 10 [188000/248297 (76%)]\tLoss: 0.446558\nTrain Epoch: 10 [189000/248297 (76%)]\tLoss: 0.552500\nTrain Epoch: 10 [190000/248297 (77%)]\tLoss: 0.503984\nTrain Epoch: 10 [191000/248297 (77%)]\tLoss: 0.514766\nTrain Epoch: 10 [192000/248297 (77%)]\tLoss: 0.554546\nTrain Epoch: 10 [193000/248297 (78%)]\tLoss: 0.428247\nTrain Epoch: 10 [194000/248297 (78%)]\tLoss: 0.472321\nTrain Epoch: 10 [195000/248297 (79%)]\tLoss: 0.528329\nTrain Epoch: 10 [196000/248297 (79%)]\tLoss: 0.585134\nTrain Epoch: 10 [197000/248297 (79%)]\tLoss: 0.496735\nTrain Epoch: 10 [198000/248297 (80%)]\tLoss: 0.537747\nTrain Epoch: 10 [199000/248297 (80%)]\tLoss: 0.568171\nTrain Epoch: 10 [200000/248297 (81%)]\tLoss: 0.525876\nTrain Epoch: 10 [201000/248297 (81%)]\tLoss: 0.514155\nTrain Epoch: 10 [202000/248297 (81%)]\tLoss: 0.438220\nTrain Epoch: 10 [203000/248297 (82%)]\tLoss: 0.542722\nTrain Epoch: 10 [204000/248297 (82%)]\tLoss: 0.424519\nTrain Epoch: 10 [205000/248297 (83%)]\tLoss: 0.576537\nTrain Epoch: 10 [206000/248297 (83%)]\tLoss: 0.445760\nTrain Epoch: 10 [207000/248297 (83%)]\tLoss: 0.469443\nTrain Epoch: 10 [208000/248297 (84%)]\tLoss: 0.487882\nTrain Epoch: 10 [209000/248297 (84%)]\tLoss: 0.459608\nTrain Epoch: 10 [210000/248297 (85%)]\tLoss: 0.533815\nTrain Epoch: 10 [211000/248297 (85%)]\tLoss: 0.489197\nTrain Epoch: 10 [212000/248297 (85%)]\tLoss: 0.523397\nTrain Epoch: 10 [213000/248297 (86%)]\tLoss: 0.510629\nTrain Epoch: 10 [214000/248297 (86%)]\tLoss: 0.525843\nTrain Epoch: 10 [215000/248297 (87%)]\tLoss: 0.496767\nTrain Epoch: 10 [216000/248297 (87%)]\tLoss: 0.438408\nTrain Epoch: 10 [217000/248297 (87%)]\tLoss: 0.430831\nTrain Epoch: 10 [218000/248297 (88%)]\tLoss: 0.492477\nTrain Epoch: 10 [219000/248297 (88%)]\tLoss: 0.490047\nTrain Epoch: 10 [220000/248297 (89%)]\tLoss: 0.538166\nTrain Epoch: 10 [221000/248297 (89%)]\tLoss: 0.511402\nTrain Epoch: 10 [222000/248297 (89%)]\tLoss: 0.438785\nTrain Epoch: 10 [223000/248297 (90%)]\tLoss: 0.468671\nTrain Epoch: 10 [224000/248297 (90%)]\tLoss: 0.411219\nTrain Epoch: 10 [225000/248297 (91%)]\tLoss: 0.495712\nTrain Epoch: 10 [226000/248297 (91%)]\tLoss: 0.557609\nTrain Epoch: 10 [227000/248297 (91%)]\tLoss: 0.458666\nTrain Epoch: 10 [228000/248297 (92%)]\tLoss: 0.547317\nTrain Epoch: 10 [229000/248297 (92%)]\tLoss: 0.468137\nTrain Epoch: 10 [230000/248297 (93%)]\tLoss: 0.505929\nTrain Epoch: 10 [231000/248297 (93%)]\tLoss: 0.420350\nTrain Epoch: 10 [232000/248297 (93%)]\tLoss: 0.542868\nTrain Epoch: 10 [233000/248297 (94%)]\tLoss: 0.473999\nTrain Epoch: 10 [234000/248297 (94%)]\tLoss: 0.463311\nTrain Epoch: 10 [235000/248297 (95%)]\tLoss: 0.518907\nTrain Epoch: 10 [236000/248297 (95%)]\tLoss: 0.481436\nTrain Epoch: 10 [237000/248297 (95%)]\tLoss: 0.485394\nTrain Epoch: 10 [238000/248297 (96%)]\tLoss: 0.483770\nTrain Epoch: 10 [239000/248297 (96%)]\tLoss: 0.558449\nTrain Epoch: 10 [240000/248297 (97%)]\tLoss: 0.439919\nTrain Epoch: 10 [241000/248297 (97%)]\tLoss: 0.474567\nTrain Epoch: 10 [242000/248297 (98%)]\tLoss: 0.455927\nTrain Epoch: 10 [243000/248297 (98%)]\tLoss: 0.493332\nTrain Epoch: 10 [244000/248297 (98%)]\tLoss: 0.452368\nTrain Epoch: 10 [245000/248297 (99%)]\tLoss: 0.606111\nTrain Epoch: 10 [246000/248297 (99%)]\tLoss: 0.543232\nTrain Epoch: 10 [247000/248297 (100%)]\tLoss: 0.553976\nTrain Epoch: 10 [248000/248297 (100%)]\tLoss: 0.465824\n\nTest set: Average loss: 0.0050, Accuracy: 20728/27589 (75%)\n\nTrain Epoch: 11 [0/248297 (0%)]\tLoss: 0.451840\nTrain Epoch: 11 [1000/248297 (0%)]\tLoss: 0.436123\nTrain Epoch: 11 [2000/248297 (1%)]\tLoss: 0.511210\nTrain Epoch: 11 [3000/248297 (1%)]\tLoss: 0.443518\nTrain Epoch: 11 [4000/248297 (2%)]\tLoss: 0.515004\nTrain Epoch: 11 [5000/248297 (2%)]\tLoss: 0.457740\nTrain Epoch: 11 [6000/248297 (2%)]\tLoss: 0.399451\nTrain Epoch: 11 [7000/248297 (3%)]\tLoss: 0.542477\nTrain Epoch: 11 [8000/248297 (3%)]\tLoss: 0.429137\nTrain Epoch: 11 [9000/248297 (4%)]\tLoss: 0.590988\nTrain Epoch: 11 [10000/248297 (4%)]\tLoss: 0.479124\nTrain Epoch: 11 [11000/248297 (4%)]\tLoss: 0.470166\nTrain Epoch: 11 [12000/248297 (5%)]\tLoss: 0.636388\nTrain Epoch: 11 [13000/248297 (5%)]\tLoss: 0.502126\nTrain Epoch: 11 [14000/248297 (6%)]\tLoss: 0.489814\nTrain Epoch: 11 [15000/248297 (6%)]\tLoss: 0.539082\nTrain Epoch: 11 [16000/248297 (6%)]\tLoss: 0.565683\nTrain Epoch: 11 [17000/248297 (7%)]\tLoss: 0.553606\nTrain Epoch: 11 [18000/248297 (7%)]\tLoss: 0.612053\nTrain Epoch: 11 [19000/248297 (8%)]\tLoss: 0.447949\nTrain Epoch: 11 [20000/248297 (8%)]\tLoss: 0.401784\nTrain Epoch: 11 [21000/248297 (8%)]\tLoss: 0.498004\nTrain Epoch: 11 [22000/248297 (9%)]\tLoss: 0.448048\nTrain Epoch: 11 [23000/248297 (9%)]\tLoss: 0.480083\nTrain Epoch: 11 [24000/248297 (10%)]\tLoss: 0.471984\nTrain Epoch: 11 [25000/248297 (10%)]\tLoss: 0.464795\nTrain Epoch: 11 [26000/248297 (10%)]\tLoss: 0.514406\nTrain Epoch: 11 [27000/248297 (11%)]\tLoss: 0.410239\nTrain Epoch: 11 [28000/248297 (11%)]\tLoss: 0.666085\nTrain Epoch: 11 [29000/248297 (12%)]\tLoss: 0.553094\nTrain Epoch: 11 [30000/248297 (12%)]\tLoss: 0.454449\nTrain Epoch: 11 [31000/248297 (12%)]\tLoss: 0.498284\nTrain Epoch: 11 [32000/248297 (13%)]\tLoss: 0.529989\nTrain Epoch: 11 [33000/248297 (13%)]\tLoss: 0.540282\nTrain Epoch: 11 [34000/248297 (14%)]\tLoss: 0.546429\nTrain Epoch: 11 [35000/248297 (14%)]\tLoss: 0.518459\nTrain Epoch: 11 [36000/248297 (15%)]\tLoss: 0.504284\nTrain Epoch: 11 [37000/248297 (15%)]\tLoss: 0.522476\nTrain Epoch: 11 [38000/248297 (15%)]\tLoss: 0.443412\nTrain Epoch: 11 [39000/248297 (16%)]\tLoss: 0.545681\nTrain Epoch: 11 [40000/248297 (16%)]\tLoss: 0.548756\nTrain Epoch: 11 [41000/248297 (17%)]\tLoss: 0.455019\nTrain Epoch: 11 [42000/248297 (17%)]\tLoss: 0.499204\nTrain Epoch: 11 [43000/248297 (17%)]\tLoss: 0.452127\nTrain Epoch: 11 [44000/248297 (18%)]\tLoss: 0.404151\nTrain Epoch: 11 [45000/248297 (18%)]\tLoss: 0.443128\nTrain Epoch: 11 [46000/248297 (19%)]\tLoss: 0.429372\nTrain Epoch: 11 [47000/248297 (19%)]\tLoss: 0.450016\nTrain Epoch: 11 [48000/248297 (19%)]\tLoss: 0.510543\nTrain Epoch: 11 [49000/248297 (20%)]\tLoss: 0.465533\nTrain Epoch: 11 [50000/248297 (20%)]\tLoss: 0.479822\nTrain Epoch: 11 [51000/248297 (21%)]\tLoss: 0.504100\nTrain Epoch: 11 [52000/248297 (21%)]\tLoss: 0.503948\nTrain Epoch: 11 [53000/248297 (21%)]\tLoss: 0.501066\nTrain Epoch: 11 [54000/248297 (22%)]\tLoss: 0.408306\nTrain Epoch: 11 [55000/248297 (22%)]\tLoss: 0.449209\nTrain Epoch: 11 [56000/248297 (23%)]\tLoss: 0.466344\nTrain Epoch: 11 [57000/248297 (23%)]\tLoss: 0.425363\nTrain Epoch: 11 [58000/248297 (23%)]\tLoss: 0.489921\nTrain Epoch: 11 [59000/248297 (24%)]\tLoss: 0.487919\nTrain Epoch: 11 [60000/248297 (24%)]\tLoss: 0.455839\nTrain Epoch: 11 [61000/248297 (25%)]\tLoss: 0.584060\nTrain Epoch: 11 [62000/248297 (25%)]\tLoss: 0.498891\nTrain Epoch: 11 [63000/248297 (25%)]\tLoss: 0.460184\nTrain Epoch: 11 [64000/248297 (26%)]\tLoss: 0.563147\nTrain Epoch: 11 [65000/248297 (26%)]\tLoss: 0.516973\nTrain Epoch: 11 [66000/248297 (27%)]\tLoss: 0.530957\nTrain Epoch: 11 [67000/248297 (27%)]\tLoss: 0.487090\nTrain Epoch: 11 [68000/248297 (27%)]\tLoss: 0.524500\nTrain Epoch: 11 [69000/248297 (28%)]\tLoss: 0.522560\nTrain Epoch: 11 [70000/248297 (28%)]\tLoss: 0.544529\nTrain Epoch: 11 [71000/248297 (29%)]\tLoss: 0.510455\nTrain Epoch: 11 [72000/248297 (29%)]\tLoss: 0.500073\nTrain Epoch: 11 [73000/248297 (29%)]\tLoss: 0.464156\nTrain Epoch: 11 [74000/248297 (30%)]\tLoss: 0.481411\nTrain Epoch: 11 [75000/248297 (30%)]\tLoss: 0.477142\nTrain Epoch: 11 [76000/248297 (31%)]\tLoss: 0.524230\nTrain Epoch: 11 [77000/248297 (31%)]\tLoss: 0.519770\nTrain Epoch: 11 [78000/248297 (31%)]\tLoss: 0.464060\nTrain Epoch: 11 [79000/248297 (32%)]\tLoss: 0.506279\nTrain Epoch: 11 [80000/248297 (32%)]\tLoss: 0.476046\nTrain Epoch: 11 [81000/248297 (33%)]\tLoss: 0.448636\nTrain Epoch: 11 [82000/248297 (33%)]\tLoss: 0.508256\nTrain Epoch: 11 [83000/248297 (33%)]\tLoss: 0.464208\nTrain Epoch: 11 [84000/248297 (34%)]\tLoss: 0.486398\nTrain Epoch: 11 [85000/248297 (34%)]\tLoss: 0.431121\nTrain Epoch: 11 [86000/248297 (35%)]\tLoss: 0.470406\nTrain Epoch: 11 [87000/248297 (35%)]\tLoss: 0.396595\nTrain Epoch: 11 [88000/248297 (35%)]\tLoss: 0.566490\nTrain Epoch: 11 [89000/248297 (36%)]\tLoss: 0.518042\nTrain Epoch: 11 [90000/248297 (36%)]\tLoss: 0.589669\nTrain Epoch: 11 [91000/248297 (37%)]\tLoss: 0.450086\nTrain Epoch: 11 [92000/248297 (37%)]\tLoss: 0.505959\nTrain Epoch: 11 [93000/248297 (37%)]\tLoss: 0.508759\nTrain Epoch: 11 [94000/248297 (38%)]\tLoss: 0.516042\nTrain Epoch: 11 [95000/248297 (38%)]\tLoss: 0.508325\nTrain Epoch: 11 [96000/248297 (39%)]\tLoss: 0.351924\nTrain Epoch: 11 [97000/248297 (39%)]\tLoss: 0.509359\nTrain Epoch: 11 [98000/248297 (39%)]\tLoss: 0.600961\nTrain Epoch: 11 [99000/248297 (40%)]\tLoss: 0.524598\nTrain Epoch: 11 [100000/248297 (40%)]\tLoss: 0.506620\nTrain Epoch: 11 [101000/248297 (41%)]\tLoss: 0.430440\nTrain Epoch: 11 [102000/248297 (41%)]\tLoss: 0.595081\nTrain Epoch: 11 [103000/248297 (41%)]\tLoss: 0.456703\nTrain Epoch: 11 [104000/248297 (42%)]\tLoss: 0.414058\nTrain Epoch: 11 [105000/248297 (42%)]\tLoss: 0.528842\nTrain Epoch: 11 [106000/248297 (43%)]\tLoss: 0.450592\nTrain Epoch: 11 [107000/248297 (43%)]\tLoss: 0.477185\nTrain Epoch: 11 [108000/248297 (44%)]\tLoss: 0.499833\nTrain Epoch: 11 [109000/248297 (44%)]\tLoss: 0.467578\nTrain Epoch: 11 [110000/248297 (44%)]\tLoss: 0.475096\nTrain Epoch: 11 [111000/248297 (45%)]\tLoss: 0.484944\nTrain Epoch: 11 [112000/248297 (45%)]\tLoss: 0.422420\nTrain Epoch: 11 [113000/248297 (46%)]\tLoss: 0.478573\nTrain Epoch: 11 [114000/248297 (46%)]\tLoss: 0.531116\nTrain Epoch: 11 [115000/248297 (46%)]\tLoss: 0.436270\nTrain Epoch: 11 [116000/248297 (47%)]\tLoss: 0.555454\nTrain Epoch: 11 [117000/248297 (47%)]\tLoss: 0.453772\nTrain Epoch: 11 [118000/248297 (48%)]\tLoss: 0.496588\nTrain Epoch: 11 [119000/248297 (48%)]\tLoss: 0.468701\nTrain Epoch: 11 [120000/248297 (48%)]\tLoss: 0.497024\nTrain Epoch: 11 [121000/248297 (49%)]\tLoss: 0.455269\nTrain Epoch: 11 [122000/248297 (49%)]\tLoss: 0.433182\nTrain Epoch: 11 [123000/248297 (50%)]\tLoss: 0.472295\nTrain Epoch: 11 [124000/248297 (50%)]\tLoss: 0.348206\nTrain Epoch: 11 [125000/248297 (50%)]\tLoss: 0.446368\nTrain Epoch: 11 [126000/248297 (51%)]\tLoss: 0.490262\nTrain Epoch: 11 [127000/248297 (51%)]\tLoss: 0.455128\nTrain Epoch: 11 [128000/248297 (52%)]\tLoss: 0.477909\nTrain Epoch: 11 [129000/248297 (52%)]\tLoss: 0.447131\nTrain Epoch: 11 [130000/248297 (52%)]\tLoss: 0.508179\nTrain Epoch: 11 [131000/248297 (53%)]\tLoss: 0.543267\nTrain Epoch: 11 [132000/248297 (53%)]\tLoss: 0.539548\nTrain Epoch: 11 [133000/248297 (54%)]\tLoss: 0.462816\nTrain Epoch: 11 [134000/248297 (54%)]\tLoss: 0.472629\nTrain Epoch: 11 [135000/248297 (54%)]\tLoss: 0.419074\nTrain Epoch: 11 [136000/248297 (55%)]\tLoss: 0.534761\nTrain Epoch: 11 [137000/248297 (55%)]\tLoss: 0.509780\nTrain Epoch: 11 [138000/248297 (56%)]\tLoss: 0.422595\nTrain Epoch: 11 [139000/248297 (56%)]\tLoss: 0.458152\nTrain Epoch: 11 [140000/248297 (56%)]\tLoss: 0.488590\nTrain Epoch: 11 [141000/248297 (57%)]\tLoss: 0.515100\nTrain Epoch: 11 [142000/248297 (57%)]\tLoss: 0.464045\nTrain Epoch: 11 [143000/248297 (58%)]\tLoss: 0.556111\nTrain Epoch: 11 [144000/248297 (58%)]\tLoss: 0.338327\nTrain Epoch: 11 [145000/248297 (58%)]\tLoss: 0.459577\nTrain Epoch: 11 [146000/248297 (59%)]\tLoss: 0.421718\nTrain Epoch: 11 [147000/248297 (59%)]\tLoss: 0.507570\nTrain Epoch: 11 [148000/248297 (60%)]\tLoss: 0.426892\nTrain Epoch: 11 [149000/248297 (60%)]\tLoss: 0.484335\nTrain Epoch: 11 [150000/248297 (60%)]\tLoss: 0.447978\nTrain Epoch: 11 [151000/248297 (61%)]\tLoss: 0.515909\nTrain Epoch: 11 [152000/248297 (61%)]\tLoss: 0.435614\nTrain Epoch: 11 [153000/248297 (62%)]\tLoss: 0.495472\nTrain Epoch: 11 [154000/248297 (62%)]\tLoss: 0.464866\nTrain Epoch: 11 [155000/248297 (62%)]\tLoss: 0.430810\nTrain Epoch: 11 [156000/248297 (63%)]\tLoss: 0.433239\nTrain Epoch: 11 [157000/248297 (63%)]\tLoss: 0.511959\nTrain Epoch: 11 [158000/248297 (64%)]\tLoss: 0.483544\nTrain Epoch: 11 [159000/248297 (64%)]\tLoss: 0.523889\nTrain Epoch: 11 [160000/248297 (64%)]\tLoss: 0.467203\nTrain Epoch: 11 [161000/248297 (65%)]\tLoss: 0.455057\nTrain Epoch: 11 [162000/248297 (65%)]\tLoss: 0.475554\nTrain Epoch: 11 [163000/248297 (66%)]\tLoss: 0.452879\nTrain Epoch: 11 [164000/248297 (66%)]\tLoss: 0.470053\nTrain Epoch: 11 [165000/248297 (66%)]\tLoss: 0.593421\nTrain Epoch: 11 [166000/248297 (67%)]\tLoss: 0.499027\nTrain Epoch: 11 [167000/248297 (67%)]\tLoss: 0.534298\nTrain Epoch: 11 [168000/248297 (68%)]\tLoss: 0.554639\nTrain Epoch: 11 [169000/248297 (68%)]\tLoss: 0.608101\nTrain Epoch: 11 [170000/248297 (68%)]\tLoss: 0.494470\nTrain Epoch: 11 [171000/248297 (69%)]\tLoss: 0.474684\nTrain Epoch: 11 [172000/248297 (69%)]\tLoss: 0.524304\nTrain Epoch: 11 [173000/248297 (70%)]\tLoss: 0.480580\nTrain Epoch: 11 [174000/248297 (70%)]\tLoss: 0.474825\nTrain Epoch: 11 [175000/248297 (71%)]\tLoss: 0.499387\nTrain Epoch: 11 [176000/248297 (71%)]\tLoss: 0.517445\nTrain Epoch: 11 [177000/248297 (71%)]\tLoss: 0.498036\nTrain Epoch: 11 [178000/248297 (72%)]\tLoss: 0.472511\nTrain Epoch: 11 [179000/248297 (72%)]\tLoss: 0.515518\nTrain Epoch: 11 [180000/248297 (73%)]\tLoss: 0.442556\nTrain Epoch: 11 [181000/248297 (73%)]\tLoss: 0.524286\nTrain Epoch: 11 [182000/248297 (73%)]\tLoss: 0.477973\nTrain Epoch: 11 [183000/248297 (74%)]\tLoss: 0.422938\nTrain Epoch: 11 [184000/248297 (74%)]\tLoss: 0.492202\nTrain Epoch: 11 [185000/248297 (75%)]\tLoss: 0.545803\nTrain Epoch: 11 [186000/248297 (75%)]\tLoss: 0.484621\nTrain Epoch: 11 [187000/248297 (75%)]\tLoss: 0.538759\nTrain Epoch: 11 [188000/248297 (76%)]\tLoss: 0.477690\nTrain Epoch: 11 [189000/248297 (76%)]\tLoss: 0.537508\nTrain Epoch: 11 [190000/248297 (77%)]\tLoss: 0.427024\nTrain Epoch: 11 [191000/248297 (77%)]\tLoss: 0.527000\nTrain Epoch: 11 [192000/248297 (77%)]\tLoss: 0.559606\nTrain Epoch: 11 [193000/248297 (78%)]\tLoss: 0.499785\nTrain Epoch: 11 [194000/248297 (78%)]\tLoss: 0.532699\nTrain Epoch: 11 [195000/248297 (79%)]\tLoss: 0.434009\nTrain Epoch: 11 [196000/248297 (79%)]\tLoss: 0.521287\nTrain Epoch: 11 [197000/248297 (79%)]\tLoss: 0.495126\nTrain Epoch: 11 [198000/248297 (80%)]\tLoss: 0.427700\nTrain Epoch: 11 [199000/248297 (80%)]\tLoss: 0.478936\nTrain Epoch: 11 [200000/248297 (81%)]\tLoss: 0.463256\nTrain Epoch: 11 [201000/248297 (81%)]\tLoss: 0.548305\nTrain Epoch: 11 [202000/248297 (81%)]\tLoss: 0.458639\nTrain Epoch: 11 [203000/248297 (82%)]\tLoss: 0.488742\nTrain Epoch: 11 [204000/248297 (82%)]\tLoss: 0.526872\nTrain Epoch: 11 [205000/248297 (83%)]\tLoss: 0.498497\nTrain Epoch: 11 [206000/248297 (83%)]\tLoss: 0.539282\nTrain Epoch: 11 [207000/248297 (83%)]\tLoss: 0.536949\nTrain Epoch: 11 [208000/248297 (84%)]\tLoss: 0.481126\nTrain Epoch: 11 [209000/248297 (84%)]\tLoss: 0.510807\nTrain Epoch: 11 [210000/248297 (85%)]\tLoss: 0.450814\nTrain Epoch: 11 [211000/248297 (85%)]\tLoss: 0.523904\nTrain Epoch: 11 [212000/248297 (85%)]\tLoss: 0.537704\nTrain Epoch: 11 [213000/248297 (86%)]\tLoss: 0.550405\nTrain Epoch: 11 [214000/248297 (86%)]\tLoss: 0.447382\nTrain Epoch: 11 [215000/248297 (87%)]\tLoss: 0.645964\nTrain Epoch: 11 [216000/248297 (87%)]\tLoss: 0.456021\nTrain Epoch: 11 [217000/248297 (87%)]\tLoss: 0.495262\nTrain Epoch: 11 [218000/248297 (88%)]\tLoss: 0.523979\nTrain Epoch: 11 [219000/248297 (88%)]\tLoss: 0.508591\nTrain Epoch: 11 [220000/248297 (89%)]\tLoss: 0.483482\nTrain Epoch: 11 [221000/248297 (89%)]\tLoss: 0.471384\nTrain Epoch: 11 [222000/248297 (89%)]\tLoss: 0.519498\nTrain Epoch: 11 [223000/248297 (90%)]\tLoss: 0.468485\nTrain Epoch: 11 [224000/248297 (90%)]\tLoss: 0.439733\nTrain Epoch: 11 [225000/248297 (91%)]\tLoss: 0.435697\nTrain Epoch: 11 [226000/248297 (91%)]\tLoss: 0.543335\nTrain Epoch: 11 [227000/248297 (91%)]\tLoss: 0.411496\nTrain Epoch: 11 [228000/248297 (92%)]\tLoss: 0.461724\nTrain Epoch: 11 [229000/248297 (92%)]\tLoss: 0.459003\nTrain Epoch: 11 [230000/248297 (93%)]\tLoss: 0.439785\nTrain Epoch: 11 [231000/248297 (93%)]\tLoss: 0.594757\nTrain Epoch: 11 [232000/248297 (93%)]\tLoss: 0.529700\nTrain Epoch: 11 [233000/248297 (94%)]\tLoss: 0.472458\nTrain Epoch: 11 [234000/248297 (94%)]\tLoss: 0.482165\nTrain Epoch: 11 [235000/248297 (95%)]\tLoss: 0.446292\nTrain Epoch: 11 [236000/248297 (95%)]\tLoss: 0.477541\nTrain Epoch: 11 [237000/248297 (95%)]\tLoss: 0.475925\nTrain Epoch: 11 [238000/248297 (96%)]\tLoss: 0.508101\nTrain Epoch: 11 [239000/248297 (96%)]\tLoss: 0.543446\nTrain Epoch: 11 [240000/248297 (97%)]\tLoss: 0.529113\nTrain Epoch: 11 [241000/248297 (97%)]\tLoss: 0.498218\nTrain Epoch: 11 [242000/248297 (98%)]\tLoss: 0.562025\nTrain Epoch: 11 [243000/248297 (98%)]\tLoss: 0.507661\nTrain Epoch: 11 [244000/248297 (98%)]\tLoss: 0.416818\nTrain Epoch: 11 [245000/248297 (99%)]\tLoss: 0.440846\nTrain Epoch: 11 [246000/248297 (99%)]\tLoss: 0.490285\nTrain Epoch: 11 [247000/248297 (100%)]\tLoss: 0.472523\nTrain Epoch: 11 [248000/248297 (100%)]\tLoss: 0.514064\n\nTest set: Average loss: 0.0050, Accuracy: 20728/27589 (75%)\n\nTrain Epoch: 12 [0/248297 (0%)]\tLoss: 0.481834\nTrain Epoch: 12 [1000/248297 (0%)]\tLoss: 0.553057\nTrain Epoch: 12 [2000/248297 (1%)]\tLoss: 0.493549\nTrain Epoch: 12 [3000/248297 (1%)]\tLoss: 0.454676\nTrain Epoch: 12 [4000/248297 (2%)]\tLoss: 0.534349\nTrain Epoch: 12 [5000/248297 (2%)]\tLoss: 0.476480\nTrain Epoch: 12 [6000/248297 (2%)]\tLoss: 0.459485\nTrain Epoch: 12 [7000/248297 (3%)]\tLoss: 0.454996\nTrain Epoch: 12 [8000/248297 (3%)]\tLoss: 0.488898\nTrain Epoch: 12 [9000/248297 (4%)]\tLoss: 0.480807\nTrain Epoch: 12 [10000/248297 (4%)]\tLoss: 0.497585\nTrain Epoch: 12 [11000/248297 (4%)]\tLoss: 0.486443\nTrain Epoch: 12 [12000/248297 (5%)]\tLoss: 0.520738\nTrain Epoch: 12 [13000/248297 (5%)]\tLoss: 0.503219\nTrain Epoch: 12 [14000/248297 (6%)]\tLoss: 0.521801\nTrain Epoch: 12 [15000/248297 (6%)]\tLoss: 0.458996\nTrain Epoch: 12 [16000/248297 (6%)]\tLoss: 0.502012\nTrain Epoch: 12 [17000/248297 (7%)]\tLoss: 0.562411\nTrain Epoch: 12 [18000/248297 (7%)]\tLoss: 0.432382\nTrain Epoch: 12 [19000/248297 (8%)]\tLoss: 0.465503\nTrain Epoch: 12 [20000/248297 (8%)]\tLoss: 0.471506\nTrain Epoch: 12 [21000/248297 (8%)]\tLoss: 0.413706\nTrain Epoch: 12 [22000/248297 (9%)]\tLoss: 0.503273\nTrain Epoch: 12 [23000/248297 (9%)]\tLoss: 0.482705\nTrain Epoch: 12 [24000/248297 (10%)]\tLoss: 0.416078\nTrain Epoch: 12 [25000/248297 (10%)]\tLoss: 0.461102\nTrain Epoch: 12 [26000/248297 (10%)]\tLoss: 0.561016\nTrain Epoch: 12 [27000/248297 (11%)]\tLoss: 0.579475\nTrain Epoch: 12 [28000/248297 (11%)]\tLoss: 0.528318\nTrain Epoch: 12 [29000/248297 (12%)]\tLoss: 0.532509\nTrain Epoch: 12 [30000/248297 (12%)]\tLoss: 0.515053\nTrain Epoch: 12 [31000/248297 (12%)]\tLoss: 0.529666\nTrain Epoch: 12 [32000/248297 (13%)]\tLoss: 0.407937\nTrain Epoch: 12 [33000/248297 (13%)]\tLoss: 0.525292\nTrain Epoch: 12 [34000/248297 (14%)]\tLoss: 0.534442\nTrain Epoch: 12 [35000/248297 (14%)]\tLoss: 0.557474\nTrain Epoch: 12 [36000/248297 (15%)]\tLoss: 0.541117\nTrain Epoch: 12 [37000/248297 (15%)]\tLoss: 0.532944\nTrain Epoch: 12 [38000/248297 (15%)]\tLoss: 0.393439\nTrain Epoch: 12 [39000/248297 (16%)]\tLoss: 0.511722\nTrain Epoch: 12 [40000/248297 (16%)]\tLoss: 0.504250\nTrain Epoch: 12 [41000/248297 (17%)]\tLoss: 0.487920\nTrain Epoch: 12 [42000/248297 (17%)]\tLoss: 0.474122\nTrain Epoch: 12 [43000/248297 (17%)]\tLoss: 0.554885\nTrain Epoch: 12 [44000/248297 (18%)]\tLoss: 0.578081\nTrain Epoch: 12 [45000/248297 (18%)]\tLoss: 0.472162\nTrain Epoch: 12 [46000/248297 (19%)]\tLoss: 0.565433\nTrain Epoch: 12 [47000/248297 (19%)]\tLoss: 0.588379\nTrain Epoch: 12 [48000/248297 (19%)]\tLoss: 0.537594\nTrain Epoch: 12 [49000/248297 (20%)]\tLoss: 0.443277\nTrain Epoch: 12 [50000/248297 (20%)]\tLoss: 0.473638\nTrain Epoch: 12 [51000/248297 (21%)]\tLoss: 0.587236\nTrain Epoch: 12 [52000/248297 (21%)]\tLoss: 0.471075\nTrain Epoch: 12 [53000/248297 (21%)]\tLoss: 0.486282\nTrain Epoch: 12 [54000/248297 (22%)]\tLoss: 0.472403\nTrain Epoch: 12 [55000/248297 (22%)]\tLoss: 0.484218\nTrain Epoch: 12 [56000/248297 (23%)]\tLoss: 0.510474\nTrain Epoch: 12 [57000/248297 (23%)]\tLoss: 0.465463\nTrain Epoch: 12 [58000/248297 (23%)]\tLoss: 0.487414\nTrain Epoch: 12 [59000/248297 (24%)]\tLoss: 0.504750\nTrain Epoch: 12 [60000/248297 (24%)]\tLoss: 0.505249\nTrain Epoch: 12 [61000/248297 (25%)]\tLoss: 0.475022\nTrain Epoch: 12 [62000/248297 (25%)]\tLoss: 0.476014\nTrain Epoch: 12 [63000/248297 (25%)]\tLoss: 0.422597\nTrain Epoch: 12 [64000/248297 (26%)]\tLoss: 0.509323\nTrain Epoch: 12 [65000/248297 (26%)]\tLoss: 0.525275\nTrain Epoch: 12 [66000/248297 (27%)]\tLoss: 0.507823\nTrain Epoch: 12 [67000/248297 (27%)]\tLoss: 0.458496\nTrain Epoch: 12 [68000/248297 (27%)]\tLoss: 0.498227\nTrain Epoch: 12 [69000/248297 (28%)]\tLoss: 0.475025\nTrain Epoch: 12 [70000/248297 (28%)]\tLoss: 0.420088\nTrain Epoch: 12 [71000/248297 (29%)]\tLoss: 0.520917\nTrain Epoch: 12 [72000/248297 (29%)]\tLoss: 0.420446\nTrain Epoch: 12 [73000/248297 (29%)]\tLoss: 0.547445\nTrain Epoch: 12 [74000/248297 (30%)]\tLoss: 0.423131\nTrain Epoch: 12 [75000/248297 (30%)]\tLoss: 0.456968\nTrain Epoch: 12 [76000/248297 (31%)]\tLoss: 0.477519\nTrain Epoch: 12 [77000/248297 (31%)]\tLoss: 0.468373\nTrain Epoch: 12 [78000/248297 (31%)]\tLoss: 0.459339\nTrain Epoch: 12 [79000/248297 (32%)]\tLoss: 0.466032\nTrain Epoch: 12 [80000/248297 (32%)]\tLoss: 0.474647\nTrain Epoch: 12 [81000/248297 (33%)]\tLoss: 0.433836\nTrain Epoch: 12 [82000/248297 (33%)]\tLoss: 0.518211\nTrain Epoch: 12 [83000/248297 (33%)]\tLoss: 0.512843\nTrain Epoch: 12 [84000/248297 (34%)]\tLoss: 0.466866\nTrain Epoch: 12 [85000/248297 (34%)]\tLoss: 0.482557\nTrain Epoch: 12 [86000/248297 (35%)]\tLoss: 0.448962\nTrain Epoch: 12 [87000/248297 (35%)]\tLoss: 0.491621\nTrain Epoch: 12 [88000/248297 (35%)]\tLoss: 0.488053\nTrain Epoch: 12 [89000/248297 (36%)]\tLoss: 0.462459\nTrain Epoch: 12 [90000/248297 (36%)]\tLoss: 0.546851\nTrain Epoch: 12 [91000/248297 (37%)]\tLoss: 0.510268\nTrain Epoch: 12 [92000/248297 (37%)]\tLoss: 0.473497\nTrain Epoch: 12 [93000/248297 (37%)]\tLoss: 0.436711\nTrain Epoch: 12 [94000/248297 (38%)]\tLoss: 0.499916\nTrain Epoch: 12 [95000/248297 (38%)]\tLoss: 0.493909\nTrain Epoch: 12 [96000/248297 (39%)]\tLoss: 0.564486\nTrain Epoch: 12 [97000/248297 (39%)]\tLoss: 0.489808\nTrain Epoch: 12 [98000/248297 (39%)]\tLoss: 0.479392\nTrain Epoch: 12 [99000/248297 (40%)]\tLoss: 0.573338\nTrain Epoch: 12 [100000/248297 (40%)]\tLoss: 0.538788\nTrain Epoch: 12 [101000/248297 (41%)]\tLoss: 0.530034\nTrain Epoch: 12 [102000/248297 (41%)]\tLoss: 0.561868\nTrain Epoch: 12 [103000/248297 (41%)]\tLoss: 0.522369\nTrain Epoch: 12 [104000/248297 (42%)]\tLoss: 0.458887\nTrain Epoch: 12 [105000/248297 (42%)]\tLoss: 0.557509\nTrain Epoch: 12 [106000/248297 (43%)]\tLoss: 0.619311\nTrain Epoch: 12 [107000/248297 (43%)]\tLoss: 0.528145\nTrain Epoch: 12 [108000/248297 (44%)]\tLoss: 0.481854\nTrain Epoch: 12 [109000/248297 (44%)]\tLoss: 0.467169\nTrain Epoch: 12 [110000/248297 (44%)]\tLoss: 0.514873\nTrain Epoch: 12 [111000/248297 (45%)]\tLoss: 0.541962\nTrain Epoch: 12 [112000/248297 (45%)]\tLoss: 0.463112\nTrain Epoch: 12 [113000/248297 (46%)]\tLoss: 0.474127\nTrain Epoch: 12 [114000/248297 (46%)]\tLoss: 0.486621\nTrain Epoch: 12 [115000/248297 (46%)]\tLoss: 0.429491\nTrain Epoch: 12 [116000/248297 (47%)]\tLoss: 0.448595\nTrain Epoch: 12 [117000/248297 (47%)]\tLoss: 0.486530\nTrain Epoch: 12 [118000/248297 (48%)]\tLoss: 0.524078\nTrain Epoch: 12 [119000/248297 (48%)]\tLoss: 0.396335\nTrain Epoch: 12 [120000/248297 (48%)]\tLoss: 0.487072\nTrain Epoch: 12 [121000/248297 (49%)]\tLoss: 0.421252\nTrain Epoch: 12 [122000/248297 (49%)]\tLoss: 0.572629\nTrain Epoch: 12 [123000/248297 (50%)]\tLoss: 0.487058\nTrain Epoch: 12 [124000/248297 (50%)]\tLoss: 0.471573\nTrain Epoch: 12 [125000/248297 (50%)]\tLoss: 0.498334\nTrain Epoch: 12 [126000/248297 (51%)]\tLoss: 0.566210\nTrain Epoch: 12 [127000/248297 (51%)]\tLoss: 0.472807\nTrain Epoch: 12 [128000/248297 (52%)]\tLoss: 0.548007\nTrain Epoch: 12 [129000/248297 (52%)]\tLoss: 0.501991\nTrain Epoch: 12 [130000/248297 (52%)]\tLoss: 0.519726\nTrain Epoch: 12 [131000/248297 (53%)]\tLoss: 0.458841\nTrain Epoch: 12 [132000/248297 (53%)]\tLoss: 0.463062\nTrain Epoch: 12 [133000/248297 (54%)]\tLoss: 0.512508\nTrain Epoch: 12 [134000/248297 (54%)]\tLoss: 0.429658\nTrain Epoch: 12 [135000/248297 (54%)]\tLoss: 0.481739\nTrain Epoch: 12 [136000/248297 (55%)]\tLoss: 0.519669\nTrain Epoch: 12 [137000/248297 (55%)]\tLoss: 0.447501\nTrain Epoch: 12 [138000/248297 (56%)]\tLoss: 0.457534\nTrain Epoch: 12 [139000/248297 (56%)]\tLoss: 0.547978\nTrain Epoch: 12 [140000/248297 (56%)]\tLoss: 0.511742\nTrain Epoch: 12 [141000/248297 (57%)]\tLoss: 0.418347\nTrain Epoch: 12 [142000/248297 (57%)]\tLoss: 0.524964\nTrain Epoch: 12 [143000/248297 (58%)]\tLoss: 0.434673\nTrain Epoch: 12 [144000/248297 (58%)]\tLoss: 0.416090\nTrain Epoch: 12 [145000/248297 (58%)]\tLoss: 0.452621\nTrain Epoch: 12 [146000/248297 (59%)]\tLoss: 0.431204\nTrain Epoch: 12 [147000/248297 (59%)]\tLoss: 0.495015\nTrain Epoch: 12 [148000/248297 (60%)]\tLoss: 0.498013\nTrain Epoch: 12 [149000/248297 (60%)]\tLoss: 0.540274\nTrain Epoch: 12 [150000/248297 (60%)]\tLoss: 0.538603\nTrain Epoch: 12 [151000/248297 (61%)]\tLoss: 0.516291\nTrain Epoch: 12 [152000/248297 (61%)]\tLoss: 0.449583\nTrain Epoch: 12 [153000/248297 (62%)]\tLoss: 0.482432\nTrain Epoch: 12 [154000/248297 (62%)]\tLoss: 0.490437\nTrain Epoch: 12 [155000/248297 (62%)]\tLoss: 0.493848\nTrain Epoch: 12 [156000/248297 (63%)]\tLoss: 0.481525\nTrain Epoch: 12 [157000/248297 (63%)]\tLoss: 0.506649\nTrain Epoch: 12 [158000/248297 (64%)]\tLoss: 0.433143\nTrain Epoch: 12 [159000/248297 (64%)]\tLoss: 0.499403\nTrain Epoch: 12 [160000/248297 (64%)]\tLoss: 0.473162\nTrain Epoch: 12 [161000/248297 (65%)]\tLoss: 0.484750\nTrain Epoch: 12 [162000/248297 (65%)]\tLoss: 0.516391\nTrain Epoch: 12 [163000/248297 (66%)]\tLoss: 0.405495\nTrain Epoch: 12 [164000/248297 (66%)]\tLoss: 0.519586\nTrain Epoch: 12 [165000/248297 (66%)]\tLoss: 0.454428\nTrain Epoch: 12 [166000/248297 (67%)]\tLoss: 0.590650\nTrain Epoch: 12 [167000/248297 (67%)]\tLoss: 0.441871\nTrain Epoch: 12 [168000/248297 (68%)]\tLoss: 0.406455\nTrain Epoch: 12 [169000/248297 (68%)]\tLoss: 0.471236\nTrain Epoch: 12 [170000/248297 (68%)]\tLoss: 0.501807\nTrain Epoch: 12 [171000/248297 (69%)]\tLoss: 0.432084\nTrain Epoch: 12 [172000/248297 (69%)]\tLoss: 0.486714\nTrain Epoch: 12 [173000/248297 (70%)]\tLoss: 0.501786\nTrain Epoch: 12 [174000/248297 (70%)]\tLoss: 0.390587\nTrain Epoch: 12 [175000/248297 (71%)]\tLoss: 0.522734\nTrain Epoch: 12 [176000/248297 (71%)]\tLoss: 0.512235\nTrain Epoch: 12 [177000/248297 (71%)]\tLoss: 0.560860\nTrain Epoch: 12 [178000/248297 (72%)]\tLoss: 0.457388\nTrain Epoch: 12 [179000/248297 (72%)]\tLoss: 0.441876\nTrain Epoch: 12 [180000/248297 (73%)]\tLoss: 0.440842\nTrain Epoch: 12 [181000/248297 (73%)]\tLoss: 0.466867\nTrain Epoch: 12 [182000/248297 (73%)]\tLoss: 0.505749\nTrain Epoch: 12 [183000/248297 (74%)]\tLoss: 0.557512\nTrain Epoch: 12 [184000/248297 (74%)]\tLoss: 0.455682\nTrain Epoch: 12 [185000/248297 (75%)]\tLoss: 0.449151\nTrain Epoch: 12 [186000/248297 (75%)]\tLoss: 0.530725\nTrain Epoch: 12 [187000/248297 (75%)]\tLoss: 0.414844\nTrain Epoch: 12 [188000/248297 (76%)]\tLoss: 0.505228\nTrain Epoch: 12 [189000/248297 (76%)]\tLoss: 0.458111\nTrain Epoch: 12 [190000/248297 (77%)]\tLoss: 0.459203\nTrain Epoch: 12 [191000/248297 (77%)]\tLoss: 0.521740\nTrain Epoch: 12 [192000/248297 (77%)]\tLoss: 0.551600\nTrain Epoch: 12 [193000/248297 (78%)]\tLoss: 0.539370\nTrain Epoch: 12 [194000/248297 (78%)]\tLoss: 0.464267\nTrain Epoch: 12 [195000/248297 (79%)]\tLoss: 0.608995\nTrain Epoch: 12 [196000/248297 (79%)]\tLoss: 0.431930\nTrain Epoch: 12 [197000/248297 (79%)]\tLoss: 0.600550\nTrain Epoch: 12 [198000/248297 (80%)]\tLoss: 0.495368\nTrain Epoch: 12 [199000/248297 (80%)]\tLoss: 0.526309\nTrain Epoch: 12 [200000/248297 (81%)]\tLoss: 0.517607\nTrain Epoch: 12 [201000/248297 (81%)]\tLoss: 0.592227\nTrain Epoch: 12 [202000/248297 (81%)]\tLoss: 0.441567\nTrain Epoch: 12 [203000/248297 (82%)]\tLoss: 0.374312\nTrain Epoch: 12 [204000/248297 (82%)]\tLoss: 0.478339\nTrain Epoch: 12 [205000/248297 (83%)]\tLoss: 0.485639\nTrain Epoch: 12 [206000/248297 (83%)]\tLoss: 0.456645\nTrain Epoch: 12 [207000/248297 (83%)]\tLoss: 0.467166\nTrain Epoch: 12 [208000/248297 (84%)]\tLoss: 0.417128\nTrain Epoch: 12 [209000/248297 (84%)]\tLoss: 0.495203\nTrain Epoch: 12 [210000/248297 (85%)]\tLoss: 0.398979\nTrain Epoch: 12 [211000/248297 (85%)]\tLoss: 0.473820\nTrain Epoch: 12 [212000/248297 (85%)]\tLoss: 0.476425\nTrain Epoch: 12 [213000/248297 (86%)]\tLoss: 0.497679\nTrain Epoch: 12 [214000/248297 (86%)]\tLoss: 0.550637\nTrain Epoch: 12 [215000/248297 (87%)]\tLoss: 0.523423\nTrain Epoch: 12 [216000/248297 (87%)]\tLoss: 0.422622\nTrain Epoch: 12 [217000/248297 (87%)]\tLoss: 0.501137\nTrain Epoch: 12 [218000/248297 (88%)]\tLoss: 0.483748\nTrain Epoch: 12 [219000/248297 (88%)]\tLoss: 0.488795\nTrain Epoch: 12 [220000/248297 (89%)]\tLoss: 0.510210\nTrain Epoch: 12 [221000/248297 (89%)]\tLoss: 0.513902\nTrain Epoch: 12 [222000/248297 (89%)]\tLoss: 0.562764\nTrain Epoch: 12 [223000/248297 (90%)]\tLoss: 0.449893\nTrain Epoch: 12 [224000/248297 (90%)]\tLoss: 0.518816\nTrain Epoch: 12 [225000/248297 (91%)]\tLoss: 0.515908\nTrain Epoch: 12 [226000/248297 (91%)]\tLoss: 0.414745\nTrain Epoch: 12 [227000/248297 (91%)]\tLoss: 0.511276\nTrain Epoch: 12 [228000/248297 (92%)]\tLoss: 0.413741\nTrain Epoch: 12 [229000/248297 (92%)]\tLoss: 0.547248\nTrain Epoch: 12 [230000/248297 (93%)]\tLoss: 0.504463\nTrain Epoch: 12 [231000/248297 (93%)]\tLoss: 0.460362\nTrain Epoch: 12 [232000/248297 (93%)]\tLoss: 0.567041\nTrain Epoch: 12 [233000/248297 (94%)]\tLoss: 0.470731\nTrain Epoch: 12 [234000/248297 (94%)]\tLoss: 0.485162\nTrain Epoch: 12 [235000/248297 (95%)]\tLoss: 0.468508\nTrain Epoch: 12 [236000/248297 (95%)]\tLoss: 0.521160\nTrain Epoch: 12 [237000/248297 (95%)]\tLoss: 0.489910\nTrain Epoch: 12 [238000/248297 (96%)]\tLoss: 0.560759\nTrain Epoch: 12 [239000/248297 (96%)]\tLoss: 0.475429\nTrain Epoch: 12 [240000/248297 (97%)]\tLoss: 0.503230\nTrain Epoch: 12 [241000/248297 (97%)]\tLoss: 0.569287\nTrain Epoch: 12 [242000/248297 (98%)]\tLoss: 0.464754\nTrain Epoch: 12 [243000/248297 (98%)]\tLoss: 0.507800\nTrain Epoch: 12 [244000/248297 (98%)]\tLoss: 0.453528\nTrain Epoch: 12 [245000/248297 (99%)]\tLoss: 0.406058\nTrain Epoch: 12 [246000/248297 (99%)]\tLoss: 0.553913\nTrain Epoch: 12 [247000/248297 (100%)]\tLoss: 0.457047\nTrain Epoch: 12 [248000/248297 (100%)]\tLoss: 0.498104\n\nTest set: Average loss: 0.0050, Accuracy: 20691/27589 (75%)\n\nTrain Epoch: 13 [0/248297 (0%)]\tLoss: 0.463584\nTrain Epoch: 13 [1000/248297 (0%)]\tLoss: 0.449652\nTrain Epoch: 13 [2000/248297 (1%)]\tLoss: 0.416740\nTrain Epoch: 13 [3000/248297 (1%)]\tLoss: 0.542582\nTrain Epoch: 13 [4000/248297 (2%)]\tLoss: 0.487873\nTrain Epoch: 13 [5000/248297 (2%)]\tLoss: 0.456364\nTrain Epoch: 13 [6000/248297 (2%)]\tLoss: 0.467584\nTrain Epoch: 13 [7000/248297 (3%)]\tLoss: 0.418025\nTrain Epoch: 13 [8000/248297 (3%)]\tLoss: 0.552681\nTrain Epoch: 13 [9000/248297 (4%)]\tLoss: 0.477982\nTrain Epoch: 13 [10000/248297 (4%)]\tLoss: 0.458648\nTrain Epoch: 13 [11000/248297 (4%)]\tLoss: 0.509708\nTrain Epoch: 13 [12000/248297 (5%)]\tLoss: 0.430380\nTrain Epoch: 13 [13000/248297 (5%)]\tLoss: 0.438439\nTrain Epoch: 13 [14000/248297 (6%)]\tLoss: 0.443422\nTrain Epoch: 13 [15000/248297 (6%)]\tLoss: 0.489016\nTrain Epoch: 13 [16000/248297 (6%)]\tLoss: 0.519420\nTrain Epoch: 13 [17000/248297 (7%)]\tLoss: 0.304124\nTrain Epoch: 13 [18000/248297 (7%)]\tLoss: 0.538704\nTrain Epoch: 13 [19000/248297 (8%)]\tLoss: 0.439081\nTrain Epoch: 13 [20000/248297 (8%)]\tLoss: 0.532613\nTrain Epoch: 13 [21000/248297 (8%)]\tLoss: 0.476564\nTrain Epoch: 13 [22000/248297 (9%)]\tLoss: 0.457667\nTrain Epoch: 13 [23000/248297 (9%)]\tLoss: 0.429775\nTrain Epoch: 13 [24000/248297 (10%)]\tLoss: 0.454855\nTrain Epoch: 13 [25000/248297 (10%)]\tLoss: 0.496914\nTrain Epoch: 13 [26000/248297 (10%)]\tLoss: 0.543705\nTrain Epoch: 13 [27000/248297 (11%)]\tLoss: 0.430183\nTrain Epoch: 13 [28000/248297 (11%)]\tLoss: 0.615995\nTrain Epoch: 13 [29000/248297 (12%)]\tLoss: 0.460244\nTrain Epoch: 13 [30000/248297 (12%)]\tLoss: 0.410453\nTrain Epoch: 13 [31000/248297 (12%)]\tLoss: 0.548756\nTrain Epoch: 13 [32000/248297 (13%)]\tLoss: 0.455708\nTrain Epoch: 13 [33000/248297 (13%)]\tLoss: 0.459439\nTrain Epoch: 13 [34000/248297 (14%)]\tLoss: 0.519614\nTrain Epoch: 13 [35000/248297 (14%)]\tLoss: 0.475162\nTrain Epoch: 13 [36000/248297 (15%)]\tLoss: 0.678055\nTrain Epoch: 13 [37000/248297 (15%)]\tLoss: 0.512335\nTrain Epoch: 13 [38000/248297 (15%)]\tLoss: 0.581676\nTrain Epoch: 13 [39000/248297 (16%)]\tLoss: 0.429664\nTrain Epoch: 13 [40000/248297 (16%)]\tLoss: 0.411217\nTrain Epoch: 13 [41000/248297 (17%)]\tLoss: 0.453488\nTrain Epoch: 13 [42000/248297 (17%)]\tLoss: 0.524302\nTrain Epoch: 13 [43000/248297 (17%)]\tLoss: 0.476180\nTrain Epoch: 13 [44000/248297 (18%)]\tLoss: 0.441528\nTrain Epoch: 13 [45000/248297 (18%)]\tLoss: 0.422143\nTrain Epoch: 13 [46000/248297 (19%)]\tLoss: 0.552005\nTrain Epoch: 13 [47000/248297 (19%)]\tLoss: 0.447239\nTrain Epoch: 13 [48000/248297 (19%)]\tLoss: 0.473023\nTrain Epoch: 13 [49000/248297 (20%)]\tLoss: 0.549615\nTrain Epoch: 13 [50000/248297 (20%)]\tLoss: 0.507659\nTrain Epoch: 13 [51000/248297 (21%)]\tLoss: 0.473661\nTrain Epoch: 13 [52000/248297 (21%)]\tLoss: 0.446816\nTrain Epoch: 13 [53000/248297 (21%)]\tLoss: 0.517759\nTrain Epoch: 13 [54000/248297 (22%)]\tLoss: 0.478137\nTrain Epoch: 13 [55000/248297 (22%)]\tLoss: 0.551978\nTrain Epoch: 13 [56000/248297 (23%)]\tLoss: 0.531553\nTrain Epoch: 13 [57000/248297 (23%)]\tLoss: 0.530421\nTrain Epoch: 13 [58000/248297 (23%)]\tLoss: 0.470562\nTrain Epoch: 13 [59000/248297 (24%)]\tLoss: 0.505391\nTrain Epoch: 13 [60000/248297 (24%)]\tLoss: 0.481764\nTrain Epoch: 13 [61000/248297 (25%)]\tLoss: 0.462696\nTrain Epoch: 13 [62000/248297 (25%)]\tLoss: 0.476360\nTrain Epoch: 13 [63000/248297 (25%)]\tLoss: 0.536114\nTrain Epoch: 13 [64000/248297 (26%)]\tLoss: 0.523428\nTrain Epoch: 13 [65000/248297 (26%)]\tLoss: 0.469309\nTrain Epoch: 13 [66000/248297 (27%)]\tLoss: 0.556659\nTrain Epoch: 13 [67000/248297 (27%)]\tLoss: 0.436271\nTrain Epoch: 13 [68000/248297 (27%)]\tLoss: 0.413025\nTrain Epoch: 13 [69000/248297 (28%)]\tLoss: 0.439506\nTrain Epoch: 13 [70000/248297 (28%)]\tLoss: 0.554309\nTrain Epoch: 13 [71000/248297 (29%)]\tLoss: 0.464578\nTrain Epoch: 13 [72000/248297 (29%)]\tLoss: 0.418075\nTrain Epoch: 13 [73000/248297 (29%)]\tLoss: 0.465822\nTrain Epoch: 13 [74000/248297 (30%)]\tLoss: 0.491777\nTrain Epoch: 13 [75000/248297 (30%)]\tLoss: 0.426056\nTrain Epoch: 13 [76000/248297 (31%)]\tLoss: 0.495669\nTrain Epoch: 13 [77000/248297 (31%)]\tLoss: 0.542086\nTrain Epoch: 13 [78000/248297 (31%)]\tLoss: 0.518515\nTrain Epoch: 13 [79000/248297 (32%)]\tLoss: 0.518532\nTrain Epoch: 13 [80000/248297 (32%)]\tLoss: 0.471813\nTrain Epoch: 13 [81000/248297 (33%)]\tLoss: 0.319080\nTrain Epoch: 13 [82000/248297 (33%)]\tLoss: 0.550488\nTrain Epoch: 13 [83000/248297 (33%)]\tLoss: 0.428305\nTrain Epoch: 13 [84000/248297 (34%)]\tLoss: 0.464984\nTrain Epoch: 13 [85000/248297 (34%)]\tLoss: 0.581318\nTrain Epoch: 13 [86000/248297 (35%)]\tLoss: 0.461046\nTrain Epoch: 13 [87000/248297 (35%)]\tLoss: 0.483395\nTrain Epoch: 13 [88000/248297 (35%)]\tLoss: 0.566292\nTrain Epoch: 13 [89000/248297 (36%)]\tLoss: 0.469427\nTrain Epoch: 13 [90000/248297 (36%)]\tLoss: 0.477434\nTrain Epoch: 13 [91000/248297 (37%)]\tLoss: 0.548048\nTrain Epoch: 13 [92000/248297 (37%)]\tLoss: 0.569166\nTrain Epoch: 13 [93000/248297 (37%)]\tLoss: 0.508085\nTrain Epoch: 13 [94000/248297 (38%)]\tLoss: 0.518528\nTrain Epoch: 13 [95000/248297 (38%)]\tLoss: 0.491384\nTrain Epoch: 13 [96000/248297 (39%)]\tLoss: 0.465878\nTrain Epoch: 13 [97000/248297 (39%)]\tLoss: 0.447156\nTrain Epoch: 13 [98000/248297 (39%)]\tLoss: 0.499072\nTrain Epoch: 13 [99000/248297 (40%)]\tLoss: 0.471453\nTrain Epoch: 13 [100000/248297 (40%)]\tLoss: 0.539333\nTrain Epoch: 13 [101000/248297 (41%)]\tLoss: 0.438745\nTrain Epoch: 13 [102000/248297 (41%)]\tLoss: 0.441876\nTrain Epoch: 13 [103000/248297 (41%)]\tLoss: 0.426015\nTrain Epoch: 13 [104000/248297 (42%)]\tLoss: 0.463486\nTrain Epoch: 13 [105000/248297 (42%)]\tLoss: 0.354717\nTrain Epoch: 13 [106000/248297 (43%)]\tLoss: 0.506126\nTrain Epoch: 13 [107000/248297 (43%)]\tLoss: 0.542990\nTrain Epoch: 13 [108000/248297 (44%)]\tLoss: 0.510478\nTrain Epoch: 13 [109000/248297 (44%)]\tLoss: 0.476055\nTrain Epoch: 13 [110000/248297 (44%)]\tLoss: 0.501632\nTrain Epoch: 13 [111000/248297 (45%)]\tLoss: 0.438317\nTrain Epoch: 13 [112000/248297 (45%)]\tLoss: 0.500049\nTrain Epoch: 13 [113000/248297 (46%)]\tLoss: 0.407188\nTrain Epoch: 13 [114000/248297 (46%)]\tLoss: 0.471362\nTrain Epoch: 13 [115000/248297 (46%)]\tLoss: 0.432991\nTrain Epoch: 13 [116000/248297 (47%)]\tLoss: 0.394637\nTrain Epoch: 13 [117000/248297 (47%)]\tLoss: 0.449184\nTrain Epoch: 13 [118000/248297 (48%)]\tLoss: 0.448828\nTrain Epoch: 13 [119000/248297 (48%)]\tLoss: 0.489964\nTrain Epoch: 13 [120000/248297 (48%)]\tLoss: 0.487652\nTrain Epoch: 13 [121000/248297 (49%)]\tLoss: 0.518627\nTrain Epoch: 13 [122000/248297 (49%)]\tLoss: 0.605188\nTrain Epoch: 13 [123000/248297 (50%)]\tLoss: 0.475774\nTrain Epoch: 13 [124000/248297 (50%)]\tLoss: 0.470788\nTrain Epoch: 13 [125000/248297 (50%)]\tLoss: 0.500541\nTrain Epoch: 13 [126000/248297 (51%)]\tLoss: 0.481438\nTrain Epoch: 13 [127000/248297 (51%)]\tLoss: 0.519461\nTrain Epoch: 13 [128000/248297 (52%)]\tLoss: 0.506726\nTrain Epoch: 13 [129000/248297 (52%)]\tLoss: 0.485706\nTrain Epoch: 13 [130000/248297 (52%)]\tLoss: 0.515594\nTrain Epoch: 13 [131000/248297 (53%)]\tLoss: 0.527067\nTrain Epoch: 13 [132000/248297 (53%)]\tLoss: 0.613490\nTrain Epoch: 13 [133000/248297 (54%)]\tLoss: 0.520492\nTrain Epoch: 13 [134000/248297 (54%)]\tLoss: 0.487045\nTrain Epoch: 13 [135000/248297 (54%)]\tLoss: 0.455542\nTrain Epoch: 13 [136000/248297 (55%)]\tLoss: 0.544306\nTrain Epoch: 13 [137000/248297 (55%)]\tLoss: 0.560908\nTrain Epoch: 13 [138000/248297 (56%)]\tLoss: 0.462600\nTrain Epoch: 13 [139000/248297 (56%)]\tLoss: 0.442660\nTrain Epoch: 13 [140000/248297 (56%)]\tLoss: 0.472469\nTrain Epoch: 13 [141000/248297 (57%)]\tLoss: 0.419394\nTrain Epoch: 13 [142000/248297 (57%)]\tLoss: 0.516876\nTrain Epoch: 13 [143000/248297 (58%)]\tLoss: 0.478571\nTrain Epoch: 13 [144000/248297 (58%)]\tLoss: 0.487279\nTrain Epoch: 13 [145000/248297 (58%)]\tLoss: 0.433811\nTrain Epoch: 13 [146000/248297 (59%)]\tLoss: 0.621005\nTrain Epoch: 13 [147000/248297 (59%)]\tLoss: 0.481193\nTrain Epoch: 13 [148000/248297 (60%)]\tLoss: 0.465492\nTrain Epoch: 13 [149000/248297 (60%)]\tLoss: 0.441609\nTrain Epoch: 13 [150000/248297 (60%)]\tLoss: 0.576663\nTrain Epoch: 13 [151000/248297 (61%)]\tLoss: 0.528565\nTrain Epoch: 13 [152000/248297 (61%)]\tLoss: 0.429577\nTrain Epoch: 13 [153000/248297 (62%)]\tLoss: 0.460509\nTrain Epoch: 13 [154000/248297 (62%)]\tLoss: 0.463917\nTrain Epoch: 13 [155000/248297 (62%)]\tLoss: 0.409837\nTrain Epoch: 13 [156000/248297 (63%)]\tLoss: 0.411940\nTrain Epoch: 13 [157000/248297 (63%)]\tLoss: 0.492376\nTrain Epoch: 13 [158000/248297 (64%)]\tLoss: 0.411097\nTrain Epoch: 13 [159000/248297 (64%)]\tLoss: 0.518806\nTrain Epoch: 13 [160000/248297 (64%)]\tLoss: 0.450029\nTrain Epoch: 13 [161000/248297 (65%)]\tLoss: 0.460386\nTrain Epoch: 13 [162000/248297 (65%)]\tLoss: 0.463335\nTrain Epoch: 13 [163000/248297 (66%)]\tLoss: 0.511534\nTrain Epoch: 13 [164000/248297 (66%)]\tLoss: 0.442106\nTrain Epoch: 13 [165000/248297 (66%)]\tLoss: 0.573665\nTrain Epoch: 13 [166000/248297 (67%)]\tLoss: 0.457281\nTrain Epoch: 13 [167000/248297 (67%)]\tLoss: 0.496741\nTrain Epoch: 13 [168000/248297 (68%)]\tLoss: 0.532422\nTrain Epoch: 13 [169000/248297 (68%)]\tLoss: 0.457036\nTrain Epoch: 13 [170000/248297 (68%)]\tLoss: 0.593667\nTrain Epoch: 13 [171000/248297 (69%)]\tLoss: 0.557736\nTrain Epoch: 13 [172000/248297 (69%)]\tLoss: 0.505473\nTrain Epoch: 13 [173000/248297 (70%)]\tLoss: 0.471645\nTrain Epoch: 13 [174000/248297 (70%)]\tLoss: 0.535680\nTrain Epoch: 13 [175000/248297 (71%)]\tLoss: 0.534282\nTrain Epoch: 13 [176000/248297 (71%)]\tLoss: 0.610155\nTrain Epoch: 13 [177000/248297 (71%)]\tLoss: 0.517056\nTrain Epoch: 13 [178000/248297 (72%)]\tLoss: 0.514000\nTrain Epoch: 13 [179000/248297 (72%)]\tLoss: 0.528412\nTrain Epoch: 13 [180000/248297 (73%)]\tLoss: 0.415824\nTrain Epoch: 13 [181000/248297 (73%)]\tLoss: 0.448302\nTrain Epoch: 13 [182000/248297 (73%)]\tLoss: 0.540207\nTrain Epoch: 13 [183000/248297 (74%)]\tLoss: 0.459721\nTrain Epoch: 13 [184000/248297 (74%)]\tLoss: 0.431904\nTrain Epoch: 13 [185000/248297 (75%)]\tLoss: 0.472344\nTrain Epoch: 13 [186000/248297 (75%)]\tLoss: 0.451296\nTrain Epoch: 13 [187000/248297 (75%)]\tLoss: 0.475270\nTrain Epoch: 13 [188000/248297 (76%)]\tLoss: 0.505663\nTrain Epoch: 13 [189000/248297 (76%)]\tLoss: 0.536812\nTrain Epoch: 13 [190000/248297 (77%)]\tLoss: 0.372639\nTrain Epoch: 13 [191000/248297 (77%)]\tLoss: 0.504589\nTrain Epoch: 13 [192000/248297 (77%)]\tLoss: 0.557472\nTrain Epoch: 13 [193000/248297 (78%)]\tLoss: 0.493598\nTrain Epoch: 13 [194000/248297 (78%)]\tLoss: 0.447185\nTrain Epoch: 13 [195000/248297 (79%)]\tLoss: 0.558983\nTrain Epoch: 13 [196000/248297 (79%)]\tLoss: 0.556651\nTrain Epoch: 13 [197000/248297 (79%)]\tLoss: 0.454906\nTrain Epoch: 13 [198000/248297 (80%)]\tLoss: 0.434137\nTrain Epoch: 13 [199000/248297 (80%)]\tLoss: 0.584757\nTrain Epoch: 13 [200000/248297 (81%)]\tLoss: 0.537898\nTrain Epoch: 13 [201000/248297 (81%)]\tLoss: 0.481120\nTrain Epoch: 13 [202000/248297 (81%)]\tLoss: 0.440614\nTrain Epoch: 13 [203000/248297 (82%)]\tLoss: 0.470324\nTrain Epoch: 13 [204000/248297 (82%)]\tLoss: 0.586177\nTrain Epoch: 13 [205000/248297 (83%)]\tLoss: 0.497748\nTrain Epoch: 13 [206000/248297 (83%)]\tLoss: 0.481110\nTrain Epoch: 13 [207000/248297 (83%)]\tLoss: 0.390794\nTrain Epoch: 13 [208000/248297 (84%)]\tLoss: 0.501958\nTrain Epoch: 13 [209000/248297 (84%)]\tLoss: 0.419156\nTrain Epoch: 13 [210000/248297 (85%)]\tLoss: 0.471134\nTrain Epoch: 13 [211000/248297 (85%)]\tLoss: 0.583037\nTrain Epoch: 13 [212000/248297 (85%)]\tLoss: 0.570984\nTrain Epoch: 13 [213000/248297 (86%)]\tLoss: 0.484668\nTrain Epoch: 13 [214000/248297 (86%)]\tLoss: 0.629324\nTrain Epoch: 13 [215000/248297 (87%)]\tLoss: 0.445445\nTrain Epoch: 13 [216000/248297 (87%)]\tLoss: 0.435349\nTrain Epoch: 13 [217000/248297 (87%)]\tLoss: 0.353340\nTrain Epoch: 13 [218000/248297 (88%)]\tLoss: 0.484469\nTrain Epoch: 13 [219000/248297 (88%)]\tLoss: 0.516770\nTrain Epoch: 13 [220000/248297 (89%)]\tLoss: 0.438844\nTrain Epoch: 13 [221000/248297 (89%)]\tLoss: 0.407973\nTrain Epoch: 13 [222000/248297 (89%)]\tLoss: 0.525301\nTrain Epoch: 13 [223000/248297 (90%)]\tLoss: 0.494933\nTrain Epoch: 13 [224000/248297 (90%)]\tLoss: 0.483363\nTrain Epoch: 13 [225000/248297 (91%)]\tLoss: 0.445807\nTrain Epoch: 13 [226000/248297 (91%)]\tLoss: 0.457822\nTrain Epoch: 13 [227000/248297 (91%)]\tLoss: 0.382809\nTrain Epoch: 13 [228000/248297 (92%)]\tLoss: 0.459403\nTrain Epoch: 13 [229000/248297 (92%)]\tLoss: 0.537621\nTrain Epoch: 13 [230000/248297 (93%)]\tLoss: 0.428032\nTrain Epoch: 13 [231000/248297 (93%)]\tLoss: 0.440187\nTrain Epoch: 13 [232000/248297 (93%)]\tLoss: 0.538765\nTrain Epoch: 13 [233000/248297 (94%)]\tLoss: 0.472519\nTrain Epoch: 13 [234000/248297 (94%)]\tLoss: 0.513470\nTrain Epoch: 13 [235000/248297 (95%)]\tLoss: 0.508396\nTrain Epoch: 13 [236000/248297 (95%)]\tLoss: 0.419783\nTrain Epoch: 13 [237000/248297 (95%)]\tLoss: 0.400775\nTrain Epoch: 13 [238000/248297 (96%)]\tLoss: 0.517732\nTrain Epoch: 13 [239000/248297 (96%)]\tLoss: 0.450133\nTrain Epoch: 13 [240000/248297 (97%)]\tLoss: 0.456063\nTrain Epoch: 13 [241000/248297 (97%)]\tLoss: 0.485747\nTrain Epoch: 13 [242000/248297 (98%)]\tLoss: 0.498263\nTrain Epoch: 13 [243000/248297 (98%)]\tLoss: 0.587815\nTrain Epoch: 13 [244000/248297 (98%)]\tLoss: 0.497068\nTrain Epoch: 13 [245000/248297 (99%)]\tLoss: 0.453247\nTrain Epoch: 13 [246000/248297 (99%)]\tLoss: 0.446408\nTrain Epoch: 13 [247000/248297 (100%)]\tLoss: 0.387366\nTrain Epoch: 13 [248000/248297 (100%)]\tLoss: 0.551890\n\nTest set: Average loss: 0.0050, Accuracy: 20755/27589 (75%)\n\nTrain Epoch: 14 [0/248297 (0%)]\tLoss: 0.464341\nTrain Epoch: 14 [1000/248297 (0%)]\tLoss: 0.396164\nTrain Epoch: 14 [2000/248297 (1%)]\tLoss: 0.541206\nTrain Epoch: 14 [3000/248297 (1%)]\tLoss: 0.393669\nTrain Epoch: 14 [4000/248297 (2%)]\tLoss: 0.500463\nTrain Epoch: 14 [5000/248297 (2%)]\tLoss: 0.495444\nTrain Epoch: 14 [6000/248297 (2%)]\tLoss: 0.349645\nTrain Epoch: 14 [7000/248297 (3%)]\tLoss: 0.508005\nTrain Epoch: 14 [8000/248297 (3%)]\tLoss: 0.410003\nTrain Epoch: 14 [9000/248297 (4%)]\tLoss: 0.502028\nTrain Epoch: 14 [10000/248297 (4%)]\tLoss: 0.423811\nTrain Epoch: 14 [11000/248297 (4%)]\tLoss: 0.486946\nTrain Epoch: 14 [12000/248297 (5%)]\tLoss: 0.519664\nTrain Epoch: 14 [13000/248297 (5%)]\tLoss: 0.467480\nTrain Epoch: 14 [14000/248297 (6%)]\tLoss: 0.552525\nTrain Epoch: 14 [15000/248297 (6%)]\tLoss: 0.482104\nTrain Epoch: 14 [16000/248297 (6%)]\tLoss: 0.546694\nTrain Epoch: 14 [17000/248297 (7%)]\tLoss: 0.468385\nTrain Epoch: 14 [18000/248297 (7%)]\tLoss: 0.446049\nTrain Epoch: 14 [19000/248297 (8%)]\tLoss: 0.420015\nTrain Epoch: 14 [20000/248297 (8%)]\tLoss: 0.486686\nTrain Epoch: 14 [21000/248297 (8%)]\tLoss: 0.471813\nTrain Epoch: 14 [22000/248297 (9%)]\tLoss: 0.515142\nTrain Epoch: 14 [23000/248297 (9%)]\tLoss: 0.511938\nTrain Epoch: 14 [24000/248297 (10%)]\tLoss: 0.490922\nTrain Epoch: 14 [25000/248297 (10%)]\tLoss: 0.506217\nTrain Epoch: 14 [26000/248297 (10%)]\tLoss: 0.462459\nTrain Epoch: 14 [27000/248297 (11%)]\tLoss: 0.415349\nTrain Epoch: 14 [28000/248297 (11%)]\tLoss: 0.453467\nTrain Epoch: 14 [29000/248297 (12%)]\tLoss: 0.473563\nTrain Epoch: 14 [30000/248297 (12%)]\tLoss: 0.504232\nTrain Epoch: 14 [31000/248297 (12%)]\tLoss: 0.483965\nTrain Epoch: 14 [32000/248297 (13%)]\tLoss: 0.467243\nTrain Epoch: 14 [33000/248297 (13%)]\tLoss: 0.494493\nTrain Epoch: 14 [34000/248297 (14%)]\tLoss: 0.509886\nTrain Epoch: 14 [35000/248297 (14%)]\tLoss: 0.429865\nTrain Epoch: 14 [36000/248297 (15%)]\tLoss: 0.471444\nTrain Epoch: 14 [37000/248297 (15%)]\tLoss: 0.492832\nTrain Epoch: 14 [38000/248297 (15%)]\tLoss: 0.504818\nTrain Epoch: 14 [39000/248297 (16%)]\tLoss: 0.497870\nTrain Epoch: 14 [40000/248297 (16%)]\tLoss: 0.514474\nTrain Epoch: 14 [41000/248297 (17%)]\tLoss: 0.475389\nTrain Epoch: 14 [42000/248297 (17%)]\tLoss: 0.479057\nTrain Epoch: 14 [43000/248297 (17%)]\tLoss: 0.520428\nTrain Epoch: 14 [44000/248297 (18%)]\tLoss: 0.423952\nTrain Epoch: 14 [45000/248297 (18%)]\tLoss: 0.467693\nTrain Epoch: 14 [46000/248297 (19%)]\tLoss: 0.443908\nTrain Epoch: 14 [47000/248297 (19%)]\tLoss: 0.403780\nTrain Epoch: 14 [48000/248297 (19%)]\tLoss: 0.414838\nTrain Epoch: 14 [49000/248297 (20%)]\tLoss: 0.548774\nTrain Epoch: 14 [50000/248297 (20%)]\tLoss: 0.496300\nTrain Epoch: 14 [51000/248297 (21%)]\tLoss: 0.457302\nTrain Epoch: 14 [52000/248297 (21%)]\tLoss: 0.504785\nTrain Epoch: 14 [53000/248297 (21%)]\tLoss: 0.453692\nTrain Epoch: 14 [54000/248297 (22%)]\tLoss: 0.523961\nTrain Epoch: 14 [55000/248297 (22%)]\tLoss: 0.486038\nTrain Epoch: 14 [56000/248297 (23%)]\tLoss: 0.412333\nTrain Epoch: 14 [57000/248297 (23%)]\tLoss: 0.468982\nTrain Epoch: 14 [58000/248297 (23%)]\tLoss: 0.471442\nTrain Epoch: 14 [59000/248297 (24%)]\tLoss: 0.422706\nTrain Epoch: 14 [60000/248297 (24%)]\tLoss: 0.465380\nTrain Epoch: 14 [61000/248297 (25%)]\tLoss: 0.498579\nTrain Epoch: 14 [62000/248297 (25%)]\tLoss: 0.454230\nTrain Epoch: 14 [63000/248297 (25%)]\tLoss: 0.562824\nTrain Epoch: 14 [64000/248297 (26%)]\tLoss: 0.440224\nTrain Epoch: 14 [65000/248297 (26%)]\tLoss: 0.525742\nTrain Epoch: 14 [66000/248297 (27%)]\tLoss: 0.527182\nTrain Epoch: 14 [67000/248297 (27%)]\tLoss: 0.521972\nTrain Epoch: 14 [68000/248297 (27%)]\tLoss: 0.482385\nTrain Epoch: 14 [69000/248297 (28%)]\tLoss: 0.472475\nTrain Epoch: 14 [70000/248297 (28%)]\tLoss: 0.524862\nTrain Epoch: 14 [71000/248297 (29%)]\tLoss: 0.428458\nTrain Epoch: 14 [72000/248297 (29%)]\tLoss: 0.480350\nTrain Epoch: 14 [73000/248297 (29%)]\tLoss: 0.514199\nTrain Epoch: 14 [74000/248297 (30%)]\tLoss: 0.581517\nTrain Epoch: 14 [75000/248297 (30%)]\tLoss: 0.428847\nTrain Epoch: 14 [76000/248297 (31%)]\tLoss: 0.474262\nTrain Epoch: 14 [77000/248297 (31%)]\tLoss: 0.510091\nTrain Epoch: 14 [78000/248297 (31%)]\tLoss: 0.455974\nTrain Epoch: 14 [79000/248297 (32%)]\tLoss: 0.465418\nTrain Epoch: 14 [80000/248297 (32%)]\tLoss: 0.549337\nTrain Epoch: 14 [81000/248297 (33%)]\tLoss: 0.462574\nTrain Epoch: 14 [82000/248297 (33%)]\tLoss: 0.521127\nTrain Epoch: 14 [83000/248297 (33%)]\tLoss: 0.470484\nTrain Epoch: 14 [84000/248297 (34%)]\tLoss: 0.549288\nTrain Epoch: 14 [85000/248297 (34%)]\tLoss: 0.452155\nTrain Epoch: 14 [86000/248297 (35%)]\tLoss: 0.490670\nTrain Epoch: 14 [87000/248297 (35%)]\tLoss: 0.504894\nTrain Epoch: 14 [88000/248297 (35%)]\tLoss: 0.483943\nTrain Epoch: 14 [89000/248297 (36%)]\tLoss: 0.404713\nTrain Epoch: 14 [90000/248297 (36%)]\tLoss: 0.558166\nTrain Epoch: 14 [91000/248297 (37%)]\tLoss: 0.455880\nTrain Epoch: 14 [92000/248297 (37%)]\tLoss: 0.483147\nTrain Epoch: 14 [93000/248297 (37%)]\tLoss: 0.565743\nTrain Epoch: 14 [94000/248297 (38%)]\tLoss: 0.511308\nTrain Epoch: 14 [95000/248297 (38%)]\tLoss: 0.446614\nTrain Epoch: 14 [96000/248297 (39%)]\tLoss: 0.502080\nTrain Epoch: 14 [97000/248297 (39%)]\tLoss: 0.478847\nTrain Epoch: 14 [98000/248297 (39%)]\tLoss: 0.442230\nTrain Epoch: 14 [99000/248297 (40%)]\tLoss: 0.516099\nTrain Epoch: 14 [100000/248297 (40%)]\tLoss: 0.431614\nTrain Epoch: 14 [101000/248297 (41%)]\tLoss: 0.505008\nTrain Epoch: 14 [102000/248297 (41%)]\tLoss: 0.514510\nTrain Epoch: 14 [103000/248297 (41%)]\tLoss: 0.417033\nTrain Epoch: 14 [104000/248297 (42%)]\tLoss: 0.531575\nTrain Epoch: 14 [105000/248297 (42%)]\tLoss: 0.459730\nTrain Epoch: 14 [106000/248297 (43%)]\tLoss: 0.451467\nTrain Epoch: 14 [107000/248297 (43%)]\tLoss: 0.529576\nTrain Epoch: 14 [108000/248297 (44%)]\tLoss: 0.527319\nTrain Epoch: 14 [109000/248297 (44%)]\tLoss: 0.441345\nTrain Epoch: 14 [110000/248297 (44%)]\tLoss: 0.507094\nTrain Epoch: 14 [111000/248297 (45%)]\tLoss: 0.528416\nTrain Epoch: 14 [112000/248297 (45%)]\tLoss: 0.458100\nTrain Epoch: 14 [113000/248297 (46%)]\tLoss: 0.492928\nTrain Epoch: 14 [114000/248297 (46%)]\tLoss: 0.492476\nTrain Epoch: 14 [115000/248297 (46%)]\tLoss: 0.490606\nTrain Epoch: 14 [116000/248297 (47%)]\tLoss: 0.493445\nTrain Epoch: 14 [117000/248297 (47%)]\tLoss: 0.402242\nTrain Epoch: 14 [118000/248297 (48%)]\tLoss: 0.552861\nTrain Epoch: 14 [119000/248297 (48%)]\tLoss: 0.543740\nTrain Epoch: 14 [120000/248297 (48%)]\tLoss: 0.478933\nTrain Epoch: 14 [121000/248297 (49%)]\tLoss: 0.499619\nTrain Epoch: 14 [122000/248297 (49%)]\tLoss: 0.501865\nTrain Epoch: 14 [123000/248297 (50%)]\tLoss: 0.435692\nTrain Epoch: 14 [124000/248297 (50%)]\tLoss: 0.465697\nTrain Epoch: 14 [125000/248297 (50%)]\tLoss: 0.443064\nTrain Epoch: 14 [126000/248297 (51%)]\tLoss: 0.455467\nTrain Epoch: 14 [127000/248297 (51%)]\tLoss: 0.440577\nTrain Epoch: 14 [128000/248297 (52%)]\tLoss: 0.470487\nTrain Epoch: 14 [129000/248297 (52%)]\tLoss: 0.578050\nTrain Epoch: 14 [130000/248297 (52%)]\tLoss: 0.492551\nTrain Epoch: 14 [131000/248297 (53%)]\tLoss: 0.550310\nTrain Epoch: 14 [132000/248297 (53%)]\tLoss: 0.459936\nTrain Epoch: 14 [133000/248297 (54%)]\tLoss: 0.424221\nTrain Epoch: 14 [134000/248297 (54%)]\tLoss: 0.407705\nTrain Epoch: 14 [135000/248297 (54%)]\tLoss: 0.532358\nTrain Epoch: 14 [136000/248297 (55%)]\tLoss: 0.558459\nTrain Epoch: 14 [137000/248297 (55%)]\tLoss: 0.471509\nTrain Epoch: 14 [138000/248297 (56%)]\tLoss: 0.407919\nTrain Epoch: 14 [139000/248297 (56%)]\tLoss: 0.544196\nTrain Epoch: 14 [140000/248297 (56%)]\tLoss: 0.490722\nTrain Epoch: 14 [141000/248297 (57%)]\tLoss: 0.525607\nTrain Epoch: 14 [142000/248297 (57%)]\tLoss: 0.482290\nTrain Epoch: 14 [143000/248297 (58%)]\tLoss: 0.511312\nTrain Epoch: 14 [144000/248297 (58%)]\tLoss: 0.478714\nTrain Epoch: 14 [145000/248297 (58%)]\tLoss: 0.415770\nTrain Epoch: 14 [146000/248297 (59%)]\tLoss: 0.481631\nTrain Epoch: 14 [147000/248297 (59%)]\tLoss: 0.494846\nTrain Epoch: 14 [148000/248297 (60%)]\tLoss: 0.631667\nTrain Epoch: 14 [149000/248297 (60%)]\tLoss: 0.447833\nTrain Epoch: 14 [150000/248297 (60%)]\tLoss: 0.488810\nTrain Epoch: 14 [151000/248297 (61%)]\tLoss: 0.424273\nTrain Epoch: 14 [152000/248297 (61%)]\tLoss: 0.566927\nTrain Epoch: 14 [153000/248297 (62%)]\tLoss: 0.375989\nTrain Epoch: 14 [154000/248297 (62%)]\tLoss: 0.584907\nTrain Epoch: 14 [155000/248297 (62%)]\tLoss: 0.555989\nTrain Epoch: 14 [156000/248297 (63%)]\tLoss: 0.499828\nTrain Epoch: 14 [157000/248297 (63%)]\tLoss: 0.428010\nTrain Epoch: 14 [158000/248297 (64%)]\tLoss: 0.413062\nTrain Epoch: 14 [159000/248297 (64%)]\tLoss: 0.506274\nTrain Epoch: 14 [160000/248297 (64%)]\tLoss: 0.459506\nTrain Epoch: 14 [161000/248297 (65%)]\tLoss: 0.517871\nTrain Epoch: 14 [162000/248297 (65%)]\tLoss: 0.453124\nTrain Epoch: 14 [163000/248297 (66%)]\tLoss: 0.577130\nTrain Epoch: 14 [164000/248297 (66%)]\tLoss: 0.455189\nTrain Epoch: 14 [165000/248297 (66%)]\tLoss: 0.467685\nTrain Epoch: 14 [166000/248297 (67%)]\tLoss: 0.581336\nTrain Epoch: 14 [167000/248297 (67%)]\tLoss: 0.532731\nTrain Epoch: 14 [168000/248297 (68%)]\tLoss: 0.424252\nTrain Epoch: 14 [169000/248297 (68%)]\tLoss: 0.564925\nTrain Epoch: 14 [170000/248297 (68%)]\tLoss: 0.572397\nTrain Epoch: 14 [171000/248297 (69%)]\tLoss: 0.458765\nTrain Epoch: 14 [172000/248297 (69%)]\tLoss: 0.500303\nTrain Epoch: 14 [173000/248297 (70%)]\tLoss: 0.473591\nTrain Epoch: 14 [174000/248297 (70%)]\tLoss: 0.484665\nTrain Epoch: 14 [175000/248297 (71%)]\tLoss: 0.427817\nTrain Epoch: 14 [176000/248297 (71%)]\tLoss: 0.464770\nTrain Epoch: 14 [177000/248297 (71%)]\tLoss: 0.556820\nTrain Epoch: 14 [178000/248297 (72%)]\tLoss: 0.463304\nTrain Epoch: 14 [179000/248297 (72%)]\tLoss: 0.502782\nTrain Epoch: 14 [180000/248297 (73%)]\tLoss: 0.472134\nTrain Epoch: 14 [181000/248297 (73%)]\tLoss: 0.389831\nTrain Epoch: 14 [182000/248297 (73%)]\tLoss: 0.487023\nTrain Epoch: 14 [183000/248297 (74%)]\tLoss: 0.504556\nTrain Epoch: 14 [184000/248297 (74%)]\tLoss: 0.518143\nTrain Epoch: 14 [185000/248297 (75%)]\tLoss: 0.516485\nTrain Epoch: 14 [186000/248297 (75%)]\tLoss: 0.466996\nTrain Epoch: 14 [187000/248297 (75%)]\tLoss: 0.494400\nTrain Epoch: 14 [188000/248297 (76%)]\tLoss: 0.531963\nTrain Epoch: 14 [189000/248297 (76%)]\tLoss: 0.505940\nTrain Epoch: 14 [190000/248297 (77%)]\tLoss: 0.452708\nTrain Epoch: 14 [191000/248297 (77%)]\tLoss: 0.483484\nTrain Epoch: 14 [192000/248297 (77%)]\tLoss: 0.476399\nTrain Epoch: 14 [193000/248297 (78%)]\tLoss: 0.576129\nTrain Epoch: 14 [194000/248297 (78%)]\tLoss: 0.429937\nTrain Epoch: 14 [195000/248297 (79%)]\tLoss: 0.521233\nTrain Epoch: 14 [196000/248297 (79%)]\tLoss: 0.437872\nTrain Epoch: 14 [197000/248297 (79%)]\tLoss: 0.503441\nTrain Epoch: 14 [198000/248297 (80%)]\tLoss: 0.454361\nTrain Epoch: 14 [199000/248297 (80%)]\tLoss: 0.397566\nTrain Epoch: 14 [200000/248297 (81%)]\tLoss: 0.466547\nTrain Epoch: 14 [201000/248297 (81%)]\tLoss: 0.494661\nTrain Epoch: 14 [202000/248297 (81%)]\tLoss: 0.403531\nTrain Epoch: 14 [203000/248297 (82%)]\tLoss: 0.463002\nTrain Epoch: 14 [204000/248297 (82%)]\tLoss: 0.407385\nTrain Epoch: 14 [205000/248297 (83%)]\tLoss: 0.475182\nTrain Epoch: 14 [206000/248297 (83%)]\tLoss: 0.481062\nTrain Epoch: 14 [207000/248297 (83%)]\tLoss: 0.548095\nTrain Epoch: 14 [208000/248297 (84%)]\tLoss: 0.542069\nTrain Epoch: 14 [209000/248297 (84%)]\tLoss: 0.413993\nTrain Epoch: 14 [210000/248297 (85%)]\tLoss: 0.581903\nTrain Epoch: 14 [211000/248297 (85%)]\tLoss: 0.485415\nTrain Epoch: 14 [212000/248297 (85%)]\tLoss: 0.531633\nTrain Epoch: 14 [213000/248297 (86%)]\tLoss: 0.504060\nTrain Epoch: 14 [214000/248297 (86%)]\tLoss: 0.491030\nTrain Epoch: 14 [215000/248297 (87%)]\tLoss: 0.544319\nTrain Epoch: 14 [216000/248297 (87%)]\tLoss: 0.487021\nTrain Epoch: 14 [217000/248297 (87%)]\tLoss: 0.536360\nTrain Epoch: 14 [218000/248297 (88%)]\tLoss: 0.447870\nTrain Epoch: 14 [219000/248297 (88%)]\tLoss: 0.468991\nTrain Epoch: 14 [220000/248297 (89%)]\tLoss: 0.508996\nTrain Epoch: 14 [221000/248297 (89%)]\tLoss: 0.452532\nTrain Epoch: 14 [222000/248297 (89%)]\tLoss: 0.486416\nTrain Epoch: 14 [223000/248297 (90%)]\tLoss: 0.534150\nTrain Epoch: 14 [224000/248297 (90%)]\tLoss: 0.481315\nTrain Epoch: 14 [225000/248297 (91%)]\tLoss: 0.435533\nTrain Epoch: 14 [226000/248297 (91%)]\tLoss: 0.456387\nTrain Epoch: 14 [227000/248297 (91%)]\tLoss: 0.455836\nTrain Epoch: 14 [228000/248297 (92%)]\tLoss: 0.540930\nTrain Epoch: 14 [229000/248297 (92%)]\tLoss: 0.515799\nTrain Epoch: 14 [230000/248297 (93%)]\tLoss: 0.511640\nTrain Epoch: 14 [231000/248297 (93%)]\tLoss: 0.487389\nTrain Epoch: 14 [232000/248297 (93%)]\tLoss: 0.494686\nTrain Epoch: 14 [233000/248297 (94%)]\tLoss: 0.477076\nTrain Epoch: 14 [234000/248297 (94%)]\tLoss: 0.528869\nTrain Epoch: 14 [235000/248297 (95%)]\tLoss: 0.459112\nTrain Epoch: 14 [236000/248297 (95%)]\tLoss: 0.435282\nTrain Epoch: 14 [237000/248297 (95%)]\tLoss: 0.397173\nTrain Epoch: 14 [238000/248297 (96%)]\tLoss: 0.541369\nTrain Epoch: 14 [239000/248297 (96%)]\tLoss: 0.436488\nTrain Epoch: 14 [240000/248297 (97%)]\tLoss: 0.485276\nTrain Epoch: 14 [241000/248297 (97%)]\tLoss: 0.443123\nTrain Epoch: 14 [242000/248297 (98%)]\tLoss: 0.530148\nTrain Epoch: 14 [243000/248297 (98%)]\tLoss: 0.430571\nTrain Epoch: 14 [244000/248297 (98%)]\tLoss: 0.475704\nTrain Epoch: 14 [245000/248297 (99%)]\tLoss: 0.460488\nTrain Epoch: 14 [246000/248297 (99%)]\tLoss: 0.454033\nTrain Epoch: 14 [247000/248297 (100%)]\tLoss: 0.569738\nTrain Epoch: 14 [248000/248297 (100%)]\tLoss: 0.466899\n\nTest set: Average loss: 0.0050, Accuracy: 20718/27589 (75%)\n\nTrain Epoch: 15 [0/248297 (0%)]\tLoss: 0.463072\nTrain Epoch: 15 [1000/248297 (0%)]\tLoss: 0.454953\nTrain Epoch: 15 [2000/248297 (1%)]\tLoss: 0.557281\nTrain Epoch: 15 [3000/248297 (1%)]\tLoss: 0.536113\nTrain Epoch: 15 [4000/248297 (2%)]\tLoss: 0.491984\nTrain Epoch: 15 [5000/248297 (2%)]\tLoss: 0.452372\nTrain Epoch: 15 [6000/248297 (2%)]\tLoss: 0.503118\nTrain Epoch: 15 [7000/248297 (3%)]\tLoss: 0.551662\nTrain Epoch: 15 [8000/248297 (3%)]\tLoss: 0.460633\nTrain Epoch: 15 [9000/248297 (4%)]\tLoss: 0.472891\nTrain Epoch: 15 [10000/248297 (4%)]\tLoss: 0.500075\nTrain Epoch: 15 [11000/248297 (4%)]\tLoss: 0.448578\nTrain Epoch: 15 [12000/248297 (5%)]\tLoss: 0.550269\nTrain Epoch: 15 [13000/248297 (5%)]\tLoss: 0.466965\nTrain Epoch: 15 [14000/248297 (6%)]\tLoss: 0.549476\nTrain Epoch: 15 [15000/248297 (6%)]\tLoss: 0.471465\nTrain Epoch: 15 [16000/248297 (6%)]\tLoss: 0.536897\nTrain Epoch: 15 [17000/248297 (7%)]\tLoss: 0.550306\nTrain Epoch: 15 [18000/248297 (7%)]\tLoss: 0.472934\nTrain Epoch: 15 [19000/248297 (8%)]\tLoss: 0.417142\nTrain Epoch: 15 [20000/248297 (8%)]\tLoss: 0.515226\nTrain Epoch: 15 [21000/248297 (8%)]\tLoss: 0.531068\nTrain Epoch: 15 [22000/248297 (9%)]\tLoss: 0.386936\nTrain Epoch: 15 [23000/248297 (9%)]\tLoss: 0.467715\nTrain Epoch: 15 [24000/248297 (10%)]\tLoss: 0.468985\nTrain Epoch: 15 [25000/248297 (10%)]\tLoss: 0.444857\nTrain Epoch: 15 [26000/248297 (10%)]\tLoss: 0.472794\nTrain Epoch: 15 [27000/248297 (11%)]\tLoss: 0.493290\nTrain Epoch: 15 [28000/248297 (11%)]\tLoss: 0.520596\nTrain Epoch: 15 [29000/248297 (12%)]\tLoss: 0.530159\nTrain Epoch: 15 [30000/248297 (12%)]\tLoss: 0.459319\nTrain Epoch: 15 [31000/248297 (12%)]\tLoss: 0.496849\nTrain Epoch: 15 [32000/248297 (13%)]\tLoss: 0.458280\nTrain Epoch: 15 [33000/248297 (13%)]\tLoss: 0.504219\nTrain Epoch: 15 [34000/248297 (14%)]\tLoss: 0.512128\nTrain Epoch: 15 [35000/248297 (14%)]\tLoss: 0.502169\nTrain Epoch: 15 [36000/248297 (15%)]\tLoss: 0.455643\nTrain Epoch: 15 [37000/248297 (15%)]\tLoss: 0.473218\nTrain Epoch: 15 [38000/248297 (15%)]\tLoss: 0.475536\nTrain Epoch: 15 [39000/248297 (16%)]\tLoss: 0.494698\nTrain Epoch: 15 [40000/248297 (16%)]\tLoss: 0.478974\nTrain Epoch: 15 [41000/248297 (17%)]\tLoss: 0.540689\nTrain Epoch: 15 [42000/248297 (17%)]\tLoss: 0.436193\nTrain Epoch: 15 [43000/248297 (17%)]\tLoss: 0.456678\nTrain Epoch: 15 [44000/248297 (18%)]\tLoss: 0.424411\nTrain Epoch: 15 [45000/248297 (18%)]\tLoss: 0.408648\nTrain Epoch: 15 [46000/248297 (19%)]\tLoss: 0.497399\nTrain Epoch: 15 [47000/248297 (19%)]\tLoss: 0.493163\nTrain Epoch: 15 [48000/248297 (19%)]\tLoss: 0.537318\nTrain Epoch: 15 [49000/248297 (20%)]\tLoss: 0.528995\nTrain Epoch: 15 [50000/248297 (20%)]\tLoss: 0.449545\nTrain Epoch: 15 [51000/248297 (21%)]\tLoss: 0.568406\nTrain Epoch: 15 [52000/248297 (21%)]\tLoss: 0.473196\nTrain Epoch: 15 [53000/248297 (21%)]\tLoss: 0.468580\nTrain Epoch: 15 [54000/248297 (22%)]\tLoss: 0.541778\nTrain Epoch: 15 [55000/248297 (22%)]\tLoss: 0.523822\nTrain Epoch: 15 [56000/248297 (23%)]\tLoss: 0.583242\nTrain Epoch: 15 [57000/248297 (23%)]\tLoss: 0.506740\nTrain Epoch: 15 [58000/248297 (23%)]\tLoss: 0.513935\nTrain Epoch: 15 [59000/248297 (24%)]\tLoss: 0.536349\nTrain Epoch: 15 [60000/248297 (24%)]\tLoss: 0.436307\nTrain Epoch: 15 [61000/248297 (25%)]\tLoss: 0.548521\nTrain Epoch: 15 [62000/248297 (25%)]\tLoss: 0.480049\nTrain Epoch: 15 [63000/248297 (25%)]\tLoss: 0.609257\nTrain Epoch: 15 [64000/248297 (26%)]\tLoss: 0.477113\nTrain Epoch: 15 [65000/248297 (26%)]\tLoss: 0.498677\nTrain Epoch: 15 [66000/248297 (27%)]\tLoss: 0.471057\nTrain Epoch: 15 [67000/248297 (27%)]\tLoss: 0.483147\nTrain Epoch: 15 [68000/248297 (27%)]\tLoss: 0.504258\nTrain Epoch: 15 [69000/248297 (28%)]\tLoss: 0.458625\nTrain Epoch: 15 [70000/248297 (28%)]\tLoss: 0.477279\nTrain Epoch: 15 [71000/248297 (29%)]\tLoss: 0.463487\nTrain Epoch: 15 [72000/248297 (29%)]\tLoss: 0.482531\nTrain Epoch: 15 [73000/248297 (29%)]\tLoss: 0.464388\nTrain Epoch: 15 [74000/248297 (30%)]\tLoss: 0.445806\nTrain Epoch: 15 [75000/248297 (30%)]\tLoss: 0.517293\nTrain Epoch: 15 [76000/248297 (31%)]\tLoss: 0.571502\nTrain Epoch: 15 [77000/248297 (31%)]\tLoss: 0.524260\nTrain Epoch: 15 [78000/248297 (31%)]\tLoss: 0.511885\nTrain Epoch: 15 [79000/248297 (32%)]\tLoss: 0.400661\nTrain Epoch: 15 [80000/248297 (32%)]\tLoss: 0.441387\nTrain Epoch: 15 [81000/248297 (33%)]\tLoss: 0.495674\nTrain Epoch: 15 [82000/248297 (33%)]\tLoss: 0.459771\nTrain Epoch: 15 [83000/248297 (33%)]\tLoss: 0.457894\nTrain Epoch: 15 [84000/248297 (34%)]\tLoss: 0.430768\nTrain Epoch: 15 [85000/248297 (34%)]\tLoss: 0.476952\nTrain Epoch: 15 [86000/248297 (35%)]\tLoss: 0.409530\nTrain Epoch: 15 [87000/248297 (35%)]\tLoss: 0.542000\nTrain Epoch: 15 [88000/248297 (35%)]\tLoss: 0.416968\nTrain Epoch: 15 [89000/248297 (36%)]\tLoss: 0.407451\nTrain Epoch: 15 [90000/248297 (36%)]\tLoss: 0.484625\nTrain Epoch: 15 [91000/248297 (37%)]\tLoss: 0.566018\nTrain Epoch: 15 [92000/248297 (37%)]\tLoss: 0.496799\nTrain Epoch: 15 [93000/248297 (37%)]\tLoss: 0.497884\nTrain Epoch: 15 [94000/248297 (38%)]\tLoss: 0.428466\nTrain Epoch: 15 [95000/248297 (38%)]\tLoss: 0.458522\nTrain Epoch: 15 [96000/248297 (39%)]\tLoss: 0.509217\nTrain Epoch: 15 [97000/248297 (39%)]\tLoss: 0.494139\nTrain Epoch: 15 [98000/248297 (39%)]\tLoss: 0.534263\nTrain Epoch: 15 [99000/248297 (40%)]\tLoss: 0.570826\nTrain Epoch: 15 [100000/248297 (40%)]\tLoss: 0.486492\nTrain Epoch: 15 [101000/248297 (41%)]\tLoss: 0.518568\nTrain Epoch: 15 [102000/248297 (41%)]\tLoss: 0.480659\nTrain Epoch: 15 [103000/248297 (41%)]\tLoss: 0.513772\nTrain Epoch: 15 [104000/248297 (42%)]\tLoss: 0.507332\nTrain Epoch: 15 [105000/248297 (42%)]\tLoss: 0.471584\nTrain Epoch: 15 [106000/248297 (43%)]\tLoss: 0.399359\nTrain Epoch: 15 [107000/248297 (43%)]\tLoss: 0.450451\nTrain Epoch: 15 [108000/248297 (44%)]\tLoss: 0.495843\nTrain Epoch: 15 [109000/248297 (44%)]\tLoss: 0.330761\nTrain Epoch: 15 [110000/248297 (44%)]\tLoss: 0.484569\nTrain Epoch: 15 [111000/248297 (45%)]\tLoss: 0.422069\nTrain Epoch: 15 [112000/248297 (45%)]\tLoss: 0.332435\nTrain Epoch: 15 [113000/248297 (46%)]\tLoss: 0.401889\nTrain Epoch: 15 [114000/248297 (46%)]\tLoss: 0.487335\nTrain Epoch: 15 [115000/248297 (46%)]\tLoss: 0.574987\nTrain Epoch: 15 [116000/248297 (47%)]\tLoss: 0.476427\nTrain Epoch: 15 [117000/248297 (47%)]\tLoss: 0.342267\nTrain Epoch: 15 [118000/248297 (48%)]\tLoss: 0.461921\nTrain Epoch: 15 [119000/248297 (48%)]\tLoss: 0.508591\nTrain Epoch: 15 [120000/248297 (48%)]\tLoss: 0.500452\nTrain Epoch: 15 [121000/248297 (49%)]\tLoss: 0.406957\nTrain Epoch: 15 [122000/248297 (49%)]\tLoss: 0.468117\nTrain Epoch: 15 [123000/248297 (50%)]\tLoss: 0.461320\nTrain Epoch: 15 [124000/248297 (50%)]\tLoss: 0.476449\nTrain Epoch: 15 [125000/248297 (50%)]\tLoss: 0.449098\nTrain Epoch: 15 [126000/248297 (51%)]\tLoss: 0.519616\nTrain Epoch: 15 [127000/248297 (51%)]\tLoss: 0.436062\nTrain Epoch: 15 [128000/248297 (52%)]\tLoss: 0.484996\nTrain Epoch: 15 [129000/248297 (52%)]\tLoss: 0.445422\nTrain Epoch: 15 [130000/248297 (52%)]\tLoss: 0.475570\nTrain Epoch: 15 [131000/248297 (53%)]\tLoss: 0.486919\nTrain Epoch: 15 [132000/248297 (53%)]\tLoss: 0.455289\nTrain Epoch: 15 [133000/248297 (54%)]\tLoss: 0.427406\nTrain Epoch: 15 [134000/248297 (54%)]\tLoss: 0.520224\nTrain Epoch: 15 [135000/248297 (54%)]\tLoss: 0.515084\nTrain Epoch: 15 [136000/248297 (55%)]\tLoss: 0.425373\nTrain Epoch: 15 [137000/248297 (55%)]\tLoss: 0.531812\nTrain Epoch: 15 [138000/248297 (56%)]\tLoss: 0.462873\nTrain Epoch: 15 [139000/248297 (56%)]\tLoss: 0.533518\nTrain Epoch: 15 [140000/248297 (56%)]\tLoss: 0.540146\nTrain Epoch: 15 [141000/248297 (57%)]\tLoss: 0.519717\nTrain Epoch: 15 [142000/248297 (57%)]\tLoss: 0.569873\nTrain Epoch: 15 [143000/248297 (58%)]\tLoss: 0.512316\nTrain Epoch: 15 [144000/248297 (58%)]\tLoss: 0.596728\nTrain Epoch: 15 [145000/248297 (58%)]\tLoss: 0.454233\nTrain Epoch: 15 [146000/248297 (59%)]\tLoss: 0.566896\nTrain Epoch: 15 [147000/248297 (59%)]\tLoss: 0.448354\nTrain Epoch: 15 [148000/248297 (60%)]\tLoss: 0.459687\nTrain Epoch: 15 [149000/248297 (60%)]\tLoss: 0.471386\nTrain Epoch: 15 [150000/248297 (60%)]\tLoss: 0.493831\nTrain Epoch: 15 [151000/248297 (61%)]\tLoss: 0.473153\nTrain Epoch: 15 [152000/248297 (61%)]\tLoss: 0.531345\nTrain Epoch: 15 [153000/248297 (62%)]\tLoss: 0.486132\nTrain Epoch: 15 [154000/248297 (62%)]\tLoss: 0.530234\nTrain Epoch: 15 [155000/248297 (62%)]\tLoss: 0.400359\nTrain Epoch: 15 [156000/248297 (63%)]\tLoss: 0.516397\nTrain Epoch: 15 [157000/248297 (63%)]\tLoss: 0.464624\nTrain Epoch: 15 [158000/248297 (64%)]\tLoss: 0.434848\nTrain Epoch: 15 [159000/248297 (64%)]\tLoss: 0.535399\nTrain Epoch: 15 [160000/248297 (64%)]\tLoss: 0.475505\nTrain Epoch: 15 [161000/248297 (65%)]\tLoss: 0.431733\nTrain Epoch: 15 [162000/248297 (65%)]\tLoss: 0.458795\nTrain Epoch: 15 [163000/248297 (66%)]\tLoss: 0.430209\nTrain Epoch: 15 [164000/248297 (66%)]\tLoss: 0.487782\nTrain Epoch: 15 [165000/248297 (66%)]\tLoss: 0.533747\nTrain Epoch: 15 [166000/248297 (67%)]\tLoss: 0.462767\nTrain Epoch: 15 [167000/248297 (67%)]\tLoss: 0.596146\nTrain Epoch: 15 [168000/248297 (68%)]\tLoss: 0.452269\nTrain Epoch: 15 [169000/248297 (68%)]\tLoss: 0.400382\nTrain Epoch: 15 [170000/248297 (68%)]\tLoss: 0.484799\nTrain Epoch: 15 [171000/248297 (69%)]\tLoss: 0.445421\nTrain Epoch: 15 [172000/248297 (69%)]\tLoss: 0.517793\nTrain Epoch: 15 [173000/248297 (70%)]\tLoss: 0.448668\nTrain Epoch: 15 [174000/248297 (70%)]\tLoss: 0.508724\nTrain Epoch: 15 [175000/248297 (71%)]\tLoss: 0.435777\nTrain Epoch: 15 [176000/248297 (71%)]\tLoss: 0.483754\nTrain Epoch: 15 [177000/248297 (71%)]\tLoss: 0.479255\nTrain Epoch: 15 [178000/248297 (72%)]\tLoss: 0.475222\nTrain Epoch: 15 [179000/248297 (72%)]\tLoss: 0.523475\nTrain Epoch: 15 [180000/248297 (73%)]\tLoss: 0.466077\nTrain Epoch: 15 [181000/248297 (73%)]\tLoss: 0.464345\nTrain Epoch: 15 [182000/248297 (73%)]\tLoss: 0.493490\nTrain Epoch: 15 [183000/248297 (74%)]\tLoss: 0.433473\nTrain Epoch: 15 [184000/248297 (74%)]\tLoss: 0.578016\nTrain Epoch: 15 [185000/248297 (75%)]\tLoss: 0.483743\nTrain Epoch: 15 [186000/248297 (75%)]\tLoss: 0.376835\nTrain Epoch: 15 [187000/248297 (75%)]\tLoss: 0.391707\nTrain Epoch: 15 [188000/248297 (76%)]\tLoss: 0.404494\nTrain Epoch: 15 [189000/248297 (76%)]\tLoss: 0.495123\nTrain Epoch: 15 [190000/248297 (77%)]\tLoss: 0.428308\nTrain Epoch: 15 [191000/248297 (77%)]\tLoss: 0.467144\nTrain Epoch: 15 [192000/248297 (77%)]\tLoss: 0.472834\nTrain Epoch: 15 [193000/248297 (78%)]\tLoss: 0.428681\nTrain Epoch: 15 [194000/248297 (78%)]\tLoss: 0.489343\nTrain Epoch: 15 [195000/248297 (79%)]\tLoss: 0.456577\nTrain Epoch: 15 [196000/248297 (79%)]\tLoss: 0.498047\nTrain Epoch: 15 [197000/248297 (79%)]\tLoss: 0.453228\nTrain Epoch: 15 [198000/248297 (80%)]\tLoss: 0.566338\nTrain Epoch: 15 [199000/248297 (80%)]\tLoss: 0.445055\nTrain Epoch: 15 [200000/248297 (81%)]\tLoss: 0.476325\nTrain Epoch: 15 [201000/248297 (81%)]\tLoss: 0.355361\nTrain Epoch: 15 [202000/248297 (81%)]\tLoss: 0.419779\nTrain Epoch: 15 [203000/248297 (82%)]\tLoss: 0.486065\nTrain Epoch: 15 [204000/248297 (82%)]\tLoss: 0.494530\nTrain Epoch: 15 [205000/248297 (83%)]\tLoss: 0.486061\nTrain Epoch: 15 [206000/248297 (83%)]\tLoss: 0.565962\nTrain Epoch: 15 [207000/248297 (83%)]\tLoss: 0.419713\nTrain Epoch: 15 [208000/248297 (84%)]\tLoss: 0.453540\nTrain Epoch: 15 [209000/248297 (84%)]\tLoss: 0.469339\nTrain Epoch: 15 [210000/248297 (85%)]\tLoss: 0.411120\nTrain Epoch: 15 [211000/248297 (85%)]\tLoss: 0.506988\nTrain Epoch: 15 [212000/248297 (85%)]\tLoss: 0.568713\nTrain Epoch: 15 [213000/248297 (86%)]\tLoss: 0.453252\nTrain Epoch: 15 [214000/248297 (86%)]\tLoss: 0.516345\nTrain Epoch: 15 [215000/248297 (87%)]\tLoss: 0.628909\nTrain Epoch: 15 [216000/248297 (87%)]\tLoss: 0.584061\nTrain Epoch: 15 [217000/248297 (87%)]\tLoss: 0.352045\nTrain Epoch: 15 [218000/248297 (88%)]\tLoss: 0.505594\nTrain Epoch: 15 [219000/248297 (88%)]\tLoss: 0.395966\nTrain Epoch: 15 [220000/248297 (89%)]\tLoss: 0.500418\nTrain Epoch: 15 [221000/248297 (89%)]\tLoss: 0.421425\nTrain Epoch: 15 [222000/248297 (89%)]\tLoss: 0.485419\nTrain Epoch: 15 [223000/248297 (90%)]\tLoss: 0.499467\nTrain Epoch: 15 [224000/248297 (90%)]\tLoss: 0.502803\nTrain Epoch: 15 [225000/248297 (91%)]\tLoss: 0.508579\nTrain Epoch: 15 [226000/248297 (91%)]\tLoss: 0.453378\nTrain Epoch: 15 [227000/248297 (91%)]\tLoss: 0.439085\nTrain Epoch: 15 [228000/248297 (92%)]\tLoss: 0.459249\nTrain Epoch: 15 [229000/248297 (92%)]\tLoss: 0.496749\nTrain Epoch: 15 [230000/248297 (93%)]\tLoss: 0.544896\nTrain Epoch: 15 [231000/248297 (93%)]\tLoss: 0.387153\nTrain Epoch: 15 [232000/248297 (93%)]\tLoss: 0.482752\nTrain Epoch: 15 [233000/248297 (94%)]\tLoss: 0.466974\nTrain Epoch: 15 [234000/248297 (94%)]\tLoss: 0.553087\nTrain Epoch: 15 [235000/248297 (95%)]\tLoss: 0.484879\nTrain Epoch: 15 [236000/248297 (95%)]\tLoss: 0.461994\nTrain Epoch: 15 [237000/248297 (95%)]\tLoss: 0.460698\nTrain Epoch: 15 [238000/248297 (96%)]\tLoss: 0.506260\nTrain Epoch: 15 [239000/248297 (96%)]\tLoss: 0.524658\nTrain Epoch: 15 [240000/248297 (97%)]\tLoss: 0.495477\nTrain Epoch: 15 [241000/248297 (97%)]\tLoss: 0.410287\nTrain Epoch: 15 [242000/248297 (98%)]\tLoss: 0.482184\nTrain Epoch: 15 [243000/248297 (98%)]\tLoss: 0.401967\nTrain Epoch: 15 [244000/248297 (98%)]\tLoss: 0.522188\nTrain Epoch: 15 [245000/248297 (99%)]\tLoss: 0.505182\nTrain Epoch: 15 [246000/248297 (99%)]\tLoss: 0.457908\nTrain Epoch: 15 [247000/248297 (100%)]\tLoss: 0.552536\nTrain Epoch: 15 [248000/248297 (100%)]\tLoss: 0.543040\n\nTest set: Average loss: 0.0050, Accuracy: 20728/27589 (75%)\n\nTrain Epoch: 16 [0/248297 (0%)]\tLoss: 0.444323\nTrain Epoch: 16 [1000/248297 (0%)]\tLoss: 0.403343\nTrain Epoch: 16 [2000/248297 (1%)]\tLoss: 0.409137\nTrain Epoch: 16 [3000/248297 (1%)]\tLoss: 0.407772\nTrain Epoch: 16 [4000/248297 (2%)]\tLoss: 0.451703\nTrain Epoch: 16 [5000/248297 (2%)]\tLoss: 0.461483\nTrain Epoch: 16 [6000/248297 (2%)]\tLoss: 0.457801\nTrain Epoch: 16 [7000/248297 (3%)]\tLoss: 0.494623\nTrain Epoch: 16 [8000/248297 (3%)]\tLoss: 0.406701\nTrain Epoch: 16 [9000/248297 (4%)]\tLoss: 0.430126\nTrain Epoch: 16 [10000/248297 (4%)]\tLoss: 0.552397\nTrain Epoch: 16 [11000/248297 (4%)]\tLoss: 0.567621\nTrain Epoch: 16 [12000/248297 (5%)]\tLoss: 0.499979\nTrain Epoch: 16 [13000/248297 (5%)]\tLoss: 0.466622\nTrain Epoch: 16 [14000/248297 (6%)]\tLoss: 0.487299\nTrain Epoch: 16 [15000/248297 (6%)]\tLoss: 0.400121\nTrain Epoch: 16 [16000/248297 (6%)]\tLoss: 0.520465\nTrain Epoch: 16 [17000/248297 (7%)]\tLoss: 0.439400\nTrain Epoch: 16 [18000/248297 (7%)]\tLoss: 0.503394\nTrain Epoch: 16 [19000/248297 (8%)]\tLoss: 0.482823\nTrain Epoch: 16 [20000/248297 (8%)]\tLoss: 0.470553\nTrain Epoch: 16 [21000/248297 (8%)]\tLoss: 0.501158\nTrain Epoch: 16 [22000/248297 (9%)]\tLoss: 0.449529\nTrain Epoch: 16 [23000/248297 (9%)]\tLoss: 0.466485\nTrain Epoch: 16 [24000/248297 (10%)]\tLoss: 0.511060\nTrain Epoch: 16 [25000/248297 (10%)]\tLoss: 0.610944\nTrain Epoch: 16 [26000/248297 (10%)]\tLoss: 0.422611\nTrain Epoch: 16 [27000/248297 (11%)]\tLoss: 0.475923\nTrain Epoch: 16 [28000/248297 (11%)]\tLoss: 0.477914\nTrain Epoch: 16 [29000/248297 (12%)]\tLoss: 0.506287\nTrain Epoch: 16 [30000/248297 (12%)]\tLoss: 0.507724\nTrain Epoch: 16 [31000/248297 (12%)]\tLoss: 0.435970\nTrain Epoch: 16 [32000/248297 (13%)]\tLoss: 0.463397\nTrain Epoch: 16 [33000/248297 (13%)]\tLoss: 0.482544\nTrain Epoch: 16 [34000/248297 (14%)]\tLoss: 0.436656\nTrain Epoch: 16 [35000/248297 (14%)]\tLoss: 0.446862\nTrain Epoch: 16 [36000/248297 (15%)]\tLoss: 0.452968\nTrain Epoch: 16 [37000/248297 (15%)]\tLoss: 0.458674\nTrain Epoch: 16 [38000/248297 (15%)]\tLoss: 0.485991\nTrain Epoch: 16 [39000/248297 (16%)]\tLoss: 0.428180\nTrain Epoch: 16 [40000/248297 (16%)]\tLoss: 0.474525\nTrain Epoch: 16 [41000/248297 (17%)]\tLoss: 0.465191\nTrain Epoch: 16 [42000/248297 (17%)]\tLoss: 0.466718\nTrain Epoch: 16 [43000/248297 (17%)]\tLoss: 0.506898\nTrain Epoch: 16 [44000/248297 (18%)]\tLoss: 0.456535\nTrain Epoch: 16 [45000/248297 (18%)]\tLoss: 0.366291\nTrain Epoch: 16 [46000/248297 (19%)]\tLoss: 0.498348\nTrain Epoch: 16 [47000/248297 (19%)]\tLoss: 0.580998\nTrain Epoch: 16 [48000/248297 (19%)]\tLoss: 0.518206\nTrain Epoch: 16 [49000/248297 (20%)]\tLoss: 0.454537\nTrain Epoch: 16 [50000/248297 (20%)]\tLoss: 0.423063\nTrain Epoch: 16 [51000/248297 (21%)]\tLoss: 0.437251\nTrain Epoch: 16 [52000/248297 (21%)]\tLoss: 0.512399\nTrain Epoch: 16 [53000/248297 (21%)]\tLoss: 0.557980\nTrain Epoch: 16 [54000/248297 (22%)]\tLoss: 0.522934\nTrain Epoch: 16 [55000/248297 (22%)]\tLoss: 0.484134\nTrain Epoch: 16 [56000/248297 (23%)]\tLoss: 0.602052\nTrain Epoch: 16 [57000/248297 (23%)]\tLoss: 0.490394\nTrain Epoch: 16 [58000/248297 (23%)]\tLoss: 0.502718\nTrain Epoch: 16 [59000/248297 (24%)]\tLoss: 0.457526\nTrain Epoch: 16 [60000/248297 (24%)]\tLoss: 0.435656\nTrain Epoch: 16 [61000/248297 (25%)]\tLoss: 0.510131\nTrain Epoch: 16 [62000/248297 (25%)]\tLoss: 0.522099\nTrain Epoch: 16 [63000/248297 (25%)]\tLoss: 0.413757\nTrain Epoch: 16 [64000/248297 (26%)]\tLoss: 0.488561\nTrain Epoch: 16 [65000/248297 (26%)]\tLoss: 0.459099\nTrain Epoch: 16 [66000/248297 (27%)]\tLoss: 0.616010\nTrain Epoch: 16 [67000/248297 (27%)]\tLoss: 0.529179\nTrain Epoch: 16 [68000/248297 (27%)]\tLoss: 0.391605\nTrain Epoch: 16 [69000/248297 (28%)]\tLoss: 0.412830\nTrain Epoch: 16 [70000/248297 (28%)]\tLoss: 0.461637\nTrain Epoch: 16 [71000/248297 (29%)]\tLoss: 0.527398\nTrain Epoch: 16 [72000/248297 (29%)]\tLoss: 0.456922\nTrain Epoch: 16 [73000/248297 (29%)]\tLoss: 0.676323\nTrain Epoch: 16 [74000/248297 (30%)]\tLoss: 0.510892\nTrain Epoch: 16 [75000/248297 (30%)]\tLoss: 0.480128\nTrain Epoch: 16 [76000/248297 (31%)]\tLoss: 0.511692\nTrain Epoch: 16 [77000/248297 (31%)]\tLoss: 0.385085\nTrain Epoch: 16 [78000/248297 (31%)]\tLoss: 0.446072\nTrain Epoch: 16 [79000/248297 (32%)]\tLoss: 0.388107\nTrain Epoch: 16 [80000/248297 (32%)]\tLoss: 0.448923\nTrain Epoch: 16 [81000/248297 (33%)]\tLoss: 0.579218\nTrain Epoch: 16 [82000/248297 (33%)]\tLoss: 0.493175\nTrain Epoch: 16 [83000/248297 (33%)]\tLoss: 0.492738\nTrain Epoch: 16 [84000/248297 (34%)]\tLoss: 0.463999\nTrain Epoch: 16 [85000/248297 (34%)]\tLoss: 0.513532\nTrain Epoch: 16 [86000/248297 (35%)]\tLoss: 0.497952\nTrain Epoch: 16 [87000/248297 (35%)]\tLoss: 0.500180\nTrain Epoch: 16 [88000/248297 (35%)]\tLoss: 0.485492\nTrain Epoch: 16 [89000/248297 (36%)]\tLoss: 0.468815\nTrain Epoch: 16 [90000/248297 (36%)]\tLoss: 0.563885\nTrain Epoch: 16 [91000/248297 (37%)]\tLoss: 0.451803\nTrain Epoch: 16 [92000/248297 (37%)]\tLoss: 0.446253\nTrain Epoch: 16 [93000/248297 (37%)]\tLoss: 0.522620\nTrain Epoch: 16 [94000/248297 (38%)]\tLoss: 0.456849\nTrain Epoch: 16 [95000/248297 (38%)]\tLoss: 0.449020\nTrain Epoch: 16 [96000/248297 (39%)]\tLoss: 0.531738\nTrain Epoch: 16 [97000/248297 (39%)]\tLoss: 0.545215\nTrain Epoch: 16 [98000/248297 (39%)]\tLoss: 0.500519\nTrain Epoch: 16 [99000/248297 (40%)]\tLoss: 0.461422\nTrain Epoch: 16 [100000/248297 (40%)]\tLoss: 0.457534\nTrain Epoch: 16 [101000/248297 (41%)]\tLoss: 0.435947\nTrain Epoch: 16 [102000/248297 (41%)]\tLoss: 0.492923\nTrain Epoch: 16 [103000/248297 (41%)]\tLoss: 0.499379\nTrain Epoch: 16 [104000/248297 (42%)]\tLoss: 0.441753\nTrain Epoch: 16 [105000/248297 (42%)]\tLoss: 0.525214\nTrain Epoch: 16 [106000/248297 (43%)]\tLoss: 0.458109\nTrain Epoch: 16 [107000/248297 (43%)]\tLoss: 0.517680\nTrain Epoch: 16 [108000/248297 (44%)]\tLoss: 0.424447\nTrain Epoch: 16 [109000/248297 (44%)]\tLoss: 0.469471\nTrain Epoch: 16 [110000/248297 (44%)]\tLoss: 0.590033\nTrain Epoch: 16 [111000/248297 (45%)]\tLoss: 0.442170\nTrain Epoch: 16 [112000/248297 (45%)]\tLoss: 0.543177\nTrain Epoch: 16 [113000/248297 (46%)]\tLoss: 0.553022\nTrain Epoch: 16 [114000/248297 (46%)]\tLoss: 0.385634\nTrain Epoch: 16 [115000/248297 (46%)]\tLoss: 0.444429\nTrain Epoch: 16 [116000/248297 (47%)]\tLoss: 0.511426\nTrain Epoch: 16 [117000/248297 (47%)]\tLoss: 0.504491\nTrain Epoch: 16 [118000/248297 (48%)]\tLoss: 0.466520\nTrain Epoch: 16 [119000/248297 (48%)]\tLoss: 0.512932\nTrain Epoch: 16 [120000/248297 (48%)]\tLoss: 0.389754\nTrain Epoch: 16 [121000/248297 (49%)]\tLoss: 0.444189\nTrain Epoch: 16 [122000/248297 (49%)]\tLoss: 0.479336\nTrain Epoch: 16 [123000/248297 (50%)]\tLoss: 0.547736\nTrain Epoch: 16 [124000/248297 (50%)]\tLoss: 0.454773\nTrain Epoch: 16 [125000/248297 (50%)]\tLoss: 0.547070\nTrain Epoch: 16 [126000/248297 (51%)]\tLoss: 0.514385\nTrain Epoch: 16 [127000/248297 (51%)]\tLoss: 0.457658\nTrain Epoch: 16 [128000/248297 (52%)]\tLoss: 0.503360\nTrain Epoch: 16 [129000/248297 (52%)]\tLoss: 0.439901\nTrain Epoch: 16 [130000/248297 (52%)]\tLoss: 0.414728\nTrain Epoch: 16 [131000/248297 (53%)]\tLoss: 0.468108\nTrain Epoch: 16 [132000/248297 (53%)]\tLoss: 0.392545\nTrain Epoch: 16 [133000/248297 (54%)]\tLoss: 0.541624\nTrain Epoch: 16 [134000/248297 (54%)]\tLoss: 0.559048\nTrain Epoch: 16 [135000/248297 (54%)]\tLoss: 0.473559\nTrain Epoch: 16 [136000/248297 (55%)]\tLoss: 0.459235\nTrain Epoch: 16 [137000/248297 (55%)]\tLoss: 0.429029\nTrain Epoch: 16 [138000/248297 (56%)]\tLoss: 0.567003\nTrain Epoch: 16 [139000/248297 (56%)]\tLoss: 0.437221\nTrain Epoch: 16 [140000/248297 (56%)]\tLoss: 0.513732\nTrain Epoch: 16 [141000/248297 (57%)]\tLoss: 0.509567\nTrain Epoch: 16 [142000/248297 (57%)]\tLoss: 0.441373\nTrain Epoch: 16 [143000/248297 (58%)]\tLoss: 0.442019\nTrain Epoch: 16 [144000/248297 (58%)]\tLoss: 0.529759\nTrain Epoch: 16 [145000/248297 (58%)]\tLoss: 0.433857\nTrain Epoch: 16 [146000/248297 (59%)]\tLoss: 0.477536\nTrain Epoch: 16 [147000/248297 (59%)]\tLoss: 0.517061\nTrain Epoch: 16 [148000/248297 (60%)]\tLoss: 0.415894\nTrain Epoch: 16 [149000/248297 (60%)]\tLoss: 0.425072\nTrain Epoch: 16 [150000/248297 (60%)]\tLoss: 0.519639\nTrain Epoch: 16 [151000/248297 (61%)]\tLoss: 0.372221\nTrain Epoch: 16 [152000/248297 (61%)]\tLoss: 0.551091\nTrain Epoch: 16 [153000/248297 (62%)]\tLoss: 0.449553\nTrain Epoch: 16 [154000/248297 (62%)]\tLoss: 0.443310\nTrain Epoch: 16 [155000/248297 (62%)]\tLoss: 0.425082\nTrain Epoch: 16 [156000/248297 (63%)]\tLoss: 0.476893\nTrain Epoch: 16 [157000/248297 (63%)]\tLoss: 0.529299\nTrain Epoch: 16 [158000/248297 (64%)]\tLoss: 0.450932\nTrain Epoch: 16 [159000/248297 (64%)]\tLoss: 0.535205\nTrain Epoch: 16 [160000/248297 (64%)]\tLoss: 0.532944\nTrain Epoch: 16 [161000/248297 (65%)]\tLoss: 0.479284\nTrain Epoch: 16 [162000/248297 (65%)]\tLoss: 0.494595\nTrain Epoch: 16 [163000/248297 (66%)]\tLoss: 0.473851\nTrain Epoch: 16 [164000/248297 (66%)]\tLoss: 0.511709\nTrain Epoch: 16 [165000/248297 (66%)]\tLoss: 0.550857\nTrain Epoch: 16 [166000/248297 (67%)]\tLoss: 0.547034\nTrain Epoch: 16 [167000/248297 (67%)]\tLoss: 0.445836\nTrain Epoch: 16 [168000/248297 (68%)]\tLoss: 0.535891\nTrain Epoch: 16 [169000/248297 (68%)]\tLoss: 0.454418\nTrain Epoch: 16 [170000/248297 (68%)]\tLoss: 0.512986\nTrain Epoch: 16 [171000/248297 (69%)]\tLoss: 0.466628\nTrain Epoch: 16 [172000/248297 (69%)]\tLoss: 0.546827\nTrain Epoch: 16 [173000/248297 (70%)]\tLoss: 0.636626\nTrain Epoch: 16 [174000/248297 (70%)]\tLoss: 0.461824\nTrain Epoch: 16 [175000/248297 (71%)]\tLoss: 0.485913\nTrain Epoch: 16 [176000/248297 (71%)]\tLoss: 0.529985\nTrain Epoch: 16 [177000/248297 (71%)]\tLoss: 0.502085\nTrain Epoch: 16 [178000/248297 (72%)]\tLoss: 0.476052\nTrain Epoch: 16 [179000/248297 (72%)]\tLoss: 0.454101\nTrain Epoch: 16 [180000/248297 (73%)]\tLoss: 0.385594\nTrain Epoch: 16 [181000/248297 (73%)]\tLoss: 0.540475\nTrain Epoch: 16 [182000/248297 (73%)]\tLoss: 0.528724\nTrain Epoch: 16 [183000/248297 (74%)]\tLoss: 0.553106\nTrain Epoch: 16 [184000/248297 (74%)]\tLoss: 0.612711\nTrain Epoch: 16 [185000/248297 (75%)]\tLoss: 0.474967\nTrain Epoch: 16 [186000/248297 (75%)]\tLoss: 0.442217\nTrain Epoch: 16 [187000/248297 (75%)]\tLoss: 0.517297\nTrain Epoch: 16 [188000/248297 (76%)]\tLoss: 0.474133\nTrain Epoch: 16 [189000/248297 (76%)]\tLoss: 0.506136\nTrain Epoch: 16 [190000/248297 (77%)]\tLoss: 0.552803\nTrain Epoch: 16 [191000/248297 (77%)]\tLoss: 0.530472\nTrain Epoch: 16 [192000/248297 (77%)]\tLoss: 0.552769\nTrain Epoch: 16 [193000/248297 (78%)]\tLoss: 0.447301\nTrain Epoch: 16 [194000/248297 (78%)]\tLoss: 0.417034\nTrain Epoch: 16 [195000/248297 (79%)]\tLoss: 0.544938\nTrain Epoch: 16 [196000/248297 (79%)]\tLoss: 0.466079\nTrain Epoch: 16 [197000/248297 (79%)]\tLoss: 0.528408\nTrain Epoch: 16 [198000/248297 (80%)]\tLoss: 0.480106\nTrain Epoch: 16 [199000/248297 (80%)]\tLoss: 0.472223\nTrain Epoch: 16 [200000/248297 (81%)]\tLoss: 0.455594\nTrain Epoch: 16 [201000/248297 (81%)]\tLoss: 0.492596\nTrain Epoch: 16 [202000/248297 (81%)]\tLoss: 0.494949\nTrain Epoch: 16 [203000/248297 (82%)]\tLoss: 0.459203\nTrain Epoch: 16 [204000/248297 (82%)]\tLoss: 0.576391\nTrain Epoch: 16 [205000/248297 (83%)]\tLoss: 0.445406\nTrain Epoch: 16 [206000/248297 (83%)]\tLoss: 0.460383\nTrain Epoch: 16 [207000/248297 (83%)]\tLoss: 0.442652\nTrain Epoch: 16 [208000/248297 (84%)]\tLoss: 0.444507\nTrain Epoch: 16 [209000/248297 (84%)]\tLoss: 0.405691\nTrain Epoch: 16 [210000/248297 (85%)]\tLoss: 0.389087\nTrain Epoch: 16 [211000/248297 (85%)]\tLoss: 0.465391\nTrain Epoch: 16 [212000/248297 (85%)]\tLoss: 0.464368\nTrain Epoch: 16 [213000/248297 (86%)]\tLoss: 0.484916\nTrain Epoch: 16 [214000/248297 (86%)]\tLoss: 0.537006\nTrain Epoch: 16 [215000/248297 (87%)]\tLoss: 0.537190\nTrain Epoch: 16 [216000/248297 (87%)]\tLoss: 0.398358\nTrain Epoch: 16 [217000/248297 (87%)]\tLoss: 0.456073\nTrain Epoch: 16 [218000/248297 (88%)]\tLoss: 0.482861\nTrain Epoch: 16 [219000/248297 (88%)]\tLoss: 0.510750\nTrain Epoch: 16 [220000/248297 (89%)]\tLoss: 0.529816\nTrain Epoch: 16 [221000/248297 (89%)]\tLoss: 0.566501\nTrain Epoch: 16 [222000/248297 (89%)]\tLoss: 0.510539\nTrain Epoch: 16 [223000/248297 (90%)]\tLoss: 0.583185\nTrain Epoch: 16 [224000/248297 (90%)]\tLoss: 0.460592\nTrain Epoch: 16 [225000/248297 (91%)]\tLoss: 0.504825\nTrain Epoch: 16 [226000/248297 (91%)]\tLoss: 0.408625\nTrain Epoch: 16 [227000/248297 (91%)]\tLoss: 0.491664\nTrain Epoch: 16 [228000/248297 (92%)]\tLoss: 0.393646\nTrain Epoch: 16 [229000/248297 (92%)]\tLoss: 0.553458\nTrain Epoch: 16 [230000/248297 (93%)]\tLoss: 0.450025\nTrain Epoch: 16 [231000/248297 (93%)]\tLoss: 0.547582\nTrain Epoch: 16 [232000/248297 (93%)]\tLoss: 0.426655\nTrain Epoch: 16 [233000/248297 (94%)]\tLoss: 0.466156\nTrain Epoch: 16 [234000/248297 (94%)]\tLoss: 0.510958\nTrain Epoch: 16 [235000/248297 (95%)]\tLoss: 0.479766\nTrain Epoch: 16 [236000/248297 (95%)]\tLoss: 0.508668\nTrain Epoch: 16 [237000/248297 (95%)]\tLoss: 0.510205\nTrain Epoch: 16 [238000/248297 (96%)]\tLoss: 0.484881\nTrain Epoch: 16 [239000/248297 (96%)]\tLoss: 0.435490\nTrain Epoch: 16 [240000/248297 (97%)]\tLoss: 0.531674\nTrain Epoch: 16 [241000/248297 (97%)]\tLoss: 0.474228\nTrain Epoch: 16 [242000/248297 (98%)]\tLoss: 0.524179\nTrain Epoch: 16 [243000/248297 (98%)]\tLoss: 0.531971\nTrain Epoch: 16 [244000/248297 (98%)]\tLoss: 0.388206\nTrain Epoch: 16 [245000/248297 (99%)]\tLoss: 0.473972\nTrain Epoch: 16 [246000/248297 (99%)]\tLoss: 0.478222\nTrain Epoch: 16 [247000/248297 (100%)]\tLoss: 0.486324\nTrain Epoch: 16 [248000/248297 (100%)]\tLoss: 0.454891\n\nTest set: Average loss: 0.0050, Accuracy: 20738/27589 (75%)\n\nTrain Epoch: 17 [0/248297 (0%)]\tLoss: 0.517793\nTrain Epoch: 17 [1000/248297 (0%)]\tLoss: 0.460033\nTrain Epoch: 17 [2000/248297 (1%)]\tLoss: 0.620826\nTrain Epoch: 17 [3000/248297 (1%)]\tLoss: 0.480042\nTrain Epoch: 17 [4000/248297 (2%)]\tLoss: 0.423935\nTrain Epoch: 17 [5000/248297 (2%)]\tLoss: 0.576639\nTrain Epoch: 17 [6000/248297 (2%)]\tLoss: 0.438826\nTrain Epoch: 17 [7000/248297 (3%)]\tLoss: 0.524266\nTrain Epoch: 17 [8000/248297 (3%)]\tLoss: 0.517248\nTrain Epoch: 17 [9000/248297 (4%)]\tLoss: 0.512251\nTrain Epoch: 17 [10000/248297 (4%)]\tLoss: 0.433936\nTrain Epoch: 17 [11000/248297 (4%)]\tLoss: 0.479490\nTrain Epoch: 17 [12000/248297 (5%)]\tLoss: 0.461415\nTrain Epoch: 17 [13000/248297 (5%)]\tLoss: 0.427999\nTrain Epoch: 17 [14000/248297 (6%)]\tLoss: 0.555115\nTrain Epoch: 17 [15000/248297 (6%)]\tLoss: 0.423343\nTrain Epoch: 17 [16000/248297 (6%)]\tLoss: 0.501306\nTrain Epoch: 17 [17000/248297 (7%)]\tLoss: 0.409676\nTrain Epoch: 17 [18000/248297 (7%)]\tLoss: 0.559359\nTrain Epoch: 17 [19000/248297 (8%)]\tLoss: 0.436117\nTrain Epoch: 17 [20000/248297 (8%)]\tLoss: 0.479540\nTrain Epoch: 17 [21000/248297 (8%)]\tLoss: 0.468376\nTrain Epoch: 17 [22000/248297 (9%)]\tLoss: 0.505338\nTrain Epoch: 17 [23000/248297 (9%)]\tLoss: 0.458166\nTrain Epoch: 17 [24000/248297 (10%)]\tLoss: 0.451994\nTrain Epoch: 17 [25000/248297 (10%)]\tLoss: 0.532684\nTrain Epoch: 17 [26000/248297 (10%)]\tLoss: 0.470102\nTrain Epoch: 17 [27000/248297 (11%)]\tLoss: 0.437503\nTrain Epoch: 17 [28000/248297 (11%)]\tLoss: 0.435538\nTrain Epoch: 17 [29000/248297 (12%)]\tLoss: 0.458912\nTrain Epoch: 17 [30000/248297 (12%)]\tLoss: 0.541716\nTrain Epoch: 17 [31000/248297 (12%)]\tLoss: 0.546482\nTrain Epoch: 17 [32000/248297 (13%)]\tLoss: 0.467845\nTrain Epoch: 17 [33000/248297 (13%)]\tLoss: 0.523931\nTrain Epoch: 17 [34000/248297 (14%)]\tLoss: 0.527746\nTrain Epoch: 17 [35000/248297 (14%)]\tLoss: 0.538079\nTrain Epoch: 17 [36000/248297 (15%)]\tLoss: 0.511825\nTrain Epoch: 17 [37000/248297 (15%)]\tLoss: 0.553822\nTrain Epoch: 17 [38000/248297 (15%)]\tLoss: 0.478366\nTrain Epoch: 17 [39000/248297 (16%)]\tLoss: 0.517453\nTrain Epoch: 17 [40000/248297 (16%)]\tLoss: 0.507205\nTrain Epoch: 17 [41000/248297 (17%)]\tLoss: 0.476256\nTrain Epoch: 17 [42000/248297 (17%)]\tLoss: 0.472678\nTrain Epoch: 17 [43000/248297 (17%)]\tLoss: 0.482791\nTrain Epoch: 17 [44000/248297 (18%)]\tLoss: 0.533758\nTrain Epoch: 17 [45000/248297 (18%)]\tLoss: 0.550065\nTrain Epoch: 17 [46000/248297 (19%)]\tLoss: 0.504636\nTrain Epoch: 17 [47000/248297 (19%)]\tLoss: 0.545013\nTrain Epoch: 17 [48000/248297 (19%)]\tLoss: 0.466695\nTrain Epoch: 17 [49000/248297 (20%)]\tLoss: 0.472498\nTrain Epoch: 17 [50000/248297 (20%)]\tLoss: 0.445031\nTrain Epoch: 17 [51000/248297 (21%)]\tLoss: 0.497880\nTrain Epoch: 17 [52000/248297 (21%)]\tLoss: 0.503097\nTrain Epoch: 17 [53000/248297 (21%)]\tLoss: 0.424665\nTrain Epoch: 17 [54000/248297 (22%)]\tLoss: 0.557337\nTrain Epoch: 17 [55000/248297 (22%)]\tLoss: 0.481656\nTrain Epoch: 17 [56000/248297 (23%)]\tLoss: 0.460610\nTrain Epoch: 17 [57000/248297 (23%)]\tLoss: 0.502912\nTrain Epoch: 17 [58000/248297 (23%)]\tLoss: 0.466894\nTrain Epoch: 17 [59000/248297 (24%)]\tLoss: 0.599021\nTrain Epoch: 17 [60000/248297 (24%)]\tLoss: 0.513101\nTrain Epoch: 17 [61000/248297 (25%)]\tLoss: 0.476883\nTrain Epoch: 17 [62000/248297 (25%)]\tLoss: 0.537767\nTrain Epoch: 17 [63000/248297 (25%)]\tLoss: 0.439730\nTrain Epoch: 17 [64000/248297 (26%)]\tLoss: 0.507843\nTrain Epoch: 17 [65000/248297 (26%)]\tLoss: 0.522426\nTrain Epoch: 17 [66000/248297 (27%)]\tLoss: 0.515281\nTrain Epoch: 17 [67000/248297 (27%)]\tLoss: 0.465399\nTrain Epoch: 17 [68000/248297 (27%)]\tLoss: 0.442767\nTrain Epoch: 17 [69000/248297 (28%)]\tLoss: 0.445593\nTrain Epoch: 17 [70000/248297 (28%)]\tLoss: 0.516182\nTrain Epoch: 17 [71000/248297 (29%)]\tLoss: 0.552156\nTrain Epoch: 17 [72000/248297 (29%)]\tLoss: 0.438157\nTrain Epoch: 17 [73000/248297 (29%)]\tLoss: 0.557530\nTrain Epoch: 17 [74000/248297 (30%)]\tLoss: 0.526002\nTrain Epoch: 17 [75000/248297 (30%)]\tLoss: 0.466327\nTrain Epoch: 17 [76000/248297 (31%)]\tLoss: 0.454067\nTrain Epoch: 17 [77000/248297 (31%)]\tLoss: 0.539727\nTrain Epoch: 17 [78000/248297 (31%)]\tLoss: 0.473218\nTrain Epoch: 17 [79000/248297 (32%)]\tLoss: 0.443127\nTrain Epoch: 17 [80000/248297 (32%)]\tLoss: 0.440494\nTrain Epoch: 17 [81000/248297 (33%)]\tLoss: 0.478226\nTrain Epoch: 17 [82000/248297 (33%)]\tLoss: 0.451202\nTrain Epoch: 17 [83000/248297 (33%)]\tLoss: 0.475489\nTrain Epoch: 17 [84000/248297 (34%)]\tLoss: 0.619994\nTrain Epoch: 17 [85000/248297 (34%)]\tLoss: 0.535902\nTrain Epoch: 17 [86000/248297 (35%)]\tLoss: 0.540276\nTrain Epoch: 17 [87000/248297 (35%)]\tLoss: 0.643271\nTrain Epoch: 17 [88000/248297 (35%)]\tLoss: 0.413926\nTrain Epoch: 17 [89000/248297 (36%)]\tLoss: 0.483742\nTrain Epoch: 17 [90000/248297 (36%)]\tLoss: 0.431840\nTrain Epoch: 17 [91000/248297 (37%)]\tLoss: 0.384708\nTrain Epoch: 17 [92000/248297 (37%)]\tLoss: 0.525558\nTrain Epoch: 17 [93000/248297 (37%)]\tLoss: 0.440295\nTrain Epoch: 17 [94000/248297 (38%)]\tLoss: 0.547861\nTrain Epoch: 17 [95000/248297 (38%)]\tLoss: 0.415794\nTrain Epoch: 17 [96000/248297 (39%)]\tLoss: 0.414164\nTrain Epoch: 17 [97000/248297 (39%)]\tLoss: 0.478986\nTrain Epoch: 17 [98000/248297 (39%)]\tLoss: 0.571203\nTrain Epoch: 17 [99000/248297 (40%)]\tLoss: 0.593067\nTrain Epoch: 17 [100000/248297 (40%)]\tLoss: 0.577589\nTrain Epoch: 17 [101000/248297 (41%)]\tLoss: 0.481115\nTrain Epoch: 17 [102000/248297 (41%)]\tLoss: 0.501251\nTrain Epoch: 17 [103000/248297 (41%)]\tLoss: 0.426075\nTrain Epoch: 17 [104000/248297 (42%)]\tLoss: 0.414881\nTrain Epoch: 17 [105000/248297 (42%)]\tLoss: 0.501221\nTrain Epoch: 17 [106000/248297 (43%)]\tLoss: 0.475899\nTrain Epoch: 17 [107000/248297 (43%)]\tLoss: 0.421287\nTrain Epoch: 17 [108000/248297 (44%)]\tLoss: 0.509833\nTrain Epoch: 17 [109000/248297 (44%)]\tLoss: 0.394283\nTrain Epoch: 17 [110000/248297 (44%)]\tLoss: 0.460738\nTrain Epoch: 17 [111000/248297 (45%)]\tLoss: 0.464667\nTrain Epoch: 17 [112000/248297 (45%)]\tLoss: 0.662246\nTrain Epoch: 17 [113000/248297 (46%)]\tLoss: 0.486591\nTrain Epoch: 17 [114000/248297 (46%)]\tLoss: 0.552851\nTrain Epoch: 17 [115000/248297 (46%)]\tLoss: 0.460098\nTrain Epoch: 17 [116000/248297 (47%)]\tLoss: 0.540471\nTrain Epoch: 17 [117000/248297 (47%)]\tLoss: 0.509593\nTrain Epoch: 17 [118000/248297 (48%)]\tLoss: 0.466692\nTrain Epoch: 17 [119000/248297 (48%)]\tLoss: 0.530771\nTrain Epoch: 17 [120000/248297 (48%)]\tLoss: 0.447957\nTrain Epoch: 17 [121000/248297 (49%)]\tLoss: 0.460742\nTrain Epoch: 17 [122000/248297 (49%)]\tLoss: 0.479411\nTrain Epoch: 17 [123000/248297 (50%)]\tLoss: 0.589322\nTrain Epoch: 17 [124000/248297 (50%)]\tLoss: 0.439796\nTrain Epoch: 17 [125000/248297 (50%)]\tLoss: 0.389923\nTrain Epoch: 17 [126000/248297 (51%)]\tLoss: 0.405666\nTrain Epoch: 17 [127000/248297 (51%)]\tLoss: 0.444938\nTrain Epoch: 17 [128000/248297 (52%)]\tLoss: 0.434434\nTrain Epoch: 17 [129000/248297 (52%)]\tLoss: 0.441327\nTrain Epoch: 17 [130000/248297 (52%)]\tLoss: 0.404424\nTrain Epoch: 17 [131000/248297 (53%)]\tLoss: 0.546182\nTrain Epoch: 17 [132000/248297 (53%)]\tLoss: 0.480673\nTrain Epoch: 17 [133000/248297 (54%)]\tLoss: 0.525057\nTrain Epoch: 17 [134000/248297 (54%)]\tLoss: 0.436119\nTrain Epoch: 17 [135000/248297 (54%)]\tLoss: 0.528109\nTrain Epoch: 17 [136000/248297 (55%)]\tLoss: 0.460722\nTrain Epoch: 17 [137000/248297 (55%)]\tLoss: 0.593258\nTrain Epoch: 17 [138000/248297 (56%)]\tLoss: 0.442948\nTrain Epoch: 17 [139000/248297 (56%)]\tLoss: 0.519985\nTrain Epoch: 17 [140000/248297 (56%)]\tLoss: 0.481086\nTrain Epoch: 17 [141000/248297 (57%)]\tLoss: 0.463519\nTrain Epoch: 17 [142000/248297 (57%)]\tLoss: 0.511287\nTrain Epoch: 17 [143000/248297 (58%)]\tLoss: 0.418064\nTrain Epoch: 17 [144000/248297 (58%)]\tLoss: 0.522397\nTrain Epoch: 17 [145000/248297 (58%)]\tLoss: 0.460127\nTrain Epoch: 17 [146000/248297 (59%)]\tLoss: 0.458724\nTrain Epoch: 17 [147000/248297 (59%)]\tLoss: 0.523205\nTrain Epoch: 17 [148000/248297 (60%)]\tLoss: 0.446869\nTrain Epoch: 17 [149000/248297 (60%)]\tLoss: 0.546437\nTrain Epoch: 17 [150000/248297 (60%)]\tLoss: 0.573656\nTrain Epoch: 17 [151000/248297 (61%)]\tLoss: 0.518053\nTrain Epoch: 17 [152000/248297 (61%)]\tLoss: 0.481696\nTrain Epoch: 17 [153000/248297 (62%)]\tLoss: 0.448864\nTrain Epoch: 17 [154000/248297 (62%)]\tLoss: 0.464411\nTrain Epoch: 17 [155000/248297 (62%)]\tLoss: 0.503086\nTrain Epoch: 17 [156000/248297 (63%)]\tLoss: 0.505672\nTrain Epoch: 17 [157000/248297 (63%)]\tLoss: 0.430724\nTrain Epoch: 17 [158000/248297 (64%)]\tLoss: 0.450735\nTrain Epoch: 17 [159000/248297 (64%)]\tLoss: 0.424904\nTrain Epoch: 17 [160000/248297 (64%)]\tLoss: 0.459932\nTrain Epoch: 17 [161000/248297 (65%)]\tLoss: 0.526015\nTrain Epoch: 17 [162000/248297 (65%)]\tLoss: 0.415704\nTrain Epoch: 17 [163000/248297 (66%)]\tLoss: 0.487553\nTrain Epoch: 17 [164000/248297 (66%)]\tLoss: 0.619377\nTrain Epoch: 17 [165000/248297 (66%)]\tLoss: 0.452848\nTrain Epoch: 17 [166000/248297 (67%)]\tLoss: 0.443904\nTrain Epoch: 17 [167000/248297 (67%)]\tLoss: 0.516528\nTrain Epoch: 17 [168000/248297 (68%)]\tLoss: 0.447045\nTrain Epoch: 17 [169000/248297 (68%)]\tLoss: 0.461318\nTrain Epoch: 17 [170000/248297 (68%)]\tLoss: 0.493969\nTrain Epoch: 17 [171000/248297 (69%)]\tLoss: 0.549048\nTrain Epoch: 17 [172000/248297 (69%)]\tLoss: 0.381863\nTrain Epoch: 17 [173000/248297 (70%)]\tLoss: 0.574003\nTrain Epoch: 17 [174000/248297 (70%)]\tLoss: 0.488965\nTrain Epoch: 17 [175000/248297 (71%)]\tLoss: 0.561360\nTrain Epoch: 17 [176000/248297 (71%)]\tLoss: 0.416651\nTrain Epoch: 17 [177000/248297 (71%)]\tLoss: 0.477129\nTrain Epoch: 17 [178000/248297 (72%)]\tLoss: 0.490613\nTrain Epoch: 17 [179000/248297 (72%)]\tLoss: 0.525772\nTrain Epoch: 17 [180000/248297 (73%)]\tLoss: 0.493150\nTrain Epoch: 17 [181000/248297 (73%)]\tLoss: 0.512644\nTrain Epoch: 17 [182000/248297 (73%)]\tLoss: 0.489072\nTrain Epoch: 17 [183000/248297 (74%)]\tLoss: 0.422911\nTrain Epoch: 17 [184000/248297 (74%)]\tLoss: 0.584454\nTrain Epoch: 17 [185000/248297 (75%)]\tLoss: 0.419284\nTrain Epoch: 17 [186000/248297 (75%)]\tLoss: 0.594572\nTrain Epoch: 17 [187000/248297 (75%)]\tLoss: 0.513170\nTrain Epoch: 17 [188000/248297 (76%)]\tLoss: 0.447392\nTrain Epoch: 17 [189000/248297 (76%)]\tLoss: 0.512071\nTrain Epoch: 17 [190000/248297 (77%)]\tLoss: 0.393996\nTrain Epoch: 17 [191000/248297 (77%)]\tLoss: 0.486700\nTrain Epoch: 17 [192000/248297 (77%)]\tLoss: 0.449535\nTrain Epoch: 17 [193000/248297 (78%)]\tLoss: 0.398602\nTrain Epoch: 17 [194000/248297 (78%)]\tLoss: 0.453535\nTrain Epoch: 17 [195000/248297 (79%)]\tLoss: 0.440397\nTrain Epoch: 17 [196000/248297 (79%)]\tLoss: 0.539307\nTrain Epoch: 17 [197000/248297 (79%)]\tLoss: 0.542416\nTrain Epoch: 17 [198000/248297 (80%)]\tLoss: 0.441138\nTrain Epoch: 17 [199000/248297 (80%)]\tLoss: 0.519310\nTrain Epoch: 17 [200000/248297 (81%)]\tLoss: 0.443819\nTrain Epoch: 17 [201000/248297 (81%)]\tLoss: 0.532993\nTrain Epoch: 17 [202000/248297 (81%)]\tLoss: 0.514418\nTrain Epoch: 17 [203000/248297 (82%)]\tLoss: 0.364511\nTrain Epoch: 17 [204000/248297 (82%)]\tLoss: 0.496439\nTrain Epoch: 17 [205000/248297 (83%)]\tLoss: 0.460697\nTrain Epoch: 17 [206000/248297 (83%)]\tLoss: 0.454628\nTrain Epoch: 17 [207000/248297 (83%)]\tLoss: 0.451663\nTrain Epoch: 17 [208000/248297 (84%)]\tLoss: 0.566680\nTrain Epoch: 17 [209000/248297 (84%)]\tLoss: 0.502072\nTrain Epoch: 17 [210000/248297 (85%)]\tLoss: 0.478535\nTrain Epoch: 17 [211000/248297 (85%)]\tLoss: 0.542348\nTrain Epoch: 17 [212000/248297 (85%)]\tLoss: 0.526193\nTrain Epoch: 17 [213000/248297 (86%)]\tLoss: 0.523401\nTrain Epoch: 17 [214000/248297 (86%)]\tLoss: 0.444487\nTrain Epoch: 17 [215000/248297 (87%)]\tLoss: 0.522306\nTrain Epoch: 17 [216000/248297 (87%)]\tLoss: 0.476748\nTrain Epoch: 17 [217000/248297 (87%)]\tLoss: 0.542562\nTrain Epoch: 17 [218000/248297 (88%)]\tLoss: 0.562545\nTrain Epoch: 17 [219000/248297 (88%)]\tLoss: 0.399001\nTrain Epoch: 17 [220000/248297 (89%)]\tLoss: 0.413793\nTrain Epoch: 17 [221000/248297 (89%)]\tLoss: 0.558616\nTrain Epoch: 17 [222000/248297 (89%)]\tLoss: 0.398641\nTrain Epoch: 17 [223000/248297 (90%)]\tLoss: 0.514372\nTrain Epoch: 17 [224000/248297 (90%)]\tLoss: 0.501248\nTrain Epoch: 17 [225000/248297 (91%)]\tLoss: 0.471150\nTrain Epoch: 17 [226000/248297 (91%)]\tLoss: 0.432112\nTrain Epoch: 17 [227000/248297 (91%)]\tLoss: 0.383126\nTrain Epoch: 17 [228000/248297 (92%)]\tLoss: 0.483487\nTrain Epoch: 17 [229000/248297 (92%)]\tLoss: 0.478739\nTrain Epoch: 17 [230000/248297 (93%)]\tLoss: 0.452048\nTrain Epoch: 17 [231000/248297 (93%)]\tLoss: 0.616219\nTrain Epoch: 17 [232000/248297 (93%)]\tLoss: 0.417161\nTrain Epoch: 17 [233000/248297 (94%)]\tLoss: 0.451816\nTrain Epoch: 17 [234000/248297 (94%)]\tLoss: 0.524707\nTrain Epoch: 17 [235000/248297 (95%)]\tLoss: 0.629513\nTrain Epoch: 17 [236000/248297 (95%)]\tLoss: 0.373916\nTrain Epoch: 17 [237000/248297 (95%)]\tLoss: 0.469657\nTrain Epoch: 17 [238000/248297 (96%)]\tLoss: 0.495661\nTrain Epoch: 17 [239000/248297 (96%)]\tLoss: 0.526655\nTrain Epoch: 17 [240000/248297 (97%)]\tLoss: 0.536242\nTrain Epoch: 17 [241000/248297 (97%)]\tLoss: 0.514007\nTrain Epoch: 17 [242000/248297 (98%)]\tLoss: 0.444766\nTrain Epoch: 17 [243000/248297 (98%)]\tLoss: 0.548604\nTrain Epoch: 17 [244000/248297 (98%)]\tLoss: 0.522059\nTrain Epoch: 17 [245000/248297 (99%)]\tLoss: 0.460720\nTrain Epoch: 17 [246000/248297 (99%)]\tLoss: 0.564669\nTrain Epoch: 17 [247000/248297 (100%)]\tLoss: 0.492803\nTrain Epoch: 17 [248000/248297 (100%)]\tLoss: 0.417483\n\nTest set: Average loss: 0.0050, Accuracy: 20732/27589 (75%)\n\nTrain Epoch: 18 [0/248297 (0%)]\tLoss: 0.475059\nTrain Epoch: 18 [1000/248297 (0%)]\tLoss: 0.524638\nTrain Epoch: 18 [2000/248297 (1%)]\tLoss: 0.519491\nTrain Epoch: 18 [3000/248297 (1%)]\tLoss: 0.539189\nTrain Epoch: 18 [4000/248297 (2%)]\tLoss: 0.388662\nTrain Epoch: 18 [5000/248297 (2%)]\tLoss: 0.498790\nTrain Epoch: 18 [6000/248297 (2%)]\tLoss: 0.462433\nTrain Epoch: 18 [7000/248297 (3%)]\tLoss: 0.445860\nTrain Epoch: 18 [8000/248297 (3%)]\tLoss: 0.621880\nTrain Epoch: 18 [9000/248297 (4%)]\tLoss: 0.463676\nTrain Epoch: 18 [10000/248297 (4%)]\tLoss: 0.496258\nTrain Epoch: 18 [11000/248297 (4%)]\tLoss: 0.510316\nTrain Epoch: 18 [12000/248297 (5%)]\tLoss: 0.487356\nTrain Epoch: 18 [13000/248297 (5%)]\tLoss: 0.521511\nTrain Epoch: 18 [14000/248297 (6%)]\tLoss: 0.443687\nTrain Epoch: 18 [15000/248297 (6%)]\tLoss: 0.518778\nTrain Epoch: 18 [16000/248297 (6%)]\tLoss: 0.502689\nTrain Epoch: 18 [17000/248297 (7%)]\tLoss: 0.471478\nTrain Epoch: 18 [18000/248297 (7%)]\tLoss: 0.489919\nTrain Epoch: 18 [19000/248297 (8%)]\tLoss: 0.644957\nTrain Epoch: 18 [20000/248297 (8%)]\tLoss: 0.468165\nTrain Epoch: 18 [21000/248297 (8%)]\tLoss: 0.436649\nTrain Epoch: 18 [22000/248297 (9%)]\tLoss: 0.485194\nTrain Epoch: 18 [23000/248297 (9%)]\tLoss: 0.484243\nTrain Epoch: 18 [24000/248297 (10%)]\tLoss: 0.514505\nTrain Epoch: 18 [25000/248297 (10%)]\tLoss: 0.561443\nTrain Epoch: 18 [26000/248297 (10%)]\tLoss: 0.483469\nTrain Epoch: 18 [27000/248297 (11%)]\tLoss: 0.572010\nTrain Epoch: 18 [28000/248297 (11%)]\tLoss: 0.397346\nTrain Epoch: 18 [29000/248297 (12%)]\tLoss: 0.494862\nTrain Epoch: 18 [30000/248297 (12%)]\tLoss: 0.445010\nTrain Epoch: 18 [31000/248297 (12%)]\tLoss: 0.487730\nTrain Epoch: 18 [32000/248297 (13%)]\tLoss: 0.391151\nTrain Epoch: 18 [33000/248297 (13%)]\tLoss: 0.498814\nTrain Epoch: 18 [34000/248297 (14%)]\tLoss: 0.553286\nTrain Epoch: 18 [35000/248297 (14%)]\tLoss: 0.500870\nTrain Epoch: 18 [36000/248297 (15%)]\tLoss: 0.453550\nTrain Epoch: 18 [37000/248297 (15%)]\tLoss: 0.416467\nTrain Epoch: 18 [38000/248297 (15%)]\tLoss: 0.559173\nTrain Epoch: 18 [39000/248297 (16%)]\tLoss: 0.436370\nTrain Epoch: 18 [40000/248297 (16%)]\tLoss: 0.497361\nTrain Epoch: 18 [41000/248297 (17%)]\tLoss: 0.462760\nTrain Epoch: 18 [42000/248297 (17%)]\tLoss: 0.463506\nTrain Epoch: 18 [43000/248297 (17%)]\tLoss: 0.515415\nTrain Epoch: 18 [44000/248297 (18%)]\tLoss: 0.479751\nTrain Epoch: 18 [45000/248297 (18%)]\tLoss: 0.521188\nTrain Epoch: 18 [46000/248297 (19%)]\tLoss: 0.546351\nTrain Epoch: 18 [47000/248297 (19%)]\tLoss: 0.522583\nTrain Epoch: 18 [48000/248297 (19%)]\tLoss: 0.462565\nTrain Epoch: 18 [49000/248297 (20%)]\tLoss: 0.494021\nTrain Epoch: 18 [50000/248297 (20%)]\tLoss: 0.543045\nTrain Epoch: 18 [51000/248297 (21%)]\tLoss: 0.507328\nTrain Epoch: 18 [52000/248297 (21%)]\tLoss: 0.457745\nTrain Epoch: 18 [53000/248297 (21%)]\tLoss: 0.560837\nTrain Epoch: 18 [54000/248297 (22%)]\tLoss: 0.497691\nTrain Epoch: 18 [55000/248297 (22%)]\tLoss: 0.474649\nTrain Epoch: 18 [56000/248297 (23%)]\tLoss: 0.493760\nTrain Epoch: 18 [57000/248297 (23%)]\tLoss: 0.572774\nTrain Epoch: 18 [58000/248297 (23%)]\tLoss: 0.472399\nTrain Epoch: 18 [59000/248297 (24%)]\tLoss: 0.408604\nTrain Epoch: 18 [60000/248297 (24%)]\tLoss: 0.500211\nTrain Epoch: 18 [61000/248297 (25%)]\tLoss: 0.391446\nTrain Epoch: 18 [62000/248297 (25%)]\tLoss: 0.439386\nTrain Epoch: 18 [63000/248297 (25%)]\tLoss: 0.554959\nTrain Epoch: 18 [64000/248297 (26%)]\tLoss: 0.581361\nTrain Epoch: 18 [65000/248297 (26%)]\tLoss: 0.543696\nTrain Epoch: 18 [66000/248297 (27%)]\tLoss: 0.466230\nTrain Epoch: 18 [67000/248297 (27%)]\tLoss: 0.414520\nTrain Epoch: 18 [68000/248297 (27%)]\tLoss: 0.454709\nTrain Epoch: 18 [69000/248297 (28%)]\tLoss: 0.577306\nTrain Epoch: 18 [70000/248297 (28%)]\tLoss: 0.542873\nTrain Epoch: 18 [71000/248297 (29%)]\tLoss: 0.467494\nTrain Epoch: 18 [72000/248297 (29%)]\tLoss: 0.482352\nTrain Epoch: 18 [73000/248297 (29%)]\tLoss: 0.479506\nTrain Epoch: 18 [74000/248297 (30%)]\tLoss: 0.552786\nTrain Epoch: 18 [75000/248297 (30%)]\tLoss: 0.519112\nTrain Epoch: 18 [76000/248297 (31%)]\tLoss: 0.520218\nTrain Epoch: 18 [77000/248297 (31%)]\tLoss: 0.440838\nTrain Epoch: 18 [78000/248297 (31%)]\tLoss: 0.414262\nTrain Epoch: 18 [79000/248297 (32%)]\tLoss: 0.503589\nTrain Epoch: 18 [80000/248297 (32%)]\tLoss: 0.462491\nTrain Epoch: 18 [81000/248297 (33%)]\tLoss: 0.483982\nTrain Epoch: 18 [82000/248297 (33%)]\tLoss: 0.461142\nTrain Epoch: 18 [83000/248297 (33%)]\tLoss: 0.370283\nTrain Epoch: 18 [84000/248297 (34%)]\tLoss: 0.489893\nTrain Epoch: 18 [85000/248297 (34%)]\tLoss: 0.502823\nTrain Epoch: 18 [86000/248297 (35%)]\tLoss: 0.415769\nTrain Epoch: 18 [87000/248297 (35%)]\tLoss: 0.519896\nTrain Epoch: 18 [88000/248297 (35%)]\tLoss: 0.524975\nTrain Epoch: 18 [89000/248297 (36%)]\tLoss: 0.415717\nTrain Epoch: 18 [90000/248297 (36%)]\tLoss: 0.550005\nTrain Epoch: 18 [91000/248297 (37%)]\tLoss: 0.528290\nTrain Epoch: 18 [92000/248297 (37%)]\tLoss: 0.524779\nTrain Epoch: 18 [93000/248297 (37%)]\tLoss: 0.502637\nTrain Epoch: 18 [94000/248297 (38%)]\tLoss: 0.436300\nTrain Epoch: 18 [95000/248297 (38%)]\tLoss: 0.412659\nTrain Epoch: 18 [96000/248297 (39%)]\tLoss: 0.501213\nTrain Epoch: 18 [97000/248297 (39%)]\tLoss: 0.448758\nTrain Epoch: 18 [98000/248297 (39%)]\tLoss: 0.531866\nTrain Epoch: 18 [99000/248297 (40%)]\tLoss: 0.529605\nTrain Epoch: 18 [100000/248297 (40%)]\tLoss: 0.620751\nTrain Epoch: 18 [101000/248297 (41%)]\tLoss: 0.508621\nTrain Epoch: 18 [102000/248297 (41%)]\tLoss: 0.451862\nTrain Epoch: 18 [103000/248297 (41%)]\tLoss: 0.449189\nTrain Epoch: 18 [104000/248297 (42%)]\tLoss: 0.438231\nTrain Epoch: 18 [105000/248297 (42%)]\tLoss: 0.483134\nTrain Epoch: 18 [106000/248297 (43%)]\tLoss: 0.472170\nTrain Epoch: 18 [107000/248297 (43%)]\tLoss: 0.418382\nTrain Epoch: 18 [108000/248297 (44%)]\tLoss: 0.482486\nTrain Epoch: 18 [109000/248297 (44%)]\tLoss: 0.506104\nTrain Epoch: 18 [110000/248297 (44%)]\tLoss: 0.470001\nTrain Epoch: 18 [111000/248297 (45%)]\tLoss: 0.389899\nTrain Epoch: 18 [112000/248297 (45%)]\tLoss: 0.515076\nTrain Epoch: 18 [113000/248297 (46%)]\tLoss: 0.465452\nTrain Epoch: 18 [114000/248297 (46%)]\tLoss: 0.437325\nTrain Epoch: 18 [115000/248297 (46%)]\tLoss: 0.467745\nTrain Epoch: 18 [116000/248297 (47%)]\tLoss: 0.468954\nTrain Epoch: 18 [117000/248297 (47%)]\tLoss: 0.403512\nTrain Epoch: 18 [118000/248297 (48%)]\tLoss: 0.467302\nTrain Epoch: 18 [119000/248297 (48%)]\tLoss: 0.625696\nTrain Epoch: 18 [120000/248297 (48%)]\tLoss: 0.519330\nTrain Epoch: 18 [121000/248297 (49%)]\tLoss: 0.513429\nTrain Epoch: 18 [122000/248297 (49%)]\tLoss: 0.504668\nTrain Epoch: 18 [123000/248297 (50%)]\tLoss: 0.546016\nTrain Epoch: 18 [124000/248297 (50%)]\tLoss: 0.475244\nTrain Epoch: 18 [125000/248297 (50%)]\tLoss: 0.438623\nTrain Epoch: 18 [126000/248297 (51%)]\tLoss: 0.547432\nTrain Epoch: 18 [127000/248297 (51%)]\tLoss: 0.526877\nTrain Epoch: 18 [128000/248297 (52%)]\tLoss: 0.545378\nTrain Epoch: 18 [129000/248297 (52%)]\tLoss: 0.545226\nTrain Epoch: 18 [130000/248297 (52%)]\tLoss: 0.446724\nTrain Epoch: 18 [131000/248297 (53%)]\tLoss: 0.507388\nTrain Epoch: 18 [132000/248297 (53%)]\tLoss: 0.453517\nTrain Epoch: 18 [133000/248297 (54%)]\tLoss: 0.507147\nTrain Epoch: 18 [134000/248297 (54%)]\tLoss: 0.407977\nTrain Epoch: 18 [135000/248297 (54%)]\tLoss: 0.467151\nTrain Epoch: 18 [136000/248297 (55%)]\tLoss: 0.520483\nTrain Epoch: 18 [137000/248297 (55%)]\tLoss: 0.489810\nTrain Epoch: 18 [138000/248297 (56%)]\tLoss: 0.491914\nTrain Epoch: 18 [139000/248297 (56%)]\tLoss: 0.552432\nTrain Epoch: 18 [140000/248297 (56%)]\tLoss: 0.411360\nTrain Epoch: 18 [141000/248297 (57%)]\tLoss: 0.566457\nTrain Epoch: 18 [142000/248297 (57%)]\tLoss: 0.496248\nTrain Epoch: 18 [143000/248297 (58%)]\tLoss: 0.574707\nTrain Epoch: 18 [144000/248297 (58%)]\tLoss: 0.458024\nTrain Epoch: 18 [145000/248297 (58%)]\tLoss: 0.536205\nTrain Epoch: 18 [146000/248297 (59%)]\tLoss: 0.527626\nTrain Epoch: 18 [147000/248297 (59%)]\tLoss: 0.507106\nTrain Epoch: 18 [148000/248297 (60%)]\tLoss: 0.517364\nTrain Epoch: 18 [149000/248297 (60%)]\tLoss: 0.440561\nTrain Epoch: 18 [150000/248297 (60%)]\tLoss: 0.404483\nTrain Epoch: 18 [151000/248297 (61%)]\tLoss: 0.445428\nTrain Epoch: 18 [152000/248297 (61%)]\tLoss: 0.489989\nTrain Epoch: 18 [153000/248297 (62%)]\tLoss: 0.423866\nTrain Epoch: 18 [154000/248297 (62%)]\tLoss: 0.518089\nTrain Epoch: 18 [155000/248297 (62%)]\tLoss: 0.478173\nTrain Epoch: 18 [156000/248297 (63%)]\tLoss: 0.424086\nTrain Epoch: 18 [157000/248297 (63%)]\tLoss: 0.438612\nTrain Epoch: 18 [158000/248297 (64%)]\tLoss: 0.471041\nTrain Epoch: 18 [159000/248297 (64%)]\tLoss: 0.458093\nTrain Epoch: 18 [160000/248297 (64%)]\tLoss: 0.460295\nTrain Epoch: 18 [161000/248297 (65%)]\tLoss: 0.516036\nTrain Epoch: 18 [162000/248297 (65%)]\tLoss: 0.514507\nTrain Epoch: 18 [163000/248297 (66%)]\tLoss: 0.514399\nTrain Epoch: 18 [164000/248297 (66%)]\tLoss: 0.544380\nTrain Epoch: 18 [165000/248297 (66%)]\tLoss: 0.435455\nTrain Epoch: 18 [166000/248297 (67%)]\tLoss: 0.482164\nTrain Epoch: 18 [167000/248297 (67%)]\tLoss: 0.549028\nTrain Epoch: 18 [168000/248297 (68%)]\tLoss: 0.516289\nTrain Epoch: 18 [169000/248297 (68%)]\tLoss: 0.491736\nTrain Epoch: 18 [170000/248297 (68%)]\tLoss: 0.425415\nTrain Epoch: 18 [171000/248297 (69%)]\tLoss: 0.439366\nTrain Epoch: 18 [172000/248297 (69%)]\tLoss: 0.519163\nTrain Epoch: 18 [173000/248297 (70%)]\tLoss: 0.472414\nTrain Epoch: 18 [174000/248297 (70%)]\tLoss: 0.456454\nTrain Epoch: 18 [175000/248297 (71%)]\tLoss: 0.465555\nTrain Epoch: 18 [176000/248297 (71%)]\tLoss: 0.523823\nTrain Epoch: 18 [177000/248297 (71%)]\tLoss: 0.465367\nTrain Epoch: 18 [178000/248297 (72%)]\tLoss: 0.408802\nTrain Epoch: 18 [179000/248297 (72%)]\tLoss: 0.553766\nTrain Epoch: 18 [180000/248297 (73%)]\tLoss: 0.484859\nTrain Epoch: 18 [181000/248297 (73%)]\tLoss: 0.483105\nTrain Epoch: 18 [182000/248297 (73%)]\tLoss: 0.550373\nTrain Epoch: 18 [183000/248297 (74%)]\tLoss: 0.585526\nTrain Epoch: 18 [184000/248297 (74%)]\tLoss: 0.481979\nTrain Epoch: 18 [185000/248297 (75%)]\tLoss: 0.557733\nTrain Epoch: 18 [186000/248297 (75%)]\tLoss: 0.501403\nTrain Epoch: 18 [187000/248297 (75%)]\tLoss: 0.550145\nTrain Epoch: 18 [188000/248297 (76%)]\tLoss: 0.550268\nTrain Epoch: 18 [189000/248297 (76%)]\tLoss: 0.488265\nTrain Epoch: 18 [190000/248297 (77%)]\tLoss: 0.485265\nTrain Epoch: 18 [191000/248297 (77%)]\tLoss: 0.437635\nTrain Epoch: 18 [192000/248297 (77%)]\tLoss: 0.475076\nTrain Epoch: 18 [193000/248297 (78%)]\tLoss: 0.560429\nTrain Epoch: 18 [194000/248297 (78%)]\tLoss: 0.422535\nTrain Epoch: 18 [195000/248297 (79%)]\tLoss: 0.511843\nTrain Epoch: 18 [196000/248297 (79%)]\tLoss: 0.416732\nTrain Epoch: 18 [197000/248297 (79%)]\tLoss: 0.463076\nTrain Epoch: 18 [198000/248297 (80%)]\tLoss: 0.472744\nTrain Epoch: 18 [199000/248297 (80%)]\tLoss: 0.512106\nTrain Epoch: 18 [200000/248297 (81%)]\tLoss: 0.521124\nTrain Epoch: 18 [201000/248297 (81%)]\tLoss: 0.446003\nTrain Epoch: 18 [202000/248297 (81%)]\tLoss: 0.476731\nTrain Epoch: 18 [203000/248297 (82%)]\tLoss: 0.536984\nTrain Epoch: 18 [204000/248297 (82%)]\tLoss: 0.510509\nTrain Epoch: 18 [205000/248297 (83%)]\tLoss: 0.412727\nTrain Epoch: 18 [206000/248297 (83%)]\tLoss: 0.499224\nTrain Epoch: 18 [207000/248297 (83%)]\tLoss: 0.425169\nTrain Epoch: 18 [208000/248297 (84%)]\tLoss: 0.483401\nTrain Epoch: 18 [209000/248297 (84%)]\tLoss: 0.477053\nTrain Epoch: 18 [210000/248297 (85%)]\tLoss: 0.469203\nTrain Epoch: 18 [211000/248297 (85%)]\tLoss: 0.486077\nTrain Epoch: 18 [212000/248297 (85%)]\tLoss: 0.525088\nTrain Epoch: 18 [213000/248297 (86%)]\tLoss: 0.492009\nTrain Epoch: 18 [214000/248297 (86%)]\tLoss: 0.537295\nTrain Epoch: 18 [215000/248297 (87%)]\tLoss: 0.486719\nTrain Epoch: 18 [216000/248297 (87%)]\tLoss: 0.501291\nTrain Epoch: 18 [217000/248297 (87%)]\tLoss: 0.571015\nTrain Epoch: 18 [218000/248297 (88%)]\tLoss: 0.520592\nTrain Epoch: 18 [219000/248297 (88%)]\tLoss: 0.489575\nTrain Epoch: 18 [220000/248297 (89%)]\tLoss: 0.455273\nTrain Epoch: 18 [221000/248297 (89%)]\tLoss: 0.551853\nTrain Epoch: 18 [222000/248297 (89%)]\tLoss: 0.421562\nTrain Epoch: 18 [223000/248297 (90%)]\tLoss: 0.477050\nTrain Epoch: 18 [224000/248297 (90%)]\tLoss: 0.467456\nTrain Epoch: 18 [225000/248297 (91%)]\tLoss: 0.454090\nTrain Epoch: 18 [226000/248297 (91%)]\tLoss: 0.543532\nTrain Epoch: 18 [227000/248297 (91%)]\tLoss: 0.527399\nTrain Epoch: 18 [228000/248297 (92%)]\tLoss: 0.514551\nTrain Epoch: 18 [229000/248297 (92%)]\tLoss: 0.425901\nTrain Epoch: 18 [230000/248297 (93%)]\tLoss: 0.446730\nTrain Epoch: 18 [231000/248297 (93%)]\tLoss: 0.409231\nTrain Epoch: 18 [232000/248297 (93%)]\tLoss: 0.425873\nTrain Epoch: 18 [233000/248297 (94%)]\tLoss: 0.519573\nTrain Epoch: 18 [234000/248297 (94%)]\tLoss: 0.503418\nTrain Epoch: 18 [235000/248297 (95%)]\tLoss: 0.491809\nTrain Epoch: 18 [236000/248297 (95%)]\tLoss: 0.473724\nTrain Epoch: 18 [237000/248297 (95%)]\tLoss: 0.436546\nTrain Epoch: 18 [238000/248297 (96%)]\tLoss: 0.497274\nTrain Epoch: 18 [239000/248297 (96%)]\tLoss: 0.445449\nTrain Epoch: 18 [240000/248297 (97%)]\tLoss: 0.420776\nTrain Epoch: 18 [241000/248297 (97%)]\tLoss: 0.404869\nTrain Epoch: 18 [242000/248297 (98%)]\tLoss: 0.433638\nTrain Epoch: 18 [243000/248297 (98%)]\tLoss: 0.485814\nTrain Epoch: 18 [244000/248297 (98%)]\tLoss: 0.451712\nTrain Epoch: 18 [245000/248297 (99%)]\tLoss: 0.501889\nTrain Epoch: 18 [246000/248297 (99%)]\tLoss: 0.413148\nTrain Epoch: 18 [247000/248297 (100%)]\tLoss: 0.552157\nTrain Epoch: 18 [248000/248297 (100%)]\tLoss: 0.449253\n\nTest set: Average loss: 0.0050, Accuracy: 20738/27589 (75%)\n\nTrain Epoch: 19 [0/248297 (0%)]\tLoss: 0.505868\nTrain Epoch: 19 [1000/248297 (0%)]\tLoss: 0.398873\nTrain Epoch: 19 [2000/248297 (1%)]\tLoss: 0.462146\nTrain Epoch: 19 [3000/248297 (1%)]\tLoss: 0.552418\nTrain Epoch: 19 [4000/248297 (2%)]\tLoss: 0.476424\nTrain Epoch: 19 [5000/248297 (2%)]\tLoss: 0.536673\nTrain Epoch: 19 [6000/248297 (2%)]\tLoss: 0.471386\nTrain Epoch: 19 [7000/248297 (3%)]\tLoss: 0.603375\nTrain Epoch: 19 [8000/248297 (3%)]\tLoss: 0.384582\nTrain Epoch: 19 [9000/248297 (4%)]\tLoss: 0.446950\nTrain Epoch: 19 [10000/248297 (4%)]\tLoss: 0.530807\nTrain Epoch: 19 [11000/248297 (4%)]\tLoss: 0.478277\nTrain Epoch: 19 [12000/248297 (5%)]\tLoss: 0.442920\nTrain Epoch: 19 [13000/248297 (5%)]\tLoss: 0.485150\nTrain Epoch: 19 [14000/248297 (6%)]\tLoss: 0.469479\nTrain Epoch: 19 [15000/248297 (6%)]\tLoss: 0.428148\nTrain Epoch: 19 [16000/248297 (6%)]\tLoss: 0.444845\nTrain Epoch: 19 [17000/248297 (7%)]\tLoss: 0.490477\nTrain Epoch: 19 [18000/248297 (7%)]\tLoss: 0.567607\nTrain Epoch: 19 [19000/248297 (8%)]\tLoss: 0.426763\nTrain Epoch: 19 [20000/248297 (8%)]\tLoss: 0.458048\nTrain Epoch: 19 [21000/248297 (8%)]\tLoss: 0.472655\nTrain Epoch: 19 [22000/248297 (9%)]\tLoss: 0.541074\nTrain Epoch: 19 [23000/248297 (9%)]\tLoss: 0.379894\nTrain Epoch: 19 [24000/248297 (10%)]\tLoss: 0.510689\nTrain Epoch: 19 [25000/248297 (10%)]\tLoss: 0.518750\nTrain Epoch: 19 [26000/248297 (10%)]\tLoss: 0.501661\nTrain Epoch: 19 [27000/248297 (11%)]\tLoss: 0.584901\nTrain Epoch: 19 [28000/248297 (11%)]\tLoss: 0.440182\nTrain Epoch: 19 [29000/248297 (12%)]\tLoss: 0.420433\nTrain Epoch: 19 [30000/248297 (12%)]\tLoss: 0.515063\nTrain Epoch: 19 [31000/248297 (12%)]\tLoss: 0.464000\nTrain Epoch: 19 [32000/248297 (13%)]\tLoss: 0.587903\nTrain Epoch: 19 [33000/248297 (13%)]\tLoss: 0.394720\nTrain Epoch: 19 [34000/248297 (14%)]\tLoss: 0.432725\nTrain Epoch: 19 [35000/248297 (14%)]\tLoss: 0.623585\nTrain Epoch: 19 [36000/248297 (15%)]\tLoss: 0.521100\nTrain Epoch: 19 [37000/248297 (15%)]\tLoss: 0.476101\nTrain Epoch: 19 [38000/248297 (15%)]\tLoss: 0.438312\nTrain Epoch: 19 [39000/248297 (16%)]\tLoss: 0.475030\nTrain Epoch: 19 [40000/248297 (16%)]\tLoss: 0.443980\nTrain Epoch: 19 [41000/248297 (17%)]\tLoss: 0.482809\nTrain Epoch: 19 [42000/248297 (17%)]\tLoss: 0.540241\nTrain Epoch: 19 [43000/248297 (17%)]\tLoss: 0.493756\nTrain Epoch: 19 [44000/248297 (18%)]\tLoss: 0.389460\nTrain Epoch: 19 [45000/248297 (18%)]\tLoss: 0.484186\nTrain Epoch: 19 [46000/248297 (19%)]\tLoss: 0.509571\nTrain Epoch: 19 [47000/248297 (19%)]\tLoss: 0.460153\nTrain Epoch: 19 [48000/248297 (19%)]\tLoss: 0.588299\nTrain Epoch: 19 [49000/248297 (20%)]\tLoss: 0.512147\nTrain Epoch: 19 [50000/248297 (20%)]\tLoss: 0.582956\nTrain Epoch: 19 [51000/248297 (21%)]\tLoss: 0.425846\nTrain Epoch: 19 [52000/248297 (21%)]\tLoss: 0.510644\nTrain Epoch: 19 [53000/248297 (21%)]\tLoss: 0.469567\nTrain Epoch: 19 [54000/248297 (22%)]\tLoss: 0.448199\nTrain Epoch: 19 [55000/248297 (22%)]\tLoss: 0.544851\nTrain Epoch: 19 [56000/248297 (23%)]\tLoss: 0.521885\nTrain Epoch: 19 [57000/248297 (23%)]\tLoss: 0.469836\nTrain Epoch: 19 [58000/248297 (23%)]\tLoss: 0.511384\nTrain Epoch: 19 [59000/248297 (24%)]\tLoss: 0.546322\nTrain Epoch: 19 [60000/248297 (24%)]\tLoss: 0.547096\nTrain Epoch: 19 [61000/248297 (25%)]\tLoss: 0.481551\nTrain Epoch: 19 [62000/248297 (25%)]\tLoss: 0.561831\nTrain Epoch: 19 [63000/248297 (25%)]\tLoss: 0.501006\nTrain Epoch: 19 [64000/248297 (26%)]\tLoss: 0.516676\nTrain Epoch: 19 [65000/248297 (26%)]\tLoss: 0.540006\nTrain Epoch: 19 [66000/248297 (27%)]\tLoss: 0.448335\nTrain Epoch: 19 [67000/248297 (27%)]\tLoss: 0.443758\nTrain Epoch: 19 [68000/248297 (27%)]\tLoss: 0.481572\nTrain Epoch: 19 [69000/248297 (28%)]\tLoss: 0.419950\nTrain Epoch: 19 [70000/248297 (28%)]\tLoss: 0.550506\nTrain Epoch: 19 [71000/248297 (29%)]\tLoss: 0.504985\nTrain Epoch: 19 [72000/248297 (29%)]\tLoss: 0.539974\nTrain Epoch: 19 [73000/248297 (29%)]\tLoss: 0.395002\nTrain Epoch: 19 [74000/248297 (30%)]\tLoss: 0.456855\nTrain Epoch: 19 [75000/248297 (30%)]\tLoss: 0.475602\nTrain Epoch: 19 [76000/248297 (31%)]\tLoss: 0.474149\nTrain Epoch: 19 [77000/248297 (31%)]\tLoss: 0.478480\nTrain Epoch: 19 [78000/248297 (31%)]\tLoss: 0.446481\nTrain Epoch: 19 [79000/248297 (32%)]\tLoss: 0.473062\nTrain Epoch: 19 [80000/248297 (32%)]\tLoss: 0.360061\nTrain Epoch: 19 [81000/248297 (33%)]\tLoss: 0.375692\nTrain Epoch: 19 [82000/248297 (33%)]\tLoss: 0.545718\nTrain Epoch: 19 [83000/248297 (33%)]\tLoss: 0.508025\nTrain Epoch: 19 [84000/248297 (34%)]\tLoss: 0.406497\nTrain Epoch: 19 [85000/248297 (34%)]\tLoss: 0.453965\nTrain Epoch: 19 [86000/248297 (35%)]\tLoss: 0.445962\nTrain Epoch: 19 [87000/248297 (35%)]\tLoss: 0.449145\nTrain Epoch: 19 [88000/248297 (35%)]\tLoss: 0.405971\nTrain Epoch: 19 [89000/248297 (36%)]\tLoss: 0.434490\nTrain Epoch: 19 [90000/248297 (36%)]\tLoss: 0.515374\nTrain Epoch: 19 [91000/248297 (37%)]\tLoss: 0.520556\nTrain Epoch: 19 [92000/248297 (37%)]\tLoss: 0.375515\nTrain Epoch: 19 [93000/248297 (37%)]\tLoss: 0.495889\nTrain Epoch: 19 [94000/248297 (38%)]\tLoss: 0.447245\nTrain Epoch: 19 [95000/248297 (38%)]\tLoss: 0.486531\nTrain Epoch: 19 [96000/248297 (39%)]\tLoss: 0.420872\nTrain Epoch: 19 [97000/248297 (39%)]\tLoss: 0.448387\nTrain Epoch: 19 [98000/248297 (39%)]\tLoss: 0.419342\nTrain Epoch: 19 [99000/248297 (40%)]\tLoss: 0.499033\nTrain Epoch: 19 [100000/248297 (40%)]\tLoss: 0.495079\nTrain Epoch: 19 [101000/248297 (41%)]\tLoss: 0.494744\nTrain Epoch: 19 [102000/248297 (41%)]\tLoss: 0.407611\nTrain Epoch: 19 [103000/248297 (41%)]\tLoss: 0.477816\nTrain Epoch: 19 [104000/248297 (42%)]\tLoss: 0.455367\nTrain Epoch: 19 [105000/248297 (42%)]\tLoss: 0.471192\nTrain Epoch: 19 [106000/248297 (43%)]\tLoss: 0.466512\nTrain Epoch: 19 [107000/248297 (43%)]\tLoss: 0.493733\nTrain Epoch: 19 [108000/248297 (44%)]\tLoss: 0.417675\nTrain Epoch: 19 [109000/248297 (44%)]\tLoss: 0.441940\nTrain Epoch: 19 [110000/248297 (44%)]\tLoss: 0.543404\nTrain Epoch: 19 [111000/248297 (45%)]\tLoss: 0.466864\nTrain Epoch: 19 [112000/248297 (45%)]\tLoss: 0.551481\nTrain Epoch: 19 [113000/248297 (46%)]\tLoss: 0.491444\nTrain Epoch: 19 [114000/248297 (46%)]\tLoss: 0.511858\nTrain Epoch: 19 [115000/248297 (46%)]\tLoss: 0.559811\nTrain Epoch: 19 [116000/248297 (47%)]\tLoss: 0.580390\nTrain Epoch: 19 [117000/248297 (47%)]\tLoss: 0.454484\nTrain Epoch: 19 [118000/248297 (48%)]\tLoss: 0.480303\nTrain Epoch: 19 [119000/248297 (48%)]\tLoss: 0.468041\nTrain Epoch: 19 [120000/248297 (48%)]\tLoss: 0.500973\nTrain Epoch: 19 [121000/248297 (49%)]\tLoss: 0.377914\nTrain Epoch: 19 [122000/248297 (49%)]\tLoss: 0.460111\nTrain Epoch: 19 [123000/248297 (50%)]\tLoss: 0.468415\nTrain Epoch: 19 [124000/248297 (50%)]\tLoss: 0.453658\nTrain Epoch: 19 [125000/248297 (50%)]\tLoss: 0.469992\nTrain Epoch: 19 [126000/248297 (51%)]\tLoss: 0.513205\nTrain Epoch: 19 [127000/248297 (51%)]\tLoss: 0.500675\nTrain Epoch: 19 [128000/248297 (52%)]\tLoss: 0.445704\nTrain Epoch: 19 [129000/248297 (52%)]\tLoss: 0.518840\nTrain Epoch: 19 [130000/248297 (52%)]\tLoss: 0.458188\nTrain Epoch: 19 [131000/248297 (53%)]\tLoss: 0.390980\nTrain Epoch: 19 [132000/248297 (53%)]\tLoss: 0.485030\nTrain Epoch: 19 [133000/248297 (54%)]\tLoss: 0.551197\nTrain Epoch: 19 [134000/248297 (54%)]\tLoss: 0.528584\nTrain Epoch: 19 [135000/248297 (54%)]\tLoss: 0.490355\nTrain Epoch: 19 [136000/248297 (55%)]\tLoss: 0.422072\nTrain Epoch: 19 [137000/248297 (55%)]\tLoss: 0.444531\nTrain Epoch: 19 [138000/248297 (56%)]\tLoss: 0.598441\nTrain Epoch: 19 [139000/248297 (56%)]\tLoss: 0.590455\nTrain Epoch: 19 [140000/248297 (56%)]\tLoss: 0.490947\nTrain Epoch: 19 [141000/248297 (57%)]\tLoss: 0.491819\nTrain Epoch: 19 [142000/248297 (57%)]\tLoss: 0.490218\nTrain Epoch: 19 [143000/248297 (58%)]\tLoss: 0.561002\nTrain Epoch: 19 [144000/248297 (58%)]\tLoss: 0.424189\nTrain Epoch: 19 [145000/248297 (58%)]\tLoss: 0.417544\nTrain Epoch: 19 [146000/248297 (59%)]\tLoss: 0.486281\nTrain Epoch: 19 [147000/248297 (59%)]\tLoss: 0.467604\nTrain Epoch: 19 [148000/248297 (60%)]\tLoss: 0.483855\nTrain Epoch: 19 [149000/248297 (60%)]\tLoss: 0.480879\nTrain Epoch: 19 [150000/248297 (60%)]\tLoss: 0.460850\nTrain Epoch: 19 [151000/248297 (61%)]\tLoss: 0.485227\nTrain Epoch: 19 [152000/248297 (61%)]\tLoss: 0.527926\nTrain Epoch: 19 [153000/248297 (62%)]\tLoss: 0.496714\nTrain Epoch: 19 [154000/248297 (62%)]\tLoss: 0.482097\nTrain Epoch: 19 [155000/248297 (62%)]\tLoss: 0.452951\nTrain Epoch: 19 [156000/248297 (63%)]\tLoss: 0.531709\nTrain Epoch: 19 [157000/248297 (63%)]\tLoss: 0.530977\nTrain Epoch: 19 [158000/248297 (64%)]\tLoss: 0.541719\nTrain Epoch: 19 [159000/248297 (64%)]\tLoss: 0.544510\nTrain Epoch: 19 [160000/248297 (64%)]\tLoss: 0.460152\nTrain Epoch: 19 [161000/248297 (65%)]\tLoss: 0.525438\nTrain Epoch: 19 [162000/248297 (65%)]\tLoss: 0.456518\nTrain Epoch: 19 [163000/248297 (66%)]\tLoss: 0.540207\nTrain Epoch: 19 [164000/248297 (66%)]\tLoss: 0.482494\nTrain Epoch: 19 [165000/248297 (66%)]\tLoss: 0.543366\nTrain Epoch: 19 [166000/248297 (67%)]\tLoss: 0.412539\nTrain Epoch: 19 [167000/248297 (67%)]\tLoss: 0.495419\nTrain Epoch: 19 [168000/248297 (68%)]\tLoss: 0.443780\nTrain Epoch: 19 [169000/248297 (68%)]\tLoss: 0.469330\nTrain Epoch: 19 [170000/248297 (68%)]\tLoss: 0.520205\nTrain Epoch: 19 [171000/248297 (69%)]\tLoss: 0.422936\nTrain Epoch: 19 [172000/248297 (69%)]\tLoss: 0.507071\nTrain Epoch: 19 [173000/248297 (70%)]\tLoss: 0.519093\nTrain Epoch: 19 [174000/248297 (70%)]\tLoss: 0.432156\nTrain Epoch: 19 [175000/248297 (71%)]\tLoss: 0.436425\nTrain Epoch: 19 [176000/248297 (71%)]\tLoss: 0.492376\nTrain Epoch: 19 [177000/248297 (71%)]\tLoss: 0.396212\nTrain Epoch: 19 [178000/248297 (72%)]\tLoss: 0.500694\nTrain Epoch: 19 [179000/248297 (72%)]\tLoss: 0.478111\nTrain Epoch: 19 [180000/248297 (73%)]\tLoss: 0.495074\nTrain Epoch: 19 [181000/248297 (73%)]\tLoss: 0.467326\nTrain Epoch: 19 [182000/248297 (73%)]\tLoss: 0.500110\nTrain Epoch: 19 [183000/248297 (74%)]\tLoss: 0.534136\nTrain Epoch: 19 [184000/248297 (74%)]\tLoss: 0.546028\nTrain Epoch: 19 [185000/248297 (75%)]\tLoss: 0.498912\nTrain Epoch: 19 [186000/248297 (75%)]\tLoss: 0.426773\nTrain Epoch: 19 [187000/248297 (75%)]\tLoss: 0.507961\nTrain Epoch: 19 [188000/248297 (76%)]\tLoss: 0.463251\nTrain Epoch: 19 [189000/248297 (76%)]\tLoss: 0.462211\nTrain Epoch: 19 [190000/248297 (77%)]\tLoss: 0.427885\nTrain Epoch: 19 [191000/248297 (77%)]\tLoss: 0.488922\nTrain Epoch: 19 [192000/248297 (77%)]\tLoss: 0.431047\nTrain Epoch: 19 [193000/248297 (78%)]\tLoss: 0.523064\nTrain Epoch: 19 [194000/248297 (78%)]\tLoss: 0.482348\nTrain Epoch: 19 [195000/248297 (79%)]\tLoss: 0.575970\nTrain Epoch: 19 [196000/248297 (79%)]\tLoss: 0.472597\nTrain Epoch: 19 [197000/248297 (79%)]\tLoss: 0.485666\nTrain Epoch: 19 [198000/248297 (80%)]\tLoss: 0.500983\nTrain Epoch: 19 [199000/248297 (80%)]\tLoss: 0.506333\nTrain Epoch: 19 [200000/248297 (81%)]\tLoss: 0.525453\nTrain Epoch: 19 [201000/248297 (81%)]\tLoss: 0.450099\nTrain Epoch: 19 [202000/248297 (81%)]\tLoss: 0.539688\nTrain Epoch: 19 [203000/248297 (82%)]\tLoss: 0.520303\nTrain Epoch: 19 [204000/248297 (82%)]\tLoss: 0.468138\nTrain Epoch: 19 [205000/248297 (83%)]\tLoss: 0.518511\nTrain Epoch: 19 [206000/248297 (83%)]\tLoss: 0.494889\nTrain Epoch: 19 [207000/248297 (83%)]\tLoss: 0.501919\nTrain Epoch: 19 [208000/248297 (84%)]\tLoss: 0.484109\nTrain Epoch: 19 [209000/248297 (84%)]\tLoss: 0.472940\nTrain Epoch: 19 [210000/248297 (85%)]\tLoss: 0.438741\nTrain Epoch: 19 [211000/248297 (85%)]\tLoss: 0.429947\nTrain Epoch: 19 [212000/248297 (85%)]\tLoss: 0.475875\nTrain Epoch: 19 [213000/248297 (86%)]\tLoss: 0.531887\nTrain Epoch: 19 [214000/248297 (86%)]\tLoss: 0.463740\nTrain Epoch: 19 [215000/248297 (87%)]\tLoss: 0.529301\nTrain Epoch: 19 [216000/248297 (87%)]\tLoss: 0.506173\nTrain Epoch: 19 [217000/248297 (87%)]\tLoss: 0.451924\nTrain Epoch: 19 [218000/248297 (88%)]\tLoss: 0.499138\nTrain Epoch: 19 [219000/248297 (88%)]\tLoss: 0.531391\nTrain Epoch: 19 [220000/248297 (89%)]\tLoss: 0.515992\nTrain Epoch: 19 [221000/248297 (89%)]\tLoss: 0.566498\nTrain Epoch: 19 [222000/248297 (89%)]\tLoss: 0.534443\nTrain Epoch: 19 [223000/248297 (90%)]\tLoss: 0.494109\nTrain Epoch: 19 [224000/248297 (90%)]\tLoss: 0.486838\nTrain Epoch: 19 [225000/248297 (91%)]\tLoss: 0.530920\nTrain Epoch: 19 [226000/248297 (91%)]\tLoss: 0.433602\nTrain Epoch: 19 [227000/248297 (91%)]\tLoss: 0.486507\nTrain Epoch: 19 [228000/248297 (92%)]\tLoss: 0.542866\nTrain Epoch: 19 [229000/248297 (92%)]\tLoss: 0.505674\nTrain Epoch: 19 [230000/248297 (93%)]\tLoss: 0.470584\nTrain Epoch: 19 [231000/248297 (93%)]\tLoss: 0.501396\nTrain Epoch: 19 [232000/248297 (93%)]\tLoss: 0.552238\nTrain Epoch: 19 [233000/248297 (94%)]\tLoss: 0.455974\nTrain Epoch: 19 [234000/248297 (94%)]\tLoss: 0.481994\nTrain Epoch: 19 [235000/248297 (95%)]\tLoss: 0.513900\nTrain Epoch: 19 [236000/248297 (95%)]\tLoss: 0.479406\nTrain Epoch: 19 [237000/248297 (95%)]\tLoss: 0.453902\nTrain Epoch: 19 [238000/248297 (96%)]\tLoss: 0.400902\nTrain Epoch: 19 [239000/248297 (96%)]\tLoss: 0.458846\nTrain Epoch: 19 [240000/248297 (97%)]\tLoss: 0.419698\nTrain Epoch: 19 [241000/248297 (97%)]\tLoss: 0.405844\nTrain Epoch: 19 [242000/248297 (98%)]\tLoss: 0.613897\nTrain Epoch: 19 [243000/248297 (98%)]\tLoss: 0.496276\nTrain Epoch: 19 [244000/248297 (98%)]\tLoss: 0.518159\nTrain Epoch: 19 [245000/248297 (99%)]\tLoss: 0.423010\nTrain Epoch: 19 [246000/248297 (99%)]\tLoss: 0.519119\nTrain Epoch: 19 [247000/248297 (100%)]\tLoss: 0.439292\nTrain Epoch: 19 [248000/248297 (100%)]\tLoss: 0.497321\n\nTest set: Average loss: 0.0050, Accuracy: 20740/27589 (75%)\n\nTrain Epoch: 20 [0/248297 (0%)]\tLoss: 0.487562\nTrain Epoch: 20 [1000/248297 (0%)]\tLoss: 0.428452\nTrain Epoch: 20 [2000/248297 (1%)]\tLoss: 0.478114\nTrain Epoch: 20 [3000/248297 (1%)]\tLoss: 0.419569\nTrain Epoch: 20 [4000/248297 (2%)]\tLoss: 0.536769\nTrain Epoch: 20 [5000/248297 (2%)]\tLoss: 0.416459\nTrain Epoch: 20 [6000/248297 (2%)]\tLoss: 0.482310\nTrain Epoch: 20 [7000/248297 (3%)]\tLoss: 0.498803\nTrain Epoch: 20 [8000/248297 (3%)]\tLoss: 0.554584\nTrain Epoch: 20 [9000/248297 (4%)]\tLoss: 0.532427\nTrain Epoch: 20 [10000/248297 (4%)]\tLoss: 0.392676\nTrain Epoch: 20 [11000/248297 (4%)]\tLoss: 0.531878\nTrain Epoch: 20 [12000/248297 (5%)]\tLoss: 0.481040\nTrain Epoch: 20 [13000/248297 (5%)]\tLoss: 0.524935\nTrain Epoch: 20 [14000/248297 (6%)]\tLoss: 0.446193\nTrain Epoch: 20 [15000/248297 (6%)]\tLoss: 0.441683\nTrain Epoch: 20 [16000/248297 (6%)]\tLoss: 0.416878\nTrain Epoch: 20 [17000/248297 (7%)]\tLoss: 0.524134\nTrain Epoch: 20 [18000/248297 (7%)]\tLoss: 0.413673\nTrain Epoch: 20 [19000/248297 (8%)]\tLoss: 0.480209\nTrain Epoch: 20 [20000/248297 (8%)]\tLoss: 0.451459\nTrain Epoch: 20 [21000/248297 (8%)]\tLoss: 0.405373\nTrain Epoch: 20 [22000/248297 (9%)]\tLoss: 0.406750\nTrain Epoch: 20 [23000/248297 (9%)]\tLoss: 0.398507\nTrain Epoch: 20 [24000/248297 (10%)]\tLoss: 0.598333\nTrain Epoch: 20 [25000/248297 (10%)]\tLoss: 0.471085\nTrain Epoch: 20 [26000/248297 (10%)]\tLoss: 0.429497\nTrain Epoch: 20 [27000/248297 (11%)]\tLoss: 0.451163\nTrain Epoch: 20 [28000/248297 (11%)]\tLoss: 0.491246\nTrain Epoch: 20 [29000/248297 (12%)]\tLoss: 0.489736\nTrain Epoch: 20 [30000/248297 (12%)]\tLoss: 0.494364\nTrain Epoch: 20 [31000/248297 (12%)]\tLoss: 0.408722\nTrain Epoch: 20 [32000/248297 (13%)]\tLoss: 0.455490\nTrain Epoch: 20 [33000/248297 (13%)]\tLoss: 0.401970\nTrain Epoch: 20 [34000/248297 (14%)]\tLoss: 0.400797\nTrain Epoch: 20 [35000/248297 (14%)]\tLoss: 0.504952\nTrain Epoch: 20 [36000/248297 (15%)]\tLoss: 0.485995\nTrain Epoch: 20 [37000/248297 (15%)]\tLoss: 0.496842\nTrain Epoch: 20 [38000/248297 (15%)]\tLoss: 0.539171\nTrain Epoch: 20 [39000/248297 (16%)]\tLoss: 0.455458\nTrain Epoch: 20 [40000/248297 (16%)]\tLoss: 0.435280\nTrain Epoch: 20 [41000/248297 (17%)]\tLoss: 0.536544\nTrain Epoch: 20 [42000/248297 (17%)]\tLoss: 0.479705\nTrain Epoch: 20 [43000/248297 (17%)]\tLoss: 0.550909\nTrain Epoch: 20 [44000/248297 (18%)]\tLoss: 0.448992\nTrain Epoch: 20 [45000/248297 (18%)]\tLoss: 0.422549\nTrain Epoch: 20 [46000/248297 (19%)]\tLoss: 0.431197\nTrain Epoch: 20 [47000/248297 (19%)]\tLoss: 0.446960\nTrain Epoch: 20 [48000/248297 (19%)]\tLoss: 0.539790\nTrain Epoch: 20 [49000/248297 (20%)]\tLoss: 0.445710\nTrain Epoch: 20 [50000/248297 (20%)]\tLoss: 0.491553\nTrain Epoch: 20 [51000/248297 (21%)]\tLoss: 0.572099\nTrain Epoch: 20 [52000/248297 (21%)]\tLoss: 0.492847\nTrain Epoch: 20 [53000/248297 (21%)]\tLoss: 0.468189\nTrain Epoch: 20 [54000/248297 (22%)]\tLoss: 0.572424\nTrain Epoch: 20 [55000/248297 (22%)]\tLoss: 0.490296\nTrain Epoch: 20 [56000/248297 (23%)]\tLoss: 0.515553\nTrain Epoch: 20 [57000/248297 (23%)]\tLoss: 0.515943\nTrain Epoch: 20 [58000/248297 (23%)]\tLoss: 0.591501\nTrain Epoch: 20 [59000/248297 (24%)]\tLoss: 0.485390\nTrain Epoch: 20 [60000/248297 (24%)]\tLoss: 0.516963\nTrain Epoch: 20 [61000/248297 (25%)]\tLoss: 0.526656\nTrain Epoch: 20 [62000/248297 (25%)]\tLoss: 0.415123\nTrain Epoch: 20 [63000/248297 (25%)]\tLoss: 0.463495\nTrain Epoch: 20 [64000/248297 (26%)]\tLoss: 0.417971\nTrain Epoch: 20 [65000/248297 (26%)]\tLoss: 0.585262\nTrain Epoch: 20 [66000/248297 (27%)]\tLoss: 0.540138\nTrain Epoch: 20 [67000/248297 (27%)]\tLoss: 0.466763\nTrain Epoch: 20 [68000/248297 (27%)]\tLoss: 0.396421\nTrain Epoch: 20 [69000/248297 (28%)]\tLoss: 0.459394\nTrain Epoch: 20 [70000/248297 (28%)]\tLoss: 0.492834\nTrain Epoch: 20 [71000/248297 (29%)]\tLoss: 0.440429\nTrain Epoch: 20 [72000/248297 (29%)]\tLoss: 0.424457\nTrain Epoch: 20 [73000/248297 (29%)]\tLoss: 0.471566\nTrain Epoch: 20 [74000/248297 (30%)]\tLoss: 0.447340\nTrain Epoch: 20 [75000/248297 (30%)]\tLoss: 0.483864\nTrain Epoch: 20 [76000/248297 (31%)]\tLoss: 0.515939\nTrain Epoch: 20 [77000/248297 (31%)]\tLoss: 0.485830\nTrain Epoch: 20 [78000/248297 (31%)]\tLoss: 0.560811\nTrain Epoch: 20 [79000/248297 (32%)]\tLoss: 0.583334\nTrain Epoch: 20 [80000/248297 (32%)]\tLoss: 0.481037\nTrain Epoch: 20 [81000/248297 (33%)]\tLoss: 0.486744\nTrain Epoch: 20 [82000/248297 (33%)]\tLoss: 0.455084\nTrain Epoch: 20 [83000/248297 (33%)]\tLoss: 0.387120\nTrain Epoch: 20 [84000/248297 (34%)]\tLoss: 0.460004\nTrain Epoch: 20 [85000/248297 (34%)]\tLoss: 0.490443\nTrain Epoch: 20 [86000/248297 (35%)]\tLoss: 0.504616\nTrain Epoch: 20 [87000/248297 (35%)]\tLoss: 0.550793\nTrain Epoch: 20 [88000/248297 (35%)]\tLoss: 0.401286\nTrain Epoch: 20 [89000/248297 (36%)]\tLoss: 0.406775\nTrain Epoch: 20 [90000/248297 (36%)]\tLoss: 0.564784\nTrain Epoch: 20 [91000/248297 (37%)]\tLoss: 0.564531\nTrain Epoch: 20 [92000/248297 (37%)]\tLoss: 0.434682\nTrain Epoch: 20 [93000/248297 (37%)]\tLoss: 0.478162\nTrain Epoch: 20 [94000/248297 (38%)]\tLoss: 0.468353\nTrain Epoch: 20 [95000/248297 (38%)]\tLoss: 0.475772\nTrain Epoch: 20 [96000/248297 (39%)]\tLoss: 0.536661\nTrain Epoch: 20 [97000/248297 (39%)]\tLoss: 0.519385\nTrain Epoch: 20 [98000/248297 (39%)]\tLoss: 0.473886\nTrain Epoch: 20 [99000/248297 (40%)]\tLoss: 0.531804\nTrain Epoch: 20 [100000/248297 (40%)]\tLoss: 0.443618\nTrain Epoch: 20 [101000/248297 (41%)]\tLoss: 0.499771\nTrain Epoch: 20 [102000/248297 (41%)]\tLoss: 0.449636\nTrain Epoch: 20 [103000/248297 (41%)]\tLoss: 0.555556\nTrain Epoch: 20 [104000/248297 (42%)]\tLoss: 0.543736\nTrain Epoch: 20 [105000/248297 (42%)]\tLoss: 0.412723\nTrain Epoch: 20 [106000/248297 (43%)]\tLoss: 0.543879\nTrain Epoch: 20 [107000/248297 (43%)]\tLoss: 0.529152\nTrain Epoch: 20 [108000/248297 (44%)]\tLoss: 0.503407\nTrain Epoch: 20 [109000/248297 (44%)]\tLoss: 0.570316\nTrain Epoch: 20 [110000/248297 (44%)]\tLoss: 0.423994\nTrain Epoch: 20 [111000/248297 (45%)]\tLoss: 0.490123\nTrain Epoch: 20 [112000/248297 (45%)]\tLoss: 0.477842\nTrain Epoch: 20 [113000/248297 (46%)]\tLoss: 0.519946\nTrain Epoch: 20 [114000/248297 (46%)]\tLoss: 0.512122\nTrain Epoch: 20 [115000/248297 (46%)]\tLoss: 0.493382\nTrain Epoch: 20 [116000/248297 (47%)]\tLoss: 0.610132\nTrain Epoch: 20 [117000/248297 (47%)]\tLoss: 0.462782\nTrain Epoch: 20 [118000/248297 (48%)]\tLoss: 0.454385\nTrain Epoch: 20 [119000/248297 (48%)]\tLoss: 0.458034\nTrain Epoch: 20 [120000/248297 (48%)]\tLoss: 0.496354\nTrain Epoch: 20 [121000/248297 (49%)]\tLoss: 0.419440\nTrain Epoch: 20 [122000/248297 (49%)]\tLoss: 0.552453\nTrain Epoch: 20 [123000/248297 (50%)]\tLoss: 0.441323\nTrain Epoch: 20 [124000/248297 (50%)]\tLoss: 0.508982\nTrain Epoch: 20 [125000/248297 (50%)]\tLoss: 0.506898\nTrain Epoch: 20 [126000/248297 (51%)]\tLoss: 0.612439\nTrain Epoch: 20 [127000/248297 (51%)]\tLoss: 0.551136\nTrain Epoch: 20 [128000/248297 (52%)]\tLoss: 0.405242\nTrain Epoch: 20 [129000/248297 (52%)]\tLoss: 0.505287\nTrain Epoch: 20 [130000/248297 (52%)]\tLoss: 0.527914\nTrain Epoch: 20 [131000/248297 (53%)]\tLoss: 0.469458\nTrain Epoch: 20 [132000/248297 (53%)]\tLoss: 0.473024\nTrain Epoch: 20 [133000/248297 (54%)]\tLoss: 0.460987\nTrain Epoch: 20 [134000/248297 (54%)]\tLoss: 0.463292\nTrain Epoch: 20 [135000/248297 (54%)]\tLoss: 0.528966\nTrain Epoch: 20 [136000/248297 (55%)]\tLoss: 0.519883\nTrain Epoch: 20 [137000/248297 (55%)]\tLoss: 0.471121\nTrain Epoch: 20 [138000/248297 (56%)]\tLoss: 0.509062\nTrain Epoch: 20 [139000/248297 (56%)]\tLoss: 0.463315\nTrain Epoch: 20 [140000/248297 (56%)]\tLoss: 0.503974\nTrain Epoch: 20 [141000/248297 (57%)]\tLoss: 0.470436\nTrain Epoch: 20 [142000/248297 (57%)]\tLoss: 0.451444\nTrain Epoch: 20 [143000/248297 (58%)]\tLoss: 0.530159\nTrain Epoch: 20 [144000/248297 (58%)]\tLoss: 0.460616\nTrain Epoch: 20 [145000/248297 (58%)]\tLoss: 0.510562\nTrain Epoch: 20 [146000/248297 (59%)]\tLoss: 0.502521\nTrain Epoch: 20 [147000/248297 (59%)]\tLoss: 0.483516\nTrain Epoch: 20 [148000/248297 (60%)]\tLoss: 0.542049\nTrain Epoch: 20 [149000/248297 (60%)]\tLoss: 0.447071\nTrain Epoch: 20 [150000/248297 (60%)]\tLoss: 0.566576\nTrain Epoch: 20 [151000/248297 (61%)]\tLoss: 0.533852\nTrain Epoch: 20 [152000/248297 (61%)]\tLoss: 0.550116\nTrain Epoch: 20 [153000/248297 (62%)]\tLoss: 0.506842\nTrain Epoch: 20 [154000/248297 (62%)]\tLoss: 0.541079\nTrain Epoch: 20 [155000/248297 (62%)]\tLoss: 0.532938\nTrain Epoch: 20 [156000/248297 (63%)]\tLoss: 0.465885\nTrain Epoch: 20 [157000/248297 (63%)]\tLoss: 0.406773\nTrain Epoch: 20 [158000/248297 (64%)]\tLoss: 0.519172\nTrain Epoch: 20 [159000/248297 (64%)]\tLoss: 0.549121\nTrain Epoch: 20 [160000/248297 (64%)]\tLoss: 0.470248\nTrain Epoch: 20 [161000/248297 (65%)]\tLoss: 0.415883\nTrain Epoch: 20 [162000/248297 (65%)]\tLoss: 0.471762\nTrain Epoch: 20 [163000/248297 (66%)]\tLoss: 0.426067\nTrain Epoch: 20 [164000/248297 (66%)]\tLoss: 0.416642\nTrain Epoch: 20 [165000/248297 (66%)]\tLoss: 0.490317\nTrain Epoch: 20 [166000/248297 (67%)]\tLoss: 0.491231\nTrain Epoch: 20 [167000/248297 (67%)]\tLoss: 0.465192\nTrain Epoch: 20 [168000/248297 (68%)]\tLoss: 0.464728\nTrain Epoch: 20 [169000/248297 (68%)]\tLoss: 0.580771\nTrain Epoch: 20 [170000/248297 (68%)]\tLoss: 0.470301\nTrain Epoch: 20 [171000/248297 (69%)]\tLoss: 0.497070\nTrain Epoch: 20 [172000/248297 (69%)]\tLoss: 0.504925\nTrain Epoch: 20 [173000/248297 (70%)]\tLoss: 0.445825\nTrain Epoch: 20 [174000/248297 (70%)]\tLoss: 0.382353\nTrain Epoch: 20 [175000/248297 (71%)]\tLoss: 0.548741\nTrain Epoch: 20 [176000/248297 (71%)]\tLoss: 0.447809\nTrain Epoch: 20 [177000/248297 (71%)]\tLoss: 0.455941\nTrain Epoch: 20 [178000/248297 (72%)]\tLoss: 0.559345\nTrain Epoch: 20 [179000/248297 (72%)]\tLoss: 0.488691\nTrain Epoch: 20 [180000/248297 (73%)]\tLoss: 0.462660\nTrain Epoch: 20 [181000/248297 (73%)]\tLoss: 0.449574\nTrain Epoch: 20 [182000/248297 (73%)]\tLoss: 0.455601\nTrain Epoch: 20 [183000/248297 (74%)]\tLoss: 0.559014\nTrain Epoch: 20 [184000/248297 (74%)]\tLoss: 0.497067\nTrain Epoch: 20 [185000/248297 (75%)]\tLoss: 0.563292\nTrain Epoch: 20 [186000/248297 (75%)]\tLoss: 0.476322\nTrain Epoch: 20 [187000/248297 (75%)]\tLoss: 0.447401\nTrain Epoch: 20 [188000/248297 (76%)]\tLoss: 0.440053\nTrain Epoch: 20 [189000/248297 (76%)]\tLoss: 0.481370\nTrain Epoch: 20 [190000/248297 (77%)]\tLoss: 0.509475\nTrain Epoch: 20 [191000/248297 (77%)]\tLoss: 0.536940\nTrain Epoch: 20 [192000/248297 (77%)]\tLoss: 0.485249\nTrain Epoch: 20 [193000/248297 (78%)]\tLoss: 0.459043\nTrain Epoch: 20 [194000/248297 (78%)]\tLoss: 0.435042\nTrain Epoch: 20 [195000/248297 (79%)]\tLoss: 0.556288\nTrain Epoch: 20 [196000/248297 (79%)]\tLoss: 0.452139\nTrain Epoch: 20 [197000/248297 (79%)]\tLoss: 0.477528\nTrain Epoch: 20 [198000/248297 (80%)]\tLoss: 0.410566\nTrain Epoch: 20 [199000/248297 (80%)]\tLoss: 0.527551\nTrain Epoch: 20 [200000/248297 (81%)]\tLoss: 0.489244\nTrain Epoch: 20 [201000/248297 (81%)]\tLoss: 0.419642\nTrain Epoch: 20 [202000/248297 (81%)]\tLoss: 0.533175\nTrain Epoch: 20 [203000/248297 (82%)]\tLoss: 0.472687\nTrain Epoch: 20 [204000/248297 (82%)]\tLoss: 0.519499\nTrain Epoch: 20 [205000/248297 (83%)]\tLoss: 0.450832\nTrain Epoch: 20 [206000/248297 (83%)]\tLoss: 0.488321\nTrain Epoch: 20 [207000/248297 (83%)]\tLoss: 0.484352\nTrain Epoch: 20 [208000/248297 (84%)]\tLoss: 0.448171\nTrain Epoch: 20 [209000/248297 (84%)]\tLoss: 0.492694\nTrain Epoch: 20 [210000/248297 (85%)]\tLoss: 0.468466\nTrain Epoch: 20 [211000/248297 (85%)]\tLoss: 0.402576\nTrain Epoch: 20 [212000/248297 (85%)]\tLoss: 0.540631\nTrain Epoch: 20 [213000/248297 (86%)]\tLoss: 0.396803\nTrain Epoch: 20 [214000/248297 (86%)]\tLoss: 0.504268\nTrain Epoch: 20 [215000/248297 (87%)]\tLoss: 0.413846\nTrain Epoch: 20 [216000/248297 (87%)]\tLoss: 0.538622\nTrain Epoch: 20 [217000/248297 (87%)]\tLoss: 0.442510\nTrain Epoch: 20 [218000/248297 (88%)]\tLoss: 0.536833\nTrain Epoch: 20 [219000/248297 (88%)]\tLoss: 0.487450\nTrain Epoch: 20 [220000/248297 (89%)]\tLoss: 0.528954\nTrain Epoch: 20 [221000/248297 (89%)]\tLoss: 0.566311\nTrain Epoch: 20 [222000/248297 (89%)]\tLoss: 0.555821\nTrain Epoch: 20 [223000/248297 (90%)]\tLoss: 0.496664\nTrain Epoch: 20 [224000/248297 (90%)]\tLoss: 0.435174\nTrain Epoch: 20 [225000/248297 (91%)]\tLoss: 0.477897\nTrain Epoch: 20 [226000/248297 (91%)]\tLoss: 0.444549\nTrain Epoch: 20 [227000/248297 (91%)]\tLoss: 0.585420\nTrain Epoch: 20 [228000/248297 (92%)]\tLoss: 0.485139\nTrain Epoch: 20 [229000/248297 (92%)]\tLoss: 0.524378\nTrain Epoch: 20 [230000/248297 (93%)]\tLoss: 0.445762\nTrain Epoch: 20 [231000/248297 (93%)]\tLoss: 0.595697\nTrain Epoch: 20 [232000/248297 (93%)]\tLoss: 0.488606\nTrain Epoch: 20 [233000/248297 (94%)]\tLoss: 0.487316\nTrain Epoch: 20 [234000/248297 (94%)]\tLoss: 0.463095\nTrain Epoch: 20 [235000/248297 (95%)]\tLoss: 0.536629\nTrain Epoch: 20 [236000/248297 (95%)]\tLoss: 0.450709\nTrain Epoch: 20 [237000/248297 (95%)]\tLoss: 0.520781\nTrain Epoch: 20 [238000/248297 (96%)]\tLoss: 0.527833\nTrain Epoch: 20 [239000/248297 (96%)]\tLoss: 0.467658\nTrain Epoch: 20 [240000/248297 (97%)]\tLoss: 0.497334\nTrain Epoch: 20 [241000/248297 (97%)]\tLoss: 0.544085\nTrain Epoch: 20 [242000/248297 (98%)]\tLoss: 0.451772\nTrain Epoch: 20 [243000/248297 (98%)]\tLoss: 0.446783\nTrain Epoch: 20 [244000/248297 (98%)]\tLoss: 0.549752\nTrain Epoch: 20 [245000/248297 (99%)]\tLoss: 0.382045\nTrain Epoch: 20 [246000/248297 (99%)]\tLoss: 0.433752\nTrain Epoch: 20 [247000/248297 (100%)]\tLoss: 0.550222\nTrain Epoch: 20 [248000/248297 (100%)]\tLoss: 0.465479\n\nTest set: Average loss: 0.0050, Accuracy: 20741/27589 (75%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Metric","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import precision_recall_curve, auc\n\n\ndef pr_auc_macro(\n    target_df: pd.DataFrame,\n    predictions_df: pd.DataFrame,\n    prec_level: float = 0.75,\n    cat_column: str = \"cat3_grouped\"\n) -> float:\n\n    df = target_df.merge(predictions_df, on=[\"variantid1\", \"variantid2\"])\n\n    y_true = df[\"target\"]\n    y_pred = df[\"scores\"]\n    categories = df[cat_column]\n\n    weights = []\n    pr_aucs = []\n\n    unique_cats, counts = np.unique(categories, return_counts=True)\n\n    # calculate metric for each big category\n    for i, category in enumerate(unique_cats):\n        # take just a certain category\n        cat_idx = np.where(categories == category)[0]\n        y_pred_cat = y_pred[cat_idx]\n        y_true_cat = y_true[cat_idx]\n\n        # if there is no matches in the category then PRAUC=0\n        if sum(y_true_cat) == 0:\n            pr_aucs.append(0)\n            weights.append(counts[i] / len(categories))\n            continue\n        \n        # get coordinates (x, y) for (recall, precision) of PR-curve\n        y, x, _ = precision_recall_curve(y_true_cat, y_pred_cat)\n        \n        # reverse the lists so that x's are in ascending order (left to right)\n        y = y[::-1]\n        x = x[::-1]\n        \n        # get indices for x-coordinate (recall) where y-coordinate (precision) \n        # is higher than precision level (75% for our task)\n        good_idx = np.where(y >= prec_level)[0]\n        \n        # if there are more than one such x's (at least one is always there, \n        # it's x=0 (recall=0)) we get a grid from x=0, to the rightest x \n        # with acceptable precision\n        if len(good_idx) > 1:\n            gt_prec_level_idx = np.arange(0, good_idx[-1] + 1)\n        # if there is only one such x, then we have zeros in the top scores \n        # and the curve simply goes down sharply at x=0 and does not rise \n        # above the required precision: PRAUC=0\n        else:\n            pr_aucs.append(0)\n            weights.append(counts[i] / len(categories))\n            continue\n        \n        # calculate category weight anyway\n        weights.append(counts[i] / len(categories))\n        # calculate PRAUC for all points where the rightest x \n        # still has required precision \n        try:\n            pr_auc_prec_level = auc(x[gt_prec_level_idx], y[gt_prec_level_idx])\n            if not np.isnan(pr_auc_prec_level):\n                pr_aucs.append(pr_auc_prec_level)\n        except ValueError:\n            pr_aucs.append(0)\n            \n    return np.average(pr_aucs, weights=weights)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:00:33.529483Z","iopub.execute_input":"2023-05-30T20:00:33.529762Z","iopub.status.idle":"2023-05-30T20:00:33.541827Z","shell.execute_reply.started":"2023-05-30T20:00:33.529737Z","shell.execute_reply":"2023-05-30T20:00:33.540875Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"boosting_scores = X_test[\"scores\"] = model.predict_proba(X_test[feats])[:, 1]","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:30:13.294341Z","start_time":"2023-05-19T06:30:13.258507Z"},"execution":{"iopub.status.busy":"2023-05-30T20:00:33.546468Z","iopub.execute_input":"2023-05-30T20:00:33.548022Z","iopub.status.idle":"2023-05-30T20:00:33.597932Z","shell.execute_reply.started":"2023-05-30T20:00:33.547995Z","shell.execute_reply":"2023-05-30T20:00:33.597050Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"pr_auc_macro_metr = pr_auc_macro(\n    target_df=y_test, \n    predictions_df=X_test,\n    prec_level=0.75,\n    cat_column=\"cat3_grouped\"\n)\n\npr_auc_macro_metr","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:00:33.599388Z","iopub.execute_input":"2023-05-30T20:00:33.599720Z","iopub.status.idle":"2023-05-30T20:00:33.914141Z","shell.execute_reply.started":"2023-05-30T20:00:33.599689Z","shell.execute_reply":"2023-05-30T20:00:33.913192Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"0.41505724089206586"},"metadata":{}}]},{"cell_type":"code","source":"precision, recall, thrs = precision_recall_curve(y_test[\"target\"], X_test[\"scores\"])\npr_auc = auc(recall, precision)\n\nfig, ax1 = plt.subplots(1, figsize=(15, 7))\n\nax1.plot(recall, precision)\nax1.axhline(y=0.75, color='grey', linestyle='-');","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:00:33.915434Z","iopub.execute_input":"2023-05-30T20:00:33.915770Z","iopub.status.idle":"2023-05-30T20:00:34.256125Z","shell.execute_reply.started":"2023-05-30T20:00:33.915735Z","shell.execute_reply":"2023-05-30T20:00:34.255200Z"},"trusted":true},"execution_count":79,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x700 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boosting_scores2 = X_test[\"scores\"] = model2.predict_proba(X_test[feats])[:, 1]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:08:30.684649Z","iopub.execute_input":"2023-05-30T20:08:30.685001Z","iopub.status.idle":"2023-05-30T20:08:30.732883Z","shell.execute_reply.started":"2023-05-30T20:08:30.684967Z","shell.execute_reply":"2023-05-30T20:08:30.731983Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"pr_auc_macro_metr = pr_auc_macro(\n    target_df=y_test, \n    predictions_df=X_test,\n    prec_level=0.75,\n    cat_column=\"cat3_grouped\"\n)\n\npr_auc_macro_metr","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:08:30.734970Z","iopub.execute_input":"2023-05-30T20:08:30.735309Z","iopub.status.idle":"2023-05-30T20:08:31.059045Z","shell.execute_reply.started":"2023-05-30T20:08:30.735258Z","shell.execute_reply":"2023-05-30T20:08:31.058141Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"0.41505724089206586"},"metadata":{}}]},{"cell_type":"code","source":"precision, recall, thrs = precision_recall_curve(y_test[\"target\"], X_test[\"scores\"])\npr_auc = auc(recall, precision)\n\nfig, ax1 = plt.subplots(1, figsize=(15, 7))\n\nax1.plot(recall, precision)\nax1.axhline(y=0.75, color='grey', linestyle='-');","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:08:31.060381Z","iopub.execute_input":"2023-05-30T20:08:31.060808Z","iopub.status.idle":"2023-05-30T20:08:31.334160Z","shell.execute_reply.started":"2023-05-30T20:08:31.060773Z","shell.execute_reply":"2023-05-30T20:08:31.333207Z"},"trusted":true},"execution_count":104,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x700 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABL4AAAJGCAYAAABV80xCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABeu0lEQVR4nO3dd3hUVeL/8c9MOpCEkpAECIQivSPE0BSN0kTddXdRVBRFvypWdDV0sQA/K+6CuiK2dVUsiK5BigFEBEF674TQEggllbSZ+/vD3XHHJMBAMnfK+/U8eXbuOecmnzy7o8uHc89YDMMwBAAAAAAAAPgYq9kBAAAAAAAAgOpA8QUAAAAAAACfRPEFAAAAAAAAn0TxBQAAAAAAAJ9E8QUAAAAAAACfRPEFAAAAAAAAn0TxBQAAAAAAAJ8UaHaAC2G323X06FGFh4fLYrGYHQcAAAAAAAAmMQxDeXl5atCggazWc+/p8ori6+jRo4qPjzc7BgAAAAAAADzEoUOH1KhRo3Ou8YriKzw8XNKvv1BERITJaQAAAAAAAGCW3NxcxcfHO/qic/GK4uu/jzdGRERQfAEAAAAAAOCCjsPicHsAAAAAAAD4JIovAAAAAAAA+CSKLwAAAAAAAPgkii8AAAAAAAD4JIovAAAAAAAA+CSKLwAAAAAAAPgkii8AAAAAAAD4JIovAAAAAAAA+CSKLwAAAAAAAPgkii8AAAAAAAD4JIovAAAAAAAA+CSKLwAAAAAAAPgkii8AAAAAAAD4JIovAAAAAAAA+CSKLwAAAAAAAPgkii8AAAAAAAD4JIovAAAAAAAA+CSKLwAAAAAAAPgkl4uv5cuXa8iQIWrQoIEsFovmzZt33nuWLVumrl27KiQkRC1atND7779/EVEBAAAAAACAC+dy8VVQUKBOnTpp5syZF7T+wIEDGjx4sPr166eNGzfqscce08iRI7Vw4UKXwwIAAAAAAAAXKtDVGwYOHKiBAwde8Pq33npLTZs21SuvvCJJatOmjVasWKHXXntN/fv3d/XH+4RDpwp18GTheddFh4eoVWy4GxIBAAAAAAD4HpeLL1etWrVKycnJTmP9+/fXY489Vuk9xcXFKi4udlzn5uZWVzxTfL3xiF5etPuC1s59sKe6Nq5TzYkAAAAAAAB8T7UXX5mZmYqJiXEai4mJUW5urs6ePauwsLBy90ydOlWTJ0+u7mimqVcrRK3Ps5MrO79Y2fkl+nrDEYovAAAAAACAi1DtxdfFGDNmjEaPHu24zs3NVXx8vImJqtatPRrr1h6Nz7lmyc4s3f3+Wi3clqVJQ9rJarWc9/sWl9l0qqBEsRGhsljOvx4AAAAAAMCXVXvxFRsbq6ysLKexrKwsRUREVLjbS5JCQkIUEhJS3dE8Wq8WUaoVEqjM3CJtOnxGXSrY9XUyv1gr953Uyn3ZWr3/lNJPFshuSF0a19brQ7uocb0aJiQHAAAAAADwDNVefCUlJWn+/PlOY4sXL1ZSUlJ1/2ivFhIYoKtb19c3m45qwbZMdWlcR/nFZVpz4KR+2ntSP+3N1s7MvArv3ZBxRoP+9qOevbGd/tClIbu/AAAAAACAX3K5+MrPz9fevXsd1wcOHNDGjRtVt25dNW7cWGPGjNGRI0f04YcfSpLuv/9+zZgxQ0899ZTuvvtuLVmyRJ999plSU1Or7rfwUQPax+qbTUf17aZjOpFbrG82HVWZ3XBa0zo2XL1aRKlXi3pq3yBSJTa7Hp+zUb+kn9bozzZp9GebNH5wG43s08yk3wIAAAAAAMAcFsMwjPMv+82yZcvUr1+/cuN33nmn3n//fd11111KT0/XsmXLnO55/PHHtX37djVq1EgTJkzQXXfddcE/Mzc3V5GRkcrJyVFERIQrcb1aQXGZuj63WMVldsdY47o11KtFPfVsHqWk5vUUVav8I6E2u6E3lu7VK4t//eTIuMhQLX3yKpXY7IoIDXJbfgAAAAAAgKrmSk/kcvFlBn8tviRpzNwt+mRNhq5tG6OH+rVQp/jaF3xvZk6RrpiaJkkKCrAowGrRnPuSXPoeAAAAAAAAnoTiy4eU2ew6W2pT+EXu1Hris036cv1hx3WDyFAt+2s/BQdaqyoiAAAAAACA27jSE1X74fa4NIEBVoUHXHxJNXFIW/VrHa24yDDd9e4aHc0p0uwVB/TAVc1VVGrTqv0nlbYjS9l5JUoZ2FoJUTWrMD0AAAAAAIB5KL58XGRYkK7v2ECS1DI2XOsOntbrabu18dBp/bgnW4UlNsfaH3af0N29E/TINZcpJDDArMgAAAAAAABVgufd/EjvFlGSpKJSuxZuy1JhiU0xESEalthYXRvX1tlSm2Yu3acFWzNNTgoAAAAAAHDp2PHlR9o1iJDFIrWIrqVBHeKU3CZG7RtGyGKxqKTMrpbjv5P0686vGzs3VGZOkRZtz9SOY3l66OoWalg7TGcKS7R8T7Zyz5bq1h6NFWC1mPxbAQAAAAAAVIziy49c1y5W2ycPUGiQVRaLc2EVHGhVg8hQHc0p0tz1R7TvRIE2HTrjmP964xG1jYvQ+ozTsv/n4xCiaoVoQPtYSVJRqU1r009rx7FcDWgfq/i6NXQyv1gBVotq1wh2168IAAAAAADgwKc6wuHZf2/Xuz8dcFxbLNL5/tcxaUhb/bD7hH7ef1JFpXbHeKuYcO3KypMk/fhUP8XXrVEtmQEAAAAAgH9xpSei+ILD0l3H9eBH69UpPlJDOjXQtW1itPHQGY39aqs6NYpUv9b11a91fY2du0U/7D7h0vfeOPFaRYYFldtpBgAAAAAA4AqKL1SrjYfO6A9v/CRJ6tm8nvpeFq2+LaMVFxmqiV9vU2RYkJKa11Pq5mNK3XLMcV9IoFXNomvpgxHdVT8i1Kz4AAAAAADAi1F8ododPXNWkWFBqhly7mPipn+/W++vTNeZwlKn8VVjrlZcZFh1RgQAAAAAAD6I4gsep6jUpoc/2aDF27MkSfVqBuvvw7qoZ/Mop3WZOUX6cc8Jrdp/Uk3r1dTD11xmRlwAAAAAAOChKL7gkcpsdv28/5SeT92unZl5slqkR665TB0aRurHPdlasTdbe4/nl7tv8g3tdFtiYwUGWE1IDQAAAAAAPAnFFzza2RKbxs3bornrj5Sbs1qkDo1qa9OhM07jTerV0LInr+JwfAAAAAAA/JwrPdG5D2gCqkFYcIBe+XMndW1cR899u11RtUJ0Zato9WkRpZ7NoxRZI0h2u6Fh7/ysn/efkiQdPFmo19P26L6+zRRgtSgkMMDk3wIAAAAAAHg6dnzBVCVldgUFWCrdyZWVW6TEKWmOa4tFMgzp0Wsu022JjRUdHsIuMAAAAAAA/IgrPRGHJsFUwYHWcxZXMRGhWplytUKDfv2f6n9r2tfT9qjHlDTN+eWQO2ICAAAAAAAvRPEFj9egdpi+erCXpv6xgx5Ldv6Ux683HjUpFQAAAAAA8HSc8QWv0CYuQm3ift2+eE/vplq8PUujP9ukVftPamdmrlrH8ggsAAAAAABwxo4veJ3w0CD1bxfruB4w/UcVlpSZmAgAAAAAAHgiii94pZohgRrcIc5x3XbiQuUUlkqSists8oLPbAAAAAAAANWMT3WE17LZDTUfO99prH54iE7kFyuhXk39qVsj/bFrQ8VFhpmUEAAAAAAAVDVXeiKKL3i1E3nF6v7C95XOWy3S5U3qqm2DCN3UpaE6x9d2XzgAAAAAAFDlKL7gV4rLbHohdYf2nyhQcpv66tsyWusOntbn6w5rzYFTjnWBVot+fLofO8AAAAAAAPBiFF/Afxw8WaB/bzqqlxftliQ9cnULjb6ulcmpAAAAAADAxXKlJ+Jwe/i0JvVq6qGrL3Nc/23JXv1zVbqW7Tqu/SfyVVxmMzEdAAAAAACoToFmBwDcYVhiY328OkOSNOHrbY5xi0WKjQhVfN0aavyfr/i6Yf/5zxqKrhUii8ViVmwAAAAAAHAJeNQRfqHUZte8DUe0MzNPGacKdehUoTJOFaqw5Pw7vga2j9Wbt3dzQ0oAAAAAAHA+nPEFXADDMHSyoMRRgv33P399fVZHzpx1Wh8bEarGdWvoietaavWBU1q8PUsPXtVcyW1jFBTAU8MAAAAAALgDxRdQBTYfPqMbZvx03nVRtUJ0Zcto9W0ZpRs7N3RDMgAAAAAA/BfFF1BFNh06o+nf79bOzDwdyykqNx8eEqi84jLH9TND2iogwKqC4jLVDA5Qmd3Q8KQEWS1Sic2u4ACrDEOyWn89N6zUZte6g6e1/0SBwkMDtXJftq5tG6P64aH6cU+2ymx2PdivhQKsnDMGAAAAAIBE8QVUi+N5Rdp5LE/dmtRRzZBfPxei1GbX99uz9MC/1rv8/a5tG6NV+04q/3+Ks8pM+UMHDeoQqxKbXftPFCg0KEBFpTbZDUM/7zupn/ef0pYjObq3T1NZLBY9cs1llGUAAAAAAJ9E8QW4kWEYumHGT9p7PF9dGtdWRGiQAqwWpW455tL3iQ4P0Ym8YklSzeAAFVzAwfvn8tf+rXR5kzoKDw1SQlQN1QjmQ1wBAAAAAN6P4gtwM5vdkGEYCvyfQ+6Ly2xK3XxMpwtLZbVIdWoEq8xu6J0f9yvAatGAdrG6slW02jeIVJndUHCgVRknC5VdUKwODSOVe7ZU3Z7//pw/N6pWsHo2j9LRM2e19uDpc66dfefluqZNTJX8vgAAAAAAmIXiC/AhZ0tsmvNLhqLDQ5XUvJ4Mw1Ct0EDlF5Wpbs1gWSy/PdJotxv69JdDGvvVlgq/V+8WUXpqQCt1bFS73JzNbshqkdP3AwAAAADA01B8AX6uuMym4jK7DLv05frDevbb7eXW1K4RpKRm9XS21KYym6Gf959Umd1Q69hwpT7ShzPCAAAAAAAeieILgJOvNx7Ro59udOmejo0itflwjh655jKNvrZl9QQDAAAAAMBFFF8AKpRXVKoXUnfo018OqWHtMB05c1aDOsTqimb1FBMRqgf/tV42e8X/SBiW2FhT/tBBhmHwOCQAAAAAwDQUXwAuit1uKG3ncS3ZmaWgAKs+XHXQab51bLj2Hs9Xmd1Qy5ha+tutXdQqJpwiDAAAAADgNhRfAKpEUalNH/18UM+n7jjnuh3PDlBYcICbUgEAAAAA/BnFF4AqdbbEps/WHpLdMGSzGxUWYW/d3k2r9mVrZJ9miq9bw4SUAAAAAAB/QPEFoNrZ7YaajZ1/zjXP3dhOdyQluCcQAAAAAMAvuNITWd2UCYCPsVotWjP2mnOumfD1No36eL2bEgEAAAAA4IwdXwAuiWEYKiyxqWZIoA5kF+jpLzerUe0wzd1wxLGmaVRNNY+updeGdlLN4EBZLOJAfAAAAADAReFRRwCmO3SqUH1eXFrp/E2dG2j6LV3cmAgAAAAA4At41BGA6eLr1tBn/5dU6fy8jUfV58Ul2nokR5+tPaSnv9isn/ef1Mn8YknSsZyzysotUlGpTdn/GQMAAAAAwBXs+AJQ7YrLbPrlwGmV2u06lV+iJz7fdNHfq1VMuHZl5alL49qqFRKo3LOlGn1dK3VpXFsRoUFVmBoAAAAA4Il41BGAR9t/Il9Xv/JDlX/fJU9cqWbRtar8+wIAAAAAPAfFFwCvUGazq8RmV43gQJXa7Aq0WvTNpqMKDw1Uy5hwbcg4ozZxEVqbfkrLdp1QvVrB2ns8X6sPnFLvFlFasTe7wu/774d6q0OjSMe13W7IauUwfQAAAADwBRRfAPyGYRh6bM5Gfb3xqNN4zeAANYuupS1HcpzGB7aPVb/W9dXnsijFRYa5MyoAAAAAoApQfAHwO0WlNj308Xp9v+P4Bd8THhKoLZP7V2MqAAAAAEBVo/gC4LcMw9DP+09pZ2auTuaXKCGqpiTpyXMcqB8UYNHWyf0VEhjgrpgAAAAAgItE8QUA51BSZlfL8d+VG//7rV20ct9JldnsalSnhm7tEa/6EaEmJAQAAAAAVIbiCwDOwzAMbT+Wq8F/W3HOdfF1w2QYUnhokHYcy1Wz6Jqa+0BP1a4R7KakAAAAAID/RfEFAC649e2ftWr/SZfuSW5TX49f21LtGkSefzEAAAAAoMpQfAGAiwzDkMVicVx/vvaQxn61RTWCA9Usuqb2Hc9XblFZufvWT7hWdWuy+wsAAAAA3IXiCwCqSVGpTe/+dEAvLtjlGHtvRHcdzC7QyYIS3dSloRrWDlNoEAflAwAAAEB1oPgCgGp2y9ur9PP+U+dc89f+rfTgVc2ddpIBAAAAAC6NKz2R1U2ZAMCn/OOOy8+75qWFu9R0zHz944d92ns8X19vPKJ9J/Jls3v83zcAAAAAgE9gxxcAXILiMpuCA6yyWCwqLCnTsl0n9OC/1rv0PfpcFqUHrmyupOb12B0GAAAAAOfBo44AYLKzJTa1mbjA5fsSm9bVC39orxb1w6shFQAAAAB4P4ovAPAQJWV2HTxZoMb1asgii04VlGjxjiy1iQ3XrbN+Vqmt4n8Ev/qXTvpj10ZuTgsAAAAAno/iCwC8iGEY+lvaXr32/e4K55+7qb3+3K0RnxQJAAAAAKL4AgCv9e3mo3ro4w0Vzt3ctZFe/nNHzgEDAAAA4NcovgDAi20+fEZz1x/RvI1HdKawtNz8Q/1a6InrWlKAAQAAAPBLFF8A4ENyi0r18Mcb9MPuExXO/1/fZkoZ2JoiDAAAAIBfcKUnsropEwDgIkWEBumDu3vo9Vs6Vzj/j+X71XTMfP2/BTtlsxsyDEM2u6EzhSXadjRHeUXld40BAAAAgD9gxxcAeJGcs6VasjNLMRGh+nDlQS3YlnlB971+S2fVDw9V1ya1FRLIIfkAAAAAvBePOgKAH9mQcVp/eGPlBa8PCrDont7NdPh0oSLCgjRuUBsdyylSs6iaslp5XBIAAACAZ6P4AgA/dOTMWWXnFeuX9FNKbFpP8XXDdM8Ha7Xu4GmXvs8zQ9rq+k4NVLdGMEUYAAAAAI9D8QUAcCi12XW21KaNGWc0/N01Lt37526N9NKfO1VTMgAAAABwHcUXAOCCnMgrVm5RqU7kFeuzXw5p7oYj5db0alFP797VnbPBAAAAAHgEii8AwEXbdyJfmw+f0eNzNpWb69q4tj4amagawYEmJAMAAAAAii8AQBVYm35Kf3prVaXz9/Ruqgeuaq6cs6U6mV+iHcdyFVUrRGdLbZKka9vEKLJGkLviAgAAAPATFF8AgCphGIaO5RRp3sYjenHBrov6HmvHJyuqVkgVJwMAAADgryi+AADVIr+4TO0nLXT5vk7xtTVzWBc1qlOjGlIBAAAA8CcUXwCAamcYhk4VlKhuzWBJksViccwVFJfpmld+UGZuUbn7Uga21sjeTRUYYHVbVgAAAAC+g+ILAOARftqbrdveWV3h3NWt66tpVE21iglXcZlNA9rHKTqcRyIBAAAAnJsrPdFF/XX7zJkzlZCQoNDQUCUmJmrNmjWVri0tLdWzzz6r5s2bKzQ0VJ06ddKCBQsu5scCALxMrxZRSp82WGvHJ5ebW7LzuGavOKCnvtysCV9vU/cXvlfrCd9p8fYsE5ICAAAA8EUu7/iaM2eOhg8frrfeekuJiYmaPn26Pv/8c+3atUv169cvt/7pp5/WRx99pFmzZql169ZauHChRo8erZUrV6pLly4X9DPZ8QUAvuN8nxb5e88Maas7eyY4PUoJAAAAwH9V66OOiYmJ6t69u2bMmCFJstvtio+P18MPP6yUlJRy6xs0aKBx48Zp1KhRjrGbb75ZYWFh+uijjyr8GcXFxSouLnb6heLj4ym+AMBHrTt4Wje/ufKca65oVld/7d9K3ZrUdVMqAAAAAJ7IleIr0JVvXFJSonXr1mnMmDGOMavVquTkZK1aVfHf3hcXFys0NNRpLCwsTCtWrKj050ydOlWTJ092JRoAwIt1a1JH6dMGS5IKS8r0S/ppvfPjfv24J9ux5uf9p3Tzm7/+u+a1oZ00sH2cQoMCTMkLAAAAwDu4tOPr6NGjatiwoVauXKmkpCTH+FNPPaUffvhBq1eXP8B42LBh2rRpk+bNm6fmzZsrLS1NN954o2w2m9Ourv/Fji8AgPTrJ0e+sWyfXlq4q9xcWFCAzpbaHNddG9fWrOGXq14tDsgHAAAAfFm17fi6GK+//rruvfdetW7dWhaLRc2bN9eIESP07rvvVnpPSEiIQkL4gwsA+DuLxaJR/VpoVL8Wyi8uU/tJCxVVK0RWi3Q8z/kvT9ZnnFG3579Xp0aR+vCeRBmGoQ0ZZySL1LReTZXa7LIZhnZn5SuhXg11aBjpdG5YQXGZSm121a4R7ObfEgAAAEB1can4ioqKUkBAgLKynD9xKysrS7GxsRXeEx0drXnz5qmoqEgnT55UgwYNlJKSombNml18agCA36kVEuh4HLLUZtcPu07oeF6xdmbm6sNVBx3rNh3OUafJiy7657x4c0f9pXv8JecFAAAAYD6rK4uDg4PVrVs3paWlOcbsdrvS0tKcHn2sSGhoqBo2bKiysjJ9+eWXuvHGGy8uMQDA7wUFWJXcNkbDEhvr2RvbK33aYM1/pM957rmwT4V86svNSkhJ1eg5G+Xi578AAAAA8DAuf6rjnDlzdOedd+of//iHevTooenTp+uzzz7Tzp07FRMTo+HDh6thw4aaOnWqJGn16tU6cuSIOnfurCNHjuiZZ57RgQMHtH79etWuXfuCfqYrz24CAPxbmc2uXVl5iokIVVStENnthjJzixQbESqr9dfya8HWY/phd7byikrVJi5CneNrK+dsqR781/py3y+qVoj+cUdXtY6NUM2Qaj8hAAAAAMB5VOsZX0OHDtWJEyc0ceJEZWZmqnPnzlqwYIFiYmIkSRkZGbJaf9tIVlRUpPHjx2v//v2qVauWBg0apH/+858XXHoBAOCKwACr2jWIdFxbrRY1qB3mtGZA+zgNaB9X7t4fn+qnZ77ZprSdxx1j2fnFjk+TbBZVU61iw/Xa0M58oiQAAADgBVze8WUGdnwBANyppMyuT9ZkaNI32ypdc/+VzfX0gFbad6JAB7IL1K9VtAIDXDpBAAAAAMBFcKUnovgCAOAcbHZD247m6LZZq5VXXHbOtXf3aqqJQ9q6KRkAAADgnyi+AACoJhknC9X3paXnXTf08njd3bupWsWGuyEVAAAA4D8ovgAAqEZ5RaVae/C06tUMVuvYCM3beERPfbH5nPfsen6AQgI5FwwAAAC4VBRfAAC42cn8Yr20cJfOFJZqwbbMStc1qhOmu3omaHDHOMVFhlW6DgAAAEDFKL4AADCZ3W7og1Xpmvzv7edc98X9SerQKJLdYAAAAMAFovgCAMCDnMwv1tcbj+rZb89dgknSXT0TdPsVTdSifi03JAMAAAC8D8UXAAAerKTMrpbjv7ugtY8nt9Q9fZqqVkhgNacCAAAAvAPFFwAAXsBmN/TBynS9smiXCkpsF3TPo9dcpoevbqHAAGs1pwMAAAA8E8UXAABeyjAMzV5xQM+n7jjv2rfv6KZeLaJUk91gAAAA8CMUXwAA+IhjOWf1f/9cp82Hc8657rbExnr+pvayWCxuSgYAAACYg+ILAAAf9fP+k7rl7Z8rnZ94fVv9sWtD1a4R7MZUAAAAgPtQfAEA4AdOFZSo63OLz7nmzqQmeuaGdpKkjFOFysotVuO6NRQTEcLuMAAAAHglii8AAPzI/35KZHR4iE7kFV/Qfff2aapxg9tWZzQAAACgylF8AQDgxw6eLNC9H67V7qz8C75nVL/mGtGrqaJqhVRjMgAAAODSUXwBAABJUnZ+sbJyi3S2xKb2DSMVEmjV9zuO694P157zvi8fSFK3JnXdlBIAAAC4cBRfAADgnAzD0Psr0zX539vPue7A1EGcBQYAAACPQvEFAABcUlJm1097szXi/V8qnJ98Qztd3zFOtWsEK8BKEQYAAADzUHwBAIBLkpCSes75u3omOD4tEgAAAHAnii8AAHDJjucWqceUtErn4yJDNbJPM93Tu6kbUwEAAMDfUXwBAIAqZbcbyisq09qDp3TPB+UPxt83ZRCPQAIAAMAtKL4AAEC1sdsNrUk/pVve/rnC+UZ1wvT96CsVGhTg5mQAAADwBxRfAACg2hWWlKntxIXnXHNnUhN9sOqgfnyqn+Lr1nBTMgAAAPgyii8AAOA2h04Van3Gac1cule7s/IrXdcyppZq1wjWZ/+X5MZ0AAAA8DUUXwAAwBR2u6H/+2idFm/PUmRYkHLOlla47p3hlyu5bYyb0wEAAMAXUHwBAACP8dPebE2Zv0PbjuY6jTePrqmFj/VVYIDVpGQAAADwRhRfAADA49jthv6+ZK9e+36303hsRKg+vjdRzaJrmZQMAAAA3oTiCwAAeCzDMHTNqz9o/4kCp/E+l0UpIixID/VroTZx/PseAAAAFaP4AgAAHm/v8Xwlv/pDhXM7nxug0KAANycCAACAN6D4AgAAXuPt5fs0Zf7OCueiagWrdWyE2jaIUHKbGHVrUkcBVoubEwIAAMCTUHwBAACvY7MbGvL3Fdp+LPec6xrXraHhSU3058vjFRkW5KZ0AAAA8BQUXwAAwGudzC/Wyn0n9dnaQ/pxT7Yk6fImdbT24OkK19cIDtDCx/oqvm4Nd8YEAACASSi+AACAzykqtem+f67T8t0nKpwfO6i1BndsoHo1gzkfDAAAwIdRfAEAAJ9WXGbTnF8OaeLX2865rllUTf21fysN7BDnpmQAAACobhRfAADAb6zYk63bZ68+77q4yFC9dXs3RYeHqE6NYIUFsysMAADAG1F8AQAAv2OzGzpTWKKvNhzRv1ZnKCjAot1Z+ZWub1G/lr55qJcCrVYFB1rdmBQAAACXguILAABA0om8Yr25bJ82Hjqt9Rlnzrn2rdu7akB7HokEAADwdBRfAAAAv1NcZtPh02d1tsSm6/++4rzrxw9uo5F9mrkhGQAAAFxB8QUAAHAeOWdLlXu2VO/9lK53fzpQ6brYiFClPXGlaoYEujEdAAAAKkPxBQAA4KKtR3JUWGJTXlGp7vlgbYVrwkMDtfTJqxRVK8TN6QAAAPBfFF8AAACX6FyfFvnX/q00ql8LNycCAACARPEFAABQpZbvPqHh764pN96rRT395fJ43di5oQmpAAAA/JMrPRGf3Q0AAHAefVtGK33aYL171+VO4z/tPalHP92oTYfOmBMMAAAA50TxBQAAcIGubh2jnc8NUJ/LotQ6NtwxfuPMn/T693tMTAYAAICK8KgjAADARfrHD/s09bud5cYb162hjFOF+uieRPW+LMqEZAAAAL6LM74AAADcJDu/WJc///0513xwdw9d2TLaTYkAAAB8G8UXAACAGx3LOatvNh7VwVOFiq4VovdXpivnbGm5dTufG6DQoAATEgIAAPgOii8AAAAPcN+Ha7Voe5bTWOvYcE0c0lZJzerJYrGYlAwAAMB7UXwBAAB4iJyzpeo0eVG58bCgAC18rK8a16thQioAAADv5UpPxKc6AgAAVKPIsCClTxussYNaO42fLbWp70tLlZCSqpP5xSalAwAA8G3s+AIAAHCjjJOF6vvS0nLjo/o115PXteLxRwAAgPPgUUcAAAAPl1NYqk7Pln8Esl+raL30506KqhViQioAAADPR/EFAADgJT5cla6JX2+rcO65m9rrjiuauDkRAACAZ+OMLwAAAC8xPClBe14YqBs6NSg3N2HeVm0/mmtCKgAAAN/Aji8AAAAPcrbEpo2HzujWWT87xt6963L1aFpPtUICTUwGAADgGXjUEQAAwMv9a/VBjftqa4VzdyY10TM3tOMgfAAA4JcovgAAAHzAuoOndPObqyqd79QoUh/fe4VqshMMAAD4EYovAAAAH1FcZlNRiV27j+dp7vrD+mTNoXJrrmoVrb3H8zVuUBsN7BBnQkoAAAD3ofgCAADwYcdyzipp6pJK5xc81ketYsJ5FBIAAPgkii8AAAA/sHBbptYcOKXZKw5Uuib1kd5qGROuoAA+zBsAAPgGii8AAAA/c7bEpjYTF1Q6XzM4QFsn92cXGAAA8Hqu9ET81R8AAIAPCAsOUPq0wTowdZDWjLum3HxBiU0vLdxlQjIAAADzsOMLAADAh+UXl6n9pIXlxu+4oonu69tMsZGhPAYJAAC8Co86AgAAwGHfiXxd88oPlc43rB2mn1KudmMiAACAi0fxBQAAgHKW7z6h8fO2KuNUYYXzrWPDdXfvpuoSX1uXxYS7OR0AAMCFofgCAADAee3JytO1ry2vcK5uzWAtf6qfaoUEujkVAADAuVF8AQAA4IJ9s+moHvlkQ6Xza8cnq17NYD4REgAAeASKLwAAAFyUrNwiJU5Jq3S+XYMIpT7Sx42JAAAAnFF8AQAA4JKU2uxqN2mhSsrsFc73alFPA9vHaWj3eD4VEgAAuBXFFwAAAKqEzW6ouMym5btP6P6P1le6Lr5umN67q4eaR9fkkUgAAFCtKL4AAABQ5QzDUPKrP2jfiYJzrts3ZZACrJRfAACgelB8AQAAoNqV2exKP1mo5Fd/KDe3euw1iokINSEVAADwdRRfAAAAcLu+Ly5VxqlCp7E7rmiiZ25oxw4wAABQZVzpiTiJFAAAAFVi+VP91DSqptPYP38+qOZj5+vImbMmpQIAAP6M4gsAAABVZumTV2npk1eVG+81bYnu/+c69wcCAAB+jUcdAQAAUG3u+3CtFm3Pchr76J5E9b4syqREAADA23HGFwAAADzGuoOndPObq8qND+oQq5DAAN3Xt5naxPH/8QAAwIWp9jO+Zs6cqYSEBIWGhioxMVFr1qw55/rp06erVatWCgsLU3x8vB5//HEVFRVdzI8GAACAl+nWpK52PDug3Pj8LZn6asMRDXz9RyWkpOoPb/yk3KJSExICAABf5XLxNWfOHI0ePVqTJk3S+vXr1alTJ/Xv31/Hjx+vcP3HH3+slJQUTZo0STt27NDs2bM1Z84cjR079pLDAwAAwDuEBQcofdpgbX+2v5pH11StkMByazZknFHHZxYpISVVZ0tsJqQEAAC+xuVHHRMTE9W9e3fNmDFDkmS32xUfH6+HH35YKSkp5dY/9NBD2rFjh9LS0hxjTzzxhFavXq0VK1Zc0M/kUUcAAADftSszT/2nL69wbv2Ea1W3ZrCbEwEAAE9WbY86lpSUaN26dUpOTv7tG1itSk5O1qpV5c9tkKSePXtq3bp1jsch9+/fr/nz52vQoEGV/pzi4mLl5uY6fQEAAMA3tYoNV/q0wdo2uX+5ua7PLVaHSQv1z58Pymb3+KNpAQCAhym/x/wcsrOzZbPZFBMT4zQeExOjnTt3VnjPsGHDlJ2drd69e8swDJWVlen+++8/56OOU6dO1eTJk12JBgAAAC9XMyRQ6dMG61jOWSVNXeIYzysu04R5WzVh3lZJ0uAOcZoxrIssFotZUQEAgJe4qMPtXbFs2TJNmTJFb7zxhtavX6+5c+cqNTVVzz33XKX3jBkzRjk5OY6vQ4cOVXdMAAAAeIi4yDClTxusfz/Uu8L51C3H1HTMfCWkpCq/uMzN6QAAgDdxacdXVFSUAgIClJWV5TSelZWl2NjYCu+ZMGGC7rjjDo0cOVKS1KFDBxUUFOi+++7TuHHjZLWW795CQkIUEhLiSjQAAAD4mA6NIpU+bbAkafX+k7rzvTUqKrU7rWk/aaH+0KWhJlzflrPAAABAOS7t+AoODla3bt2cDqq32+1KS0tTUlJShfcUFhaWK7cCAgIkSS6eqw8AAAA/ldisnnY+N1Dp0wZr/iN9nOa+2nBEXZ9brISUVG0+fMacgAAAwCO5tONLkkaPHq0777xTl19+uXr06KHp06eroKBAI0aMkCQNHz5cDRs21NSpUyVJQ4YM0auvvqouXbooMTFRe/fu1YQJEzRkyBBHAQYAAABcqLYNIpQ+bbB+3HNCd8xe4zR3w4yfJEkzh3VVx0aRiq9bw4yIAADAQ7hcfA0dOlQnTpzQxIkTlZmZqc6dO2vBggWOA+8zMjKcdniNHz9eFotF48eP15EjRxQdHa0hQ4bohRdeqLrfAgAAAH6nz2XRSp82WOnZBbrq5WVOc6M+Xu94vfeFgQoMqPajbQEAgAeyGF7wvGFubq4iIyOVk5OjiIgIs+MAAADAA+UUlqrntDQVlNjKzbVrEKGnB7RW58a1FREaZEI6AABQVVzpiSi+AAAA4HNsdkPNx86vdH5lytVqUDvMjYkAAEBVcaUnYs83AAAAfE6A1aL0aYP1xf1J6tsyutx8z2lLNPD1H3Uyv9iEdAAAwF3Y8QUAAAC/UGazq+2khSops5ebe3pAaz1wVXMTUgEAAFfxqCMAAABQiRV7snX77NUVzkWGBWn9hGsVYLW4ORUAALhQFF8AAADAeZTZ7Hpx4S69vXx/pWuaRdfU2IFt1LNFPdUIdvkD0QEAQDWg+AIAAABcsHTXcY1475fzruvYKFL/vDtRkTX4ZEgAAMxC8QUAAABchF2Zedp2NEffbDqqZbtOnHPtmnHXqH54qJuSAQCA/6L4AgAAAKpITmGp3v3pgF5P21PhfFCARS//uZNu7NzQzckAAPBPFF8AAABANSgps6vl+O8qnV815mrFRYa5MREAAP6H4gsAAACoRoZh6Jf00xr71RbtPZ5fbn7b5P6qGcJh+AAAVAeKLwAAAMBNDMNQ0zHzK5wb2D5Wb97ezc2JAADwbRRfAAAAgJvZ7YZaT1igEpu9wvlvH+6t9g0j3ZwKAADfQ/EFAAAAmOR0QYlmrzigGUv3VjhfMzhAreMiNH1oZ8XXreHmdAAAeD+KLwAAAMBkNruhj1cf1ISvt51z3bVtYzQssbGuahkti8XipnQAAHgvii8AAADAw8zbcESPzdl4zjVv3tZVAzvEuScQAABeiuILAAAA8GBFpTY99PEGfb8jq8L5TROvU2SNIDenAgDAO1B8AQAAAF5k1b6TunXWz+XGf3yqH+eAAQDwO670RFY3ZQIAAABQiaTm9bRvyqBy431eXKpHP92g9OwC5RaVmpAMAADvxo4vAAAAwIPszMzVgOk/Vjo/fnAb3d2rqaxWDsIHAPgnHnUEAAAAvNyJvGLd9s7P2p2VX+H8sze20/CkBPeGAgDAA1B8AQAAAD7CMAyV2Q31nLZEJ/KKy82/8If2urV7Y3aAAQD8BsUXAAAA4KPe++mAJv97e7nxf9zRTf3bxZqQCAAA96L4AgAAAHzcK4t26e9L9jqNxUWG6qenr2b3FwDAp1F8AQAAAH7iX6sPatxXW53Gru8Yp7/f2kUWCwUYAMD3UHwBAAAAfuTHPSd0x+w1Fc7Nf6SP2sSFU4IBAHwGxRcAAADghw6dKlSfF5dWOv/6LZ11Y+eGbkwEAEDVo/gCAAAA/FSZza51B09r6Ns/V7rmvr7NNHZQGzemAgCg6lB8AQAAAJAk5RSWqtOziyqc2za5v2qGBLo5EQAAl4biCwAAAEA5K/dla9is1U5jCfVqaMFjfRUaFGBSKgAAXEPxBQAAAKBCeUWl6vBMxTvALqtfS4se78tB+AAAj0bxBQAAAOCcPl6dobFfbal0fumTV6lpVE03JgIA4MJQfAEAAAC4IGU2uw6eKtQ1r/xQ4fwt3eM19Y8d2AUGAPAYrvREVjdlAgAAAOCBAgOsah5dSwemDtKYga3LzX/6yyE1HTNfuzLzTEgHAMClYccXAAAAgHKW7Tquu977pdz4tD920OCOcQoPDTIhFQAAPOoIAAAAoAoUl9nUbuJCldkr/iPD8ze11+1XNHFzKgCAv/PZ4uvEiRMUXwAAAICblZTZ9cL87fr3pmMqKrU5zV3ZMlpv3t7NpGQAAH+Um5ur6OjoCyq+At2UqUq88sorCg0NNTsGAAAA4HdCJf05UOX/BHFImjp1kQmJAAD+qqio6ILXcrg9AAAAAAAAfBKPOgIAAAC4KPlFpeo5bUm5M8CeGtBKd/VsalIqAICvc+VRR68qvjjcHgAAAPA8B7IL1O/lZeXGH7m6hUZf18r9gQAAPs1nD7en+AIAAAA815frDuuJzzeVG+/SuLbeGX656tUKMSEVAMDXUHwBAAAAMM2/Vh/UuK+2Vjh3b5+mGje4rZsTAQB8CcUXAAAAANN9siZDY+ZuqXBuzn1XqH3DSNUM8aoPmgcAeACKLwAAAAAe5dXFu/W3tD0VzrWJi1C3JrU1dlAb1QimCAMAnBvFFwAAAACPlDQ1Tcdyis655u+3dtH1HeNksVjclAoA4E0ovgAAAAB4tJzCUj3x+SadLizR1iM5Ki6zl1vTqVGkPrs/SSGBASYkBAB4KoovAAAAAF6lpMyu5Fd/UMapwnJzr9/SWTd0asAOMACAJIovAAAAAF7seG6Rrnn1B+UVlZWbe/nPndS3ZZTqh4eakAwA4AkovgAAAAB4vbFfbdHHqzMqnOvWpI6+fKCnmxMBADwBxRcAAAAAn3HoVKH6vLi0wrngQKu2Te6voACrm1MBAMxC8QUAAADAJ207mqPBf1tRbrxvy2hd2TJakhQaZNVtiU3cHQ0A4CYUXwAAAAB8lmEY2nDojP74xsrzru3QMFIzh3VV43o13JAMAOAOFF8AAAAAfJ7dbmjkh2u1ZOdxSVLdmsE6VVByznveu6u7+rWu7454AIBqQvEFAAAAwG+dLijRc6nbNXf9kUrXzBjWRdd3bODGVACAqkLxBQAAAAD69bHIozlFuuHvK3Tyd7vB6tYM1kf3JKptA/6MAQDehOILAAAAAH7HMAzN+eWQUuZuKTf32tBO+kOXRiakAgC4ypWeiM/8BQAAAOAXLBaLbunRWD/89So1+d1h94/P2aSElFR9uiZDXrA3AABwgdjxBQAAAMAvGYahfyzfr2nf7Sw31z2hjj6/v6cJqQAA58OOLwAAAAA4D4vFovuvbK4tz1yna9vGOM39kn5aCSmpOpBdYFI6AEBVYMcXAAAAAPzHyn3ZGjZrdbnx9GmDTUgDAKgIO74AAAAA4CL0bB6lnc8NKDeekJKqzYfPcP4XAHgZdnwBAAAAQCWajknV7//E9O+HeqtDo0hzAgEA2PEFAAAAAFVh44TrdHmTOk5jQ2asUEJKqg6dKjQpFQDgQrHjCwAAAAAuwKOfbtDXG486jV3dur5m33m5LBaLSakAwP+40hNRfAEAAADABTIMQx2fWaS84jKn8Y6NInVVy2iNurqFQgIDTEoHAP6B4gsAAAAAqlFeUak6PLOowrkDUwexAwwAqhFnfAEAAABANQoPDVL6tMF6bWgnhQU57/BqOma+Fm3LNCkZAOB/seMLAAAAAC6R3W7ohpkrtPVIrtP4Nw/1UsdGtc0JBQA+ikcdAQAAAMAE8zYc0WNzNlY4t+eFgQoK4KEbALhUPOoIAAAAACa4qUtDrRl7TYVzl437Tne+u0Y2u8fvPQAAn8GOLwAAAACoBoZh6PO1h/XUl5vLzXEAPgBcPHZ8AQAAAIDJLBaL/tI9XunTBuvuXk2d5v781iqVlNlNSgYA/oPiCwAAAACq2cQhbbX3hYGO67UHT6vl+O/09vJ9KrNRgAFAdeFRRwAAAABwE5vd0LBZP2v1gVPl5j66J1G9L4syIRUAeBcedQQAAAAADxRgtWjO/yXptsTG5eZun71aCSmpOplfbEIyAPBN7PgCAAAAAJMcOlWoP7yxUtm/K7v+1K2RJlzfVpFhQSYlAwDP5UpPRPEFAAAAAB6g17QlOnLmrNNYXGSoZt7WVV3ia/MpkADwH9X+qOPMmTOVkJCg0NBQJSYmas2aNZWuveqqq2SxWMp9DR48+GJ+NAAAAAD4pJ9SrtZbt3dzGjuWU6Q/vrFSTcfMV0JKqlI3H5MX7F0AAI/h8o6vOXPmaPjw4XrrrbeUmJio6dOn6/PPP9euXbtUv379cutPnTqlkpISx/XJkyfVqVMnvfPOO7rrrrsu6Gey4wsAAACAPzl0qlC3vP1zuR1g/3VnUhM9c0M7doEB8EvV+qhjYmKiunfvrhkzZkiS7Ha74uPj9fDDDyslJeW890+fPl0TJ07UsWPHVLNmzQrXFBcXq7j4t2fcc3NzFR8fT/EFAAAAwO8s2ZmlBz5ar+Iye7m5529qr9uvaGJCKgAwT7U96lhSUqJ169YpOTn5t29gtSo5OVmrVq26oO8xe/Zs3XLLLZWWXpI0depURUZGOr7i4+NdiQkAAAAAPuPq1jHa9fxApU8brHeGX+40N37eViWkpOrVxbtVVGozKSEAeC6Xiq/s7GzZbDbFxMQ4jcfExCgzM/O8969Zs0Zbt27VyJEjz7luzJgxysnJcXwdOnTIlZgAAAAA4JOS28YofdpgJbdx/jPZ39L2qPWEBWo94TvOAAOA/xHozh82e/ZsdejQQT169DjnupCQEIWEhLgpFQAAAAB4l3fuvFx2u6ER7/+iX9JPqbDk191eRaV2NR0zX+Ghgdow4VoFBlzU55kBgM9w6Z+CUVFRCggIUFZWltN4VlaWYmNjz3lvQUGBPv30U91zzz2upwQAAAAAOLFaLfrg7h7a/uwA/TzmGqe5vKIytRj3ncZ+tUW7s/JMSggA5nOp+AoODla3bt2UlpbmGLPb7UpLS1NSUtI57/38889VXFys22+//eKSAgAAAAAqFBsZqvRpg/Xtw72dxj9enaHrXluuhJRUNRuTqs2Hz5gTEABM4vK+19GjR2vWrFn64IMPtGPHDj3wwAMqKCjQiBEjJEnDhw/XmDFjyt03e/Zs3XTTTapXr96lpwYAAAAAlNO+YaQOTB2k269oXG7Obkg3zPhJCSmpOlVQYkI6AHA/l8/4Gjp0qE6cOKGJEycqMzNTnTt31oIFCxwH3mdkZMhqde7Tdu3apRUrVmjRokVVkxoAAAAAUCGLxaLnb+qg52/qILvd0NebjujxOZuc1nR9brEkqV+raL17V3dZLBYzogJAtbMYXvCRH7m5uYqMjFROTo4iIiLMjgMAAAAAXqfUZlfS1DRl51e82+vDu3uob8toN6cCANe50hNRfAEAAACAHzEMQ5+vPaynvtxc4fxXD/ZUl8Z13JwKAC4cxRcAAAAA4Lyy84v18sJd+vSXQ07jneJra+4DPRVg5RFIAJ7HlZ7I5cPtAQAAAAC+IapWiKbd3FHL/9rPaXzToTNqPna+Zi7da1IyAKga7PgCAAAAAEiSTuQVq/sL35cbf/HmjvpL93gTEgFAeTzqCAAAAAC4aN9vz9LID9eWG78tsbFe+EMHExIBwG941BEAAAAAcNGS28Zo53MDdHevpk7j/1qdof6vLVdBcZm8YA8FALDjCwAAAABQubyiUv1rdYamfbez3Nxn/5ekHk3rmpAKgD/jUUcAAAAAQJU6euasek5bUuHcvFG91KlRpCwWPgUSQPWj+AIAAAAAVIucwlIt2p6pv36xudzcjGFddH3HBiakAuBPKL4AAAAAANWquMymTpMXqajU7jTeIDJUH97TQy3qh5uUDICvo/gCAAAAALjNJ2syNGbulnLjL/6po7on1FV8nTAFBvDZagCqBsUXAAAAAMCtth7J0ZOfb9LOzLwK52/tEa9JQ9opNCjAzckA+BqKLwAAAACAKQpLytR24sJzrtn8zHWKCA1yUyIAvobiCwAAAADgEbYcztGQGSvKjd9xRRONvral6tQMNiEVAG9G8QUAAAAA8Cgn84vV98WlKiixlZsbP7iNbr+iCY9BArggFF8AAAAAAI+0eHuW7v1wbaXz8x/po7YN+HMfgMpRfAEAAAAAPJrdbmjG0r16dfHuCudf+lNH/albI1ksFjcnA+DpKL4AAAAAAF7jdEGJ/rX6oF5eVL4Em3B9W93Tu6kJqQB4KoovAAAAAIDXKSmz65FPNmjBtsxyc/NG9VLn+NruDwXA41B8AQAAAAC82jebjuqRTzaUGx8/uI1G9mlmQiIAnsKVnsjqpkwAAAAAAFywGzo10L4pg8qNP5+6Q3/5xyrlFZWakAqAt6H4AgAAAAB4pACrRenTBmvHswOczvlac+CUOjyzSMdzi0xMB8AbUHwBAAAAADxaWHCAJlzfVmvGXqMB7WId4z2mpOnTNRkmJgPg6TjjCwAAAADgVdZnnNYf31jpNDbnviuU2KyeSYkAuBNnfAEAAAAAfFbXxnX05QM9ncaGvv2zVu07aVIiAJ6KHV8AAAAAAK+UnV+s8V9t1YJtmY6xDg0j1a5BhDo2qq1be8TLYrGYmBBAdXClJ6L4AgAAAAB4tf+3YKfeXLav0vmdzw1QaFCAGxMBqE4UXwAAAAAAv1JSZlf6yQLtyszTG8v2acexXKf5yTe00509E8wJB6BKUXwBAAAAAPxaSZldQ99epQ0ZZxxj9WoG66eUq9n9BXg5DrcHAAAAAPi14ECrvnqwlz6/P8kxdrKgRK0nLFB+cZmJyQC4E8UXAAAAAMBndU+oq31TBql9w992hbSftFAfrEw3LxQAt6H4AgAAAAD4tACrRd8+3Ed3JjVxjE36ZpsSUlL1xbrDJiYDUN0ovgAAAAAAfmHyje31xm1dncae/HyTElJSNX/LMZNSAahOHG4PAAAAAPA7K/dla9is1U5jrWLC9fA1LXR9xwYmpQJwIfhURwAAAAAAzsMwDI2Zu0Wf/nKo3NyasdeofkSoCakAnA/FFwAAAAAAF8gwDC3fk607313jNN4qJlz/vKcHBRjgYSi+AAAAAAC4CAOmL9fOzLxy45smXafIsCATEgH4PYovAAAAAAAu0pbDObpx5grZK/jT8nsjuqtfq/ruDwXAgeILAAAAAIBLdDK/WHd/sFabDp0pNzduUBvd27eZ+0MBcKknsropEwAAAAAAXqVerRB9PaqX1o5PLjf3wvwdGj9viwmpALiCHV8AAAAAAFygX9JP6c9vrXIaOzB1kCwWi0mJAP/Dji8AAAAAAKpB94S6WvF0P6expmPma8zczfKCfSWA36H4AgAAAADABY3q1NDeFwY6jX2y5pCajpmvhz/ZoKJSm0nJAPwejzoCAAAAAHCR9mTl6a73ftGRM2edxv/crZGm/rGDAgPYbwJUNR51BAAAAADADS6LCdfi0X01uEOc0/jn6w6rxbjvNOK9NTqeW2RSOgDs+AIAAAAAoIocPFmgK19aVm782rYxmjX8cvcHAnwQO74AAAAAADBBk3o1lT5tsP79UG81jarpGF+8PUtPf7HZxGSAf2LHFwAAAAAA1eRAdoH6vbys3PjmZ65TRGiQ+wMBPoAdXwAAAAAAeICmUTW19Mmryo13fGaRElJS9dDH690fCvAjFF8AAAAAAFSjplG/Pv745QM9y819u/mYElJSdehUoQnJAN/Ho44AAAAAALjZ0p3HNeL9X5zG/n5rFw3p1MCkRID3cKUnovgCAAAAAMAEeUWluvnNldqdle80/nhySz2afJlJqQDPR/EFAAAAAICXWLIzS3e/v7bcePeEOvr0viQFWC0mpAI8F4fbAwAAAADgJa5uHaMDUwepf7sYp/Ff0k+r+dj5uv+f63SmsMSkdIB3Y8cXAAAAAAAeorCkTB+sPKj/t2BnhfN7XxiowAD2sMC/seMLAAAAAAAvVCM4UA9c1Vzp0wbrH3d0KzffYtx3WrgtU16whwXwCOz4AgAAAADAg5XZ7LrypWU6cuas0/iLN3fUX7rHm5QKMA87vgAAAAAA8BGBAVb9lHK1YiJCnMaf+nKzbnl7lUmpAO/Aji8AAAAAALzIgq3HdP9H653GwkMCldw2Rq8N7WxOKMCN2PEFAAAAAICPGtA+Tl+P6uU0lldcpq82HFFCSqryikpNSgZ4HnZ8AQAAAADghWx2Q++uOKCCkjJN/35PufmP7klU78uiTEgGVC9XeiKKLwAAAAAAfMADH63Td1szncYCrRbtnTLIpERA9eBRRwAAAAAA/Mybt3fTsiev0lWtoh1jZXZDCSmpWrXvpInJAPOw4wsAAAAAAB9jtxu68701+nFPttP4wsf6qlVsuEmpgKrBo44AAAAAAPi54jKbUr7coq82HCk3FxcZqgWP9lVkjSATkgGXhuILAAAAAABI+vUQ/Ps/WqfF27PKzVks0h86N9TUmzsoJDDAhHSA6yi+AAAAAABAORsyTusPb6yscO7Gzg304p86UoDB41F8AQAAAACAShWX2fTOjwf00sJd5eaGJTbWlD90MCEVcGEovgAAAAAAwAU5XVCiLs8tdhprGVNL3zzUW6FB7P6C53GlJ7K6KRMAAAAAAPBAdWoGK33aYG2aeJ1jbHdWvlpPWKBP12SYmAy4dBRfAAAAAABAkTWCtHVyf7Vv+NsOmpS5W3T1K8v0wcp0HT1z1sR0wMXhUUcAAAAAAOBk6a7jGvHeL+XGe7Wop3+NvMKERMBveNQRAAAAAABctH6t6mvpk1fp1h7xCg8NdIz/tPekElJSZbd7/B4aQBI7vgAAAAAAwHkUl9nUavwCp7FvH+6tdg0iZLFYTEoFf8WnOgIAAAAAgCpVVGpT6wkLKpz78al+iq9bw82J4K941BEAAAAAAFSp0KAApU8brOdval9urs+LS5WQkiov2FsDP3NRxdfMmTOVkJCg0NBQJSYmas2aNedcf+bMGY0aNUpxcXEKCQlRy5YtNX/+/IsKDAAAAAAAzHP7FU2UPm2wdj8/UIM6xDrNNR0zX2dLbCYlA8pzufiaM2eORo8erUmTJmn9+vXq1KmT+vfvr+PHj1e4vqSkRNdee63S09P1xRdfaNeuXZo1a5YaNmx4yeEBAAAAAIA5ggOteuO2btr53ACn8TYTF2jx9iyTUgHOXD7jKzExUd27d9eMGTMkSXa7XfHx8Xr44YeVkpJSbv1bb72ll156STt37lRQUNBFheSMLwAAAAAAPJdhGGo6pvyTXWvGXqP6EaEmJIIvq7YzvkpKSrRu3TolJyf/9g2sViUnJ2vVqlUV3vPNN98oKSlJo0aNUkxMjNq3b68pU6bIZqt862NxcbFyc3OdvgAAAAAAgGeyWCxKnzZY793V3Wm8x5Q03fJ2xX0B4A4uFV/Z2dmy2WyKiYlxGo+JiVFmZmaF9+zfv19ffPGFbDab5s+frwkTJuiVV17R888/X+nPmTp1qiIjIx1f8fHxrsQEAAAAAAAm6Ne6vjY/c50a1QlzjP28/5QSUlJVUFxmYjL4q2r/VEe73a769evr7bffVrdu3TR06FCNGzdOb731VqX3jBkzRjk5OY6vQ4cOVXdMAAAAAABQBSJCg7Ti6au1dnyy03i7SQs1Zu5mldnsJiWDPwp0ZXFUVJQCAgKUleV8SF1WVpZiY2MrvCcuLk5BQUEKCAhwjLVp00aZmZkqKSlRcHBwuXtCQkIUEhLiSjQAAAAAAOBBomqFaP+UQRr54Vot2fnrB+J9suaQPllzSCGBVr1xW1dd0ybmPN8FuDQu7fgKDg5Wt27dlJaW5hiz2+1KS0tTUlJShff06tVLe/fuld3+W6O7e/duxcXFVVh6AQAAAAAA32C1WvTuXd315QM9FR7y296b4jK77vlgrRJSUuXiZ+4BLnH5UcfRo0dr1qxZ+uCDD7Rjxw498MADKigo0IgRIyRJw4cP15gxYxzrH3jgAZ06dUqPPvqodu/erdTUVE2ZMkWjRo2qut8CAAAAAAB4rG5N6mjL5P56f0T3cnNNx8zXqYISE1LBH7j0qKMkDR06VCdOnNDEiROVmZmpzp07a8GCBY4D7zMyMmS1/tanxcfHa+HChXr88cfVsWNHNWzYUI8++qiefvrpqvstAAAAAACAx7uqVX2lTxssSerz4hIdOnVWktT1ucVa/td+alyvhpnx4IMshhfsKczNzVVkZKRycnIUERFhdhwAAAAAAFAFpn+/W9O/3+M0Nv+RPmrbgD/7o3Ku9ETV/qmOAAAAAAAAFXksuaXuv7K509igv/2oO2av5uwvVAmKLwAAAAAAYJqUga21+ZnrdF/fZo6xH/dkq+mY+Zq94oCJyeALeNQRAAAAAAB4hL3H85T86vJy498+3FvtG0aakAieiEcdAQAAAACA12lRP1zp0wZr6h87OI1f//cV+n8Ldspu9/i9O/AwFF8AAAAAAMCj3NqjsdKnDdatPeIdY28u26dmY+er1GY3MRm8DcUXAAAAAADwSFP/2FEzhnVxGrts3HcmpYE3ovgCAAAAAAAe6/qODZQ+bbDaN/ztLKeElFQ+9REXhOILAAAAAAB4vG8f7uN03XTMfJOSwJtQfAEAAAAAAK+QPm2w03VCSqqO5xWZlAbegOILAAAAAAB4jd+XXz1eSNNXGw6blAaejuILAAAAAAB4lfRpg/XgVc0d14/P2aTe/2+JiYngqSi+AAAAAACA13lqQGt9+UCS4/rw6bNKSEmVzc6h9/gNxRcAAAAAAPBK3ZrU1foJ1zqNNR/Loff4DcUXAAAAAADwWnVrBmv/lEFOY28s22tSGngaii8AAAAAAODVrFaL06H3Ly7YJcPgkUdQfAEAAAAAAB/x9ahejtdNx8znvC9QfAEAAAAAAN/QKb62OsfXdlw3HztfT32xSXlFpeaFgqkovgAAAAAAgM/46sGeahZd03H92drD6vDMIq07eNrEVDALxRcAAAAAAPAZFotFS564St8+3FuDO8Y5xm9+c6W2HM4xMRnMQPEFAAAAAAB8TvuGkZo5rKtmDuvqGBsyY4VeXrjLxFRwN4ovAAAAAADgswZ3jNMjV7dwXM9YupdD7/0IxRcAAAAAAPBpo69rpbkP9nRcNx8738Q0cCeKLwAAAAAA4PO6Nq6jujWDHdcPfbzexDRwF4ovAAAAAADgF9aNT3a8/nbzMf31800mpoE7UHwBAAAAAAC/YLFYtHHitY7rz9cd1q1v/6yT+cUmpkJ1ovgCAAAAAAB+o3aNYH33aB/H9ar9J9Xt+e81YPpyZeYUmZgM1YHiCwAAAAAA+JU2cRFaPfYaXdc2xjG2MzNPV0xN08erM0xMhqpG8QUAAAAAAPxOTESo3h5+uT66J1GRYUGO8bFfbdGSnVkmJkNVshiGYZgd4nxyc3MVGRmpnJwcRUREmB0HAAAAAAD4mK1HcnT931c4rrs1qaMvH+hpYiJUxpWeiB1fAAAAAADA77VvGKmP7010XK87eFqvLt5tYiJUBYovAAAAAAAAST2bRyn1kd6O67+l7dGerDwTE+FSUXwBAAAAAAD8R7sGkfr24d/Kr2tfWy6b3eNPiUIlKL4AAAAAAAD+R/uGkXrgquaO6+Zj55uYBpeC4gsAAAAAAOB3nh7QWjd3beS4TkhJlRd8PiB+h+ILAAAAAACgAq/8pZPTddMx8ym/vAzFFwAAAAAAQCV2PDtAAVaL47r9pIUmpoGrKL4AAAAAAAAqERYcoH1TBjmuC0psGjB9uYmJ4AqKLwAAAAAAgPPY/z/l187MPM1cutfENLhQFF8AAAAAAADnYbVatOv5AY7rlxbu0v4T+SYmwoWg+AIAAAAAALgAIYEBWjs+2XF99Ss/aMexXBMT4XwovgAAAAAAAC5QVK0QvXdXd8f1wNd/VH5xmYmJcC4UXwAAAAAAAC7o17q+/n5rF8d1+0kLlXO21MREqAzFFwAAAAAAgIuGdGqg+69s7rjuNHmRiWlQGYovAAAAAACAi5AysLWGdGrguD5TWGJiGlSE4gsAAAAAAOAivfaXTo7XnZ9drKJSm4lp8HsUXwAAAAAAABcpMMCq2xIbO65bT1hgYhr8HsUXAAAAAADAJXjhDx10U+ffHnlMSEk1MQ3+F8UXAAAAAADAJZp+Sxen6zvfXWNSEvwvii8AAAAAAIAqsHHitY7XP+w+oTKb3cQ0kCi+AAAAAAAAqkTtGsH66sGejusR7/9iYhpIFF8AAAAAAABVpkvjOo7XP+7J1p6sPBPTgOILAAAAAACgCi1+vK/j9bWvLTcxCSi+AAAAAAAAqtBlMeEaP7iN4zrly80mpvFvFF8AAAAAAABVbGSfZo7X3+84bmIS/0bxBQAAAAAAUA3+eU8PSVJ2frHJSfwXxRcAAAAAAEA16J5Q1/F65Ad8wqMZKL4AAAAAAACqQWhQgOP19zuOq9RmNzGNf6L4AgAAAAAAqCZLnrjS8fqycd8pv7jMxDT+h+ILAAAAAACgmjSLrqURvRIc17e8vcq8MH6I4gsAAAAAAKAaTRrSTuMGtZEkbT2SqxcX7DQ5kf+g+AIAAAAAAKhm9/Zt5nj9xrJ9JibxLxRfAAAAAAAAbpD2P+d9TZm/w8Qk/oPiCwAAAAAAwA2aR9dyvH57+X5l5hSZmMY/UHwBAAAAAAC4yQd393C8vmJqmolJ/APFFwAAAAAAgJtc2TJaneNrO64/W3vIvDB+gOILAAAAAADAjeaN6uV4/dQXm01M4vsovgAAAAAAANzss/9Lcry+7rUfTEzi2yi+AAAAAAAA3KxH07qO17uz8lVUajMxje+i+AIAAAAAADDB2vHJjtd9X1xqYhLfRfEFAAAAAABggqhaIbqqVbQk6XhesXLOlpqcyPdQfAEAAAAAAJjkvbu6O153mrzIxCS+ieILAAAAAADAJBaLRc2iajquV+7LNjGN76H4AgAAAAAAMFHaE1c6Xg+btVqGYZiYxrdQfAEAAAAAAJjIYrHo7Tu6Oa73Hs83MY1vofgCAAAAAAAw2XXtYh2vr31tuYlJfAvFFwAAAAAAgAcY3DHO8XrB1mMmJvEdFF8AAAAAAAAeYOawro7Xoz/bZGIS33FRxdfMmTOVkJCg0NBQJSYmas2aNZWuff/992WxWJy+QkNDLzowAAAAAACArxqW2FiSVFhi45D7KuBy8TVnzhyNHj1akyZN0vr169WpUyf1799fx48fr/SeiIgIHTt2zPF18ODBSwoNAAAAAADgi+7p3dTxeuxXW01M4htcLr5effVV3XvvvRoxYoTatm2rt956SzVq1NC7775b6T0Wi0WxsbGOr5iYmEsKDQAAAAAA4IuaR9dyvP5kTQa7vi6RS8VXSUmJ1q1bp+Tk5N++gdWq5ORkrVq1qtL78vPz1aRJE8XHx+vGG2/Utm3bzvlziouLlZub6/QFAAAAAADgD758oKfj9fOpO0xM4v1cKr6ys7Nls9nK7diKiYlRZmZmhfe0atVK7777rr7++mt99NFHstvt6tmzpw4fPlzpz5k6daoiIyMdX/Hx8a7EBAAAAAAA8FrdmtRxvH73pwMmJvF+1f6pjklJSRo+fLg6d+6sK6+8UnPnzlV0dLT+8Y9/VHrPmDFjlJOT4/g6dOhQdccEAAAAAADwGPdf2VySVCMowOQk3s2l4isqKkoBAQHKyspyGs/KylJsbOwFfY+goCB16dJFe/furXRNSEiIIiIinL4AAAAAAAD8xY2dG0iSCkpsstk55+tiuVR8BQcHq1u3bkpLS3OM2e12paWlKSkp6YK+h81m05YtWxQXF+daUgAAAAAAAD/Rov5vh9z/a/VBE5N4N5cfdRw9erRmzZqlDz74QDt27NADDzyggoICjRgxQpI0fPhwjRkzxrH+2Wef1aJFi7R//36tX79et99+uw4ePKiRI0dW3W8BAAAAAADgQ4ICfqtsJn597g8JROUCXb1h6NChOnHihCZOnKjMzEx17txZCxYscBx4n5GRIav1t/9yTp8+rXvvvVeZmZmqU6eOunXrppUrV6pt27ZV91sAAAAAAAD4mElD2mryv7dLkvKLy1QrxOUax+9ZDMPw+AdFc3NzFRkZqZycHM77AgAAAAAAfsFmN9R87HxJUu8WUfpoZKLJiTyDKz1RtX+qIwAAAAAAAFwXYLUo0GqRJK3Ym21yGu9E8QUAAAAAAOChpt3c0fG6z4tLTEzinSi+AAAAAAAAPNSQTnGO14dOnVVeUamJabwPxRcAAAAAAICHCgkM0M9jrnFcv7p4t4lpvA/FFwAAAAAAgAeLjQx1vP5xD2d9uYLiCwAAAAAAwMONG9RGknjU0UUUXwAAAAAAAB6uW0IdSVJWbrH2ZOWZnMZ7UHwBAAAAAAB4uLZxEY7X1762XHa7YWIa70HxBQAAAAAA4OFCgwI04fq2jus73l1tYhrvQfEFAAAAAADgBe7p3VQWy6+vf9p7UunZBeYG8gIUXwAAAAAAAF5i2ZNXOV6/vGiXeUG8BMUXAAAAAACAl2hSr6b+1K2RJOnbzcdkGJz1dS4UXwAAAAAAAF7k//o2c7xevD3LxCSej+ILAAAAAADAi1wWE+54/eC/1puYxPNRfAEAAAAAAHiZYYmNJUlldkMn8opNTuO5KL4AAAAAAAC8zPM3tne8/nh1holJPBvFFwAAAAAAgJexWi1q9Z9HHj9ec9DkNJ6L4gsAAAAAAMALDewQK0nKyi3WvhP5JqfxTBRfAAAAAAAAXmh4UoLj9Zi5W8wL4sEovgAAAAAAALxQ3ZrBuqFTA0nSmgOnTE7jmSi+AAAAAAAAvNTUP3ZwvD5VUGJiEs9E8QUAAAAAAOClaoYEOl4/9PF6E5N4JoovAAAAAAAAL1anRpAkaeW+k9p8+Iy5YTwMxRcAAAAAAIAXe+fO7o7XN8z4ycQknofiCwAAAAAAwIt1a1JH9cNDHNebDp0xL4yHofgCAAAAAADwcj+Pucbx+saZ7Pr6L4ovAAAAAAAAL2e1WnRz10aO6zKb3cQ0noPiCwAAAAAAwAdM/WMHx+u5G46YmMRzUHwBAAAAAAD4gOBAq4ICLJKkp77YbHIaz0DxBQAAAAAA4CNmDOvqeL31SI6JSTwDxRcAAAAAAICP6N8u1vF6zNwtJibxDBRfAAAAAAAAPmRYYmNJ0pYjOSoqtZmcxlwUXwAAAAAAAD7kqf6tfnvt52d9UXwBAAAAAAD4kNo1ghUZFiRJ+mbTUZPTmIviCwAAAAAAwMekDGzteL3u4GkTk5iL4gsAAAAAAMDH3Ny1keP1iwt2mpjEXBRfAAAAAAAAPiY40KrGdWtIkg5kF5icxjwUXwAAAAAAAD7opi4NJUmXxdQyOYl5KL4AAAAAAAB8UOvYcElSaZlhchLzUHwBAAAAAAD4oOCAX2ufNemnTE5iHoovAAAAAAAAHxQWHCBJslhMDmIiii8AAAAAAAAf1LB2mCTJMKQym93kNOag+AIAAAAAAPBBDeuEOV6fLCgxMYl5KL4AAAAAAAB8UFDAb7XPom2ZJiYxD8UXAAAAAACAj/rvAfcWPz3oi+ILAAAAAADAR43onaA2cRGqFRJodhRTWAzDMMwOcT65ubmKjIxUTk6OIiIizI4DAAAAAAAAk7jSE7HjCwAAAAAAAD6J4gsAAAAAAAA+ieILAAAAAAAAPoniCwAAAAAAAD6J4gsAAAAAAAA+ieILAAAAAAAAPoniCwAAAAAAAD6J4gsAAAAAAAA+ieILAAAAAAAAPoniCwAAAAAAAD6J4gsAAAAAAAA+ieILAAAAAAAAPoniCwAAAAAAAD6J4gsAAAAAAAA+ieILAAAAAAAAPoniCwAAAAAAAD6J4gsAAAAAAAA+ieILAAAAAAAAPoniCwAAAAAAAD6J4gsAAAAAAAA+ieILAAAAAAAAPinQ7AAXwjAMSVJubq7JSQAAAAAAAGCm//ZD/+2LzsUriq+8vDxJUnx8vMlJAAAAAAAA4Any8vIUGRl5zjUW40LqMZPZ7XYdPXpU4eHhslgsZsepErm5uYqPj9ehQ4cUERFhdhzAa/FeAqoG7yWg6vB+AqoG7yWgavjie8kwDOXl5alBgwayWs99ipdX7PiyWq1q1KiR2TGqRUREhM/8Dw8wE+8loGrwXgKqDu8noGrwXgKqhq+9l8630+u/ONweAAAAAAAAPoniCwAAAAAAAD6J4sskISEhmjRpkkJCQsyOAng13ktA1eC9BFQd3k9A1eC9BFQNf38vecXh9gAAAAAAAICr2PEFAAAAAAAAn0TxBQAAAAAAAJ9E8QUAAAAAAACfRPEFAAAAAAAAn0TxBQAAAAAAAJ9E8VWNZs6cqYSEBIWGhioxMVFr1qw55/rPP/9crVu3VmhoqDp06KD58+e7KSng2Vx5L82aNUt9+vRRnTp1VKdOHSUnJ5/3vQf4C1f/vfRfn376qSwWi2666abqDQh4EVffT2fOnNGoUaMUFxenkJAQtWzZkv+vB8j199L06dPVqlUrhYWFKT4+Xo8//riKiorclBbwTMuXL9eQIUPUoEEDWSwWzZs377z3LFu2TF27dlVISIhatGih999/v9pzmoXiq5rMmTNHo0eP1qRJk7R+/Xp16tRJ/fv31/Hjxytcv3LlSt1666265557tGHDBt1000266aabtHXrVjcnBzyLq++lZcuW6dZbb9XSpUu1atUqxcfH67rrrtORI0fcnBzwLK6+l/4rPT1dTz75pPr06eOmpIDnc/X9VFJSomuvvVbp6en64osvtGvXLs2aNUsNGzZ0c3LAs7j6Xvr444+VkpKiSZMmaceOHZo9e7bmzJmjsWPHujk54FkKCgrUqVMnzZw584LWHzhwQIMHD1a/fv20ceNGPfbYYxo5cqQWLlxYzUnNYTEMwzA7hC9KTExU9+7dNWPGDEmS3W5XfHy8Hn74YaWkpJRbP3ToUBUUFOjbb791jF1xxRXq3Lmz3nrrLbflBjyNq++l37PZbKpTp45mzJih4cOHV3dcwGNdzHvJZrOpb9++uvvuu/Xjjz/qzJkzF/Q3iICvc/X99NZbb+mll17Szp07FRQU5O64gMdy9b300EMPaceOHUpLS3OMPfHEE1q9erVWrFjhttyAJ7NYLPrqq6/OuVP/6aefVmpqqtNGm1tuuUVnzpzRggUL3JDSvdjxVQ1KSkq0bt06JScnO8asVquSk5O1atWqCu9ZtWqV03pJ6t+/f6XrAX9wMe+l3yssLFRpaanq1q1bXTEBj3ex76Vnn31W9evX1z333OOOmIBXuJj30zfffKOkpCSNGjVKMTExat++vaZMmSKbzeau2IDHuZj3Us+ePbVu3TrH45D79+/X/PnzNWjQILdkBnyFv/UPgWYH8EXZ2dmy2WyKiYlxGo+JidHOnTsrvCczM7PC9ZmZmdWWE/B0F/Ne+r2nn35aDRo0KPcPdsCfXMx7acWKFZo9e7Y2btzohoSA97iY99P+/fu1ZMkS3XbbbZo/f7727t2rBx98UKWlpZo0aZI7YgMe52LeS8OGDVN2drZ69+4twzBUVlam+++/n0cdARdV1j/k5ubq7NmzCgsLMylZ9WDHFwCfNW3aNH366af66quvFBoaanYcwGvk5eXpjjvu0KxZsxQVFWV2HMDr2e121a9fX2+//ba6deumoUOHaty4cRxnAbho2bJlmjJlit544w2tX79ec+fOVWpqqp577jmzowHwYOz4qgZRUVEKCAhQVlaW03hWVpZiY2MrvCc2Ntal9YA/uJj30n+9/PLLmjZtmr7//nt17NixOmMCHs/V99K+ffuUnp6uIUOGOMbsdrskKTAwULt27VLz5s2rNzTgoS7m301xcXEKCgpSQECAY6xNmzbKzMxUSUmJgoODqzUz4Iku5r00YcIE3XHHHRo5cqQkqUOHDiooKNB9992ncePGyWplXwdwISrrHyIiInxut5fEjq9qERwcrG7dujkdumi325WWlqakpKQK70lKSnJaL0mLFy+udD3gDy7mvSRJL774op577jktWLBAl19+uTuiAh7N1fdS69attWXLFm3cuNHxdcMNNzg++Sc+Pt6d8QGPcjH/burVq5f27t3rKJAlaffu3YqLi6P0gt+6mPdSYWFhuXLrv4Uyn9kGXDi/6x8MVItPP/3UCAkJMd5//31j+/btxn333WfUrl3byMzMNAzDMO644w4jJSXFsf6nn34yAgMDjZdfftnYsWOHMWnSJCMoKMjYsmWLWb8C4BFcfS9NmzbNCA4ONr744gvj2LFjjq+8vDyzfgXAI7j6Xvq9O++807jxxhvdlBbwbK6+nzIyMozw8HDjoYceMnbt2mV8++23Rv369Y3nn3/erF8B8AiuvpcmTZpkhIeHG5988omxf/9+Y9GiRUbz5s2Nv/zlL2b9CoBHyMvLMzZs2GBs2LDBkGS8+uqrxoYNG4yDBw8ahmEYKSkpxh133OFYv3//fqNGjRrGX//6V2PHjh3GzJkzjYCAAGPBggVm/QrVikcdq8nQoUN14sQJTZw4UZmZmercubMWLFjgOEAuIyPD6W8revbsqY8//ljjx4/X2LFjddlll2nevHlq3769Wb8C4BFcfS+9+eabKikp0Z/+9Cen7zNp0iQ988wz7owOeBRX30sAKufq+yk+Pl4LFy7U448/ro4dO6phw4Z69NFH9fTTT5v1KwAewdX30vjx42WxWDR+/HgdOXJE0dHRGjJkiF544QWzfgXAI6xdu1b9+vVzXI8ePVqSdOedd+r999/XsWPHlJGR4Zhv2rSpUlNT9fjjj+v1119Xo0aN9M4776h///5uz+4OFsNgTygAAAAAAAB8D3+1CwAAAAAAAJ9E8QUAAAAAAACfRPEFAAAAAAAAn0TxBQAAAAAAAJ9E8QUAAAAAAACfRPEFAAAAAAAAn0TxBQAAAAAAAJ9E8QUAAAAAAACfRPEFAAAAAAAAn0TxBQAAAAAAAJ9E8QUAAAAAAACf9P8B4DqtIWRGDukAAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:00:34.257421Z","iopub.execute_input":"2023-05-30T20:00:34.258265Z","iopub.status.idle":"2023-05-30T20:00:34.263871Z","shell.execute_reply.started":"2023-05-30T20:00:34.258231Z","shell.execute_reply":"2023-05-30T20:00:34.263006Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, dataloader):\n    pred_list = []\n    model.eval()\n\n    \n    with torch.no_grad():\n        for feats, _ in tqdm(dataloader):\n            feats = feats.to(device)\n            pred = model(feats)          \n            pred_list.extend([prob1 for prob0, prob1 in pred.tolist()])\n\n    return pred_list","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:00:34.622839Z","iopub.status.idle":"2023-05-30T20:00:34.623679Z","shell.execute_reply.started":"2023-05-30T20:00:34.623443Z","shell.execute_reply":"2023-05-30T20:00:34.623467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dist_score_list = eval_model(net_model, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:03:53.538161Z","iopub.execute_input":"2023-05-30T20:03:53.540874Z","iopub.status.idle":"2023-05-30T20:03:53.880815Z","shell.execute_reply.started":"2023-05-30T20:03:53.540839Z","shell.execute_reply":"2023-05-30T20:03:53.879848Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  3.05it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test[\"scores\"] = dist_score_list","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:03:53.882731Z","iopub.execute_input":"2023-05-30T20:03:53.883081Z","iopub.status.idle":"2023-05-30T20:03:53.892384Z","shell.execute_reply.started":"2023-05-30T20:03:53.883047Z","shell.execute_reply":"2023-05-30T20:03:53.891158Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"pr_auc_macro_metr = pr_auc_macro(\n    target_df=y_test, \n    predictions_df=X_test,\n    prec_level=0.75,\n    cat_column=\"cat3_grouped\"\n)\n\npr_auc_macro_metr","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:03:55.886255Z","iopub.execute_input":"2023-05-30T20:03:55.886640Z","iopub.status.idle":"2023-05-30T20:03:56.211872Z","shell.execute_reply.started":"2023-05-30T20:03:55.886611Z","shell.execute_reply":"2023-05-30T20:03:56.210977Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"0.1652410212832041"},"metadata":{}}]},{"cell_type":"code","source":"precision, recall, thrs = precision_recall_curve(y_test[\"target\"], X_test[\"scores\"])\npr_auc = auc(recall, precision)\n\nfig, ax1 = plt.subplots(1, figsize=(15, 7))\n\nax1.plot(recall, precision)\nax1.axhline(y=0.75, color='grey', linestyle='-');","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:30:42.074029Z","start_time":"2023-05-19T06:30:41.619959Z"},"execution":{"iopub.status.busy":"2023-05-30T20:03:57.662102Z","iopub.execute_input":"2023-05-30T20:03:57.662485Z","iopub.status.idle":"2023-05-30T20:03:58.005984Z","shell.execute_reply.started":"2023-05-30T20:03:57.662455Z","shell.execute_reply":"2023-05-30T20:03:58.004918Z"},"trusted":true},"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x700 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_siam_model(model, device, test_loader):\n    pred_list = []\n    model.eval()\n    \n    with torch.no_grad():\n        for (images_1, images_2, targets) in test_loader:\n            images_1, images_2 = images_1.to(device), images_2.to(device)\n            outputs = model(images_1, images_2).squeeze()\n            pred_list.extend(outputs.tolist())\n    return pred_list","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:04:00.571554Z","iopub.execute_input":"2023-05-30T20:04:00.571920Z","iopub.status.idle":"2023-05-30T20:04:00.580411Z","shell.execute_reply.started":"2023-05-30T20:04:00.571890Z","shell.execute_reply":"2023-05-30T20:04:00.579455Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"siam_score_list = test_siam_model(siam_imgs_net, device, siam_test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:04:02.152429Z","iopub.execute_input":"2023-05-30T20:04:02.152804Z","iopub.status.idle":"2023-05-30T20:04:02.911422Z","shell.execute_reply.started":"2023-05-30T20:04:02.152775Z","shell.execute_reply":"2023-05-30T20:04:02.910340Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"X_test[\"scores\"] = siam_score_list","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:04:13.228124Z","iopub.execute_input":"2023-05-30T20:04:13.228491Z","iopub.status.idle":"2023-05-30T20:04:13.240068Z","shell.execute_reply.started":"2023-05-30T20:04:13.228461Z","shell.execute_reply":"2023-05-30T20:04:13.237551Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"pr_auc_macro_metr = pr_auc_macro(\n    target_df=y_test, \n    predictions_df=X_test,\n    prec_level=0.75,\n    cat_column=\"cat3_grouped\"\n)\n\npr_auc_macro_metr","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:04:23.951381Z","iopub.execute_input":"2023-05-30T20:04:23.951737Z","iopub.status.idle":"2023-05-30T20:04:24.269662Z","shell.execute_reply.started":"2023-05-30T20:04:23.951709Z","shell.execute_reply":"2023-05-30T20:04:24.268725Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"0.27173954695949615"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Создадим метадатасет**","metadata":{}},{"cell_type":"code","source":"all_scores_list = [dist_score_list, boosting_scores, siam_score_list, list(X_test['main_cos_dist'])]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:08:32.445390Z","iopub.execute_input":"2023-05-30T21:08:32.445883Z","iopub.status.idle":"2023-05-30T21:08:32.460409Z","shell.execute_reply.started":"2023-05-30T21:08:32.445845Z","shell.execute_reply":"2023-05-30T21:08:32.459319Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"class MetaDataset(Dataset):\n    def __init__(self, all_scores: List[Iterable[float]],\n                 target_df: pd.DataFrame):\n        \"\"\"\n        Args:\n            dist_df: dataframe that contains only columns representing\n            distances between properties of a product pair and 'target' column\n            that equals 1 if the pair is same product, otherwise 0\n        \"\"\"\n        self.features = list(zip(*all_scores))\n        self.labels = list(target_df)\n    def __len__(self):\n        return len(self.features)\n    def __getitem__(self, idx):\n        inp = torch.tensor(self.features[idx], dtype = torch.float32)\n        label = self.labels[idx]\n        return inp, label","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:08:33.179118Z","iopub.execute_input":"2023-05-30T21:08:33.179699Z","iopub.status.idle":"2023-05-30T21:08:33.187731Z","shell.execute_reply.started":"2023-05-30T21:08:33.179665Z","shell.execute_reply":"2023-05-30T21:08:33.186671Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"metadataset = MetaDataset(all_scores_list, y_test['target'])","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:08:33.806575Z","iopub.execute_input":"2023-05-30T21:08:33.807315Z","iopub.status.idle":"2023-05-30T21:08:33.826807Z","shell.execute_reply.started":"2023-05-30T21:08:33.807247Z","shell.execute_reply":"2023-05-30T21:08:33.825896Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"metadataset[3]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:08:34.258718Z","iopub.execute_input":"2023-05-30T21:08:34.259079Z","iopub.status.idle":"2023-05-30T21:08:34.268800Z","shell.execute_reply.started":"2023-05-30T21:08:34.259050Z","shell.execute_reply":"2023-05-30T21:08:34.267696Z"},"trusted":true},"execution_count":156,"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"(tensor([0.0003, 0.0832, 0.1055, 0.0000]), 0.0)"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"metadataset[3][0]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:08:38.864141Z","iopub.execute_input":"2023-05-30T21:08:38.864992Z","iopub.status.idle":"2023-05-30T21:08:38.872929Z","shell.execute_reply.started":"2023-05-30T21:08:38.864956Z","shell.execute_reply":"2023-05-30T21:08:38.872000Z"},"trusted":true},"execution_count":157,"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"tensor([0.0003, 0.0832, 0.1055, 0.0000])"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset[3][0]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:08:40.058066Z","iopub.execute_input":"2023-05-30T21:08:40.058786Z","iopub.status.idle":"2023-05-30T21:08:40.067110Z","shell.execute_reply.started":"2023-05-30T21:08:40.058751Z","shell.execute_reply":"2023-05-30T21:08:40.066184Z"},"trusted":true},"execution_count":158,"outputs":[{"execution_count":158,"output_type":"execute_result","data":{"text/plain":"tensor([0.0000e+00, 4.7200e+00, 5.4392e+00, 4.1154e-01, 5.1291e-03, 0.0000e+00,\n        0.0000e+00])"},"metadata":{}}]},{"cell_type":"markdown","source":"**Попробуем сделать метамодель**","metadata":{}},{"cell_type":"code","source":"epox_num = 30\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nmetamodel = Mega_model(len(all_scores_list)).to(device)\n\noptimizer_meta = torch.optim.Adam(metamodel.parameters(), lr=3e-3)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:09:48.094726Z","iopub.execute_input":"2023-05-30T21:09:48.095082Z","iopub.status.idle":"2023-05-30T21:09:48.104801Z","shell.execute_reply.started":"2023-05-30T21:09:48.095052Z","shell.execute_reply":"2023-05-30T21:09:48.103832Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"meta_dataloader = DataLoader(metadataset, batch_size=100, shuffle=False, drop_last=False)\ndataloaders_meta = {phase: meta_dataloader for phase in ['train', 'val']}","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:09:50.308684Z","iopub.execute_input":"2023-05-30T21:09:50.309045Z","iopub.status.idle":"2023-05-30T21:09:50.316895Z","shell.execute_reply.started":"2023-05-30T21:09:50.309016Z","shell.execute_reply":"2023-05-30T21:09:50.315998Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"loss, acc, rec_1 = train_model(metamodel, criterion, optimizer_meta, epox_num, dataloaders_meta)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:09:51.365077Z","iopub.execute_input":"2023-05-30T21:09:51.365472Z","iopub.status.idle":"2023-05-30T21:10:11.855631Z","shell.execute_reply.started":"2023-05-30T21:09:51.365442Z","shell.execute_reply":"2023-05-30T21:10:11.854171Z"},"trusted":true},"execution_count":167,"outputs":[{"name":"stdout","text":"Epoch 1/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 395.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.6018, acc: 0.7079, rec_1: 0.7079\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 757.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5249, acc: 0.7449, rec_1: 0.7449\nEpoch 2/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 447.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5172, acc: 0.7835, rec_1: 0.7835\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 735.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5142, acc: 0.7850, rec_1: 0.7850\nEpoch 3/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 434.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5140, acc: 0.7861, rec_1: 0.7861\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 763.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5134, acc: 0.7860, rec_1: 0.7860\nEpoch 4/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 439.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5137, acc: 0.7862, rec_1: 0.7862\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 744.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5132, acc: 0.7857, rec_1: 0.7857\nEpoch 5/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 440.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5136, acc: 0.7860, rec_1: 0.7860\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 608.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5132, acc: 0.7858, rec_1: 0.7858\nEpoch 6/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 430.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5136, acc: 0.7857, rec_1: 0.7857\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 768.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5132, acc: 0.7857, rec_1: 0.7857\nEpoch 7/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 437.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5136, acc: 0.7858, rec_1: 0.7858\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 762.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5132, acc: 0.7858, rec_1: 0.7858\nEpoch 8/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 446.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5136, acc: 0.7857, rec_1: 0.7857\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 773.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5132, acc: 0.7857, rec_1: 0.7857\nEpoch 9/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 443.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5136, acc: 0.7857, rec_1: 0.7857\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 759.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5132, acc: 0.7857, rec_1: 0.7857\nEpoch 10/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 403.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5136, acc: 0.7857, rec_1: 0.7857\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 741.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5131, acc: 0.7857, rec_1: 0.7857\nEpoch 11/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 439.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5135, acc: 0.7857, rec_1: 0.7857\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 771.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5131, acc: 0.7857, rec_1: 0.7857\nEpoch 12/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 445.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5135, acc: 0.7856, rec_1: 0.7856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 765.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5131, acc: 0.7857, rec_1: 0.7857\nEpoch 13/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 443.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5135, acc: 0.7856, rec_1: 0.7856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 757.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5131, acc: 0.7857, rec_1: 0.7857\nEpoch 14/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 445.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5135, acc: 0.7857, rec_1: 0.7857\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 755.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"val loss: 0.5131, acc: 0.7857, rec_1: 0.7857\nEpoch 15/30\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 442.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5135, acc: 0.7856, rec_1: 0.7856\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 766.54it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[167], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss, acc, rec_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetamodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepox_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders_meta\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[66], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs, dataset)\u001b[0m\n\u001b[1;32m     36\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset[phase])\n\u001b[1;32m     37\u001b[0m epoch_acc \u001b[38;5;241m=\u001b[39m accuracy_score(target, pred_list)\n\u001b[0;32m---> 38\u001b[0m epoch_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmicro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, rec_1: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(phase,\n\u001b[1;32m     40\u001b[0m                                             epoch_loss,\n\u001b[1;32m     41\u001b[0m                                             epoch_acc, \n\u001b[1;32m     42\u001b[0m                                             epoch_f1\n\u001b[1;32m     43\u001b[0m                                             ))\n\u001b[1;32m     44\u001b[0m loss_list[phase]\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[1;32m   1012\u001b[0m     y_true,\n\u001b[1;32m   1013\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1020\u001b[0m ):\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[1;32m   1159\u001b[0m     y_true,\n\u001b[1;32m   1160\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1168\u001b[0m ):\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:87\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 87\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/multiclass.py:329\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y):\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"**Посчитаем метрику на метамодели (что не очень честно, потому что она обучалсь на тех же данных, на которых мы метрику считаем**","metadata":{}},{"cell_type":"code","source":"metamodel_out_scores = eval_model(metamodel, meta_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:10:18.294185Z","iopub.execute_input":"2023-05-30T21:10:18.295402Z","iopub.status.idle":"2023-05-30T21:10:18.944045Z","shell.execute_reply.started":"2023-05-30T21:10:18.295363Z","shell.execute_reply":"2023-05-30T21:10:18.943040Z"},"trusted":true},"execution_count":168,"outputs":[{"name":"stderr","text":"100%|██████████| 307/307 [00:00<00:00, 485.96it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test[\"scores\"] = metamodel_out_scores","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:10:18.945942Z","iopub.execute_input":"2023-05-30T21:10:18.946584Z","iopub.status.idle":"2023-05-30T21:10:18.979223Z","shell.execute_reply.started":"2023-05-30T21:10:18.946550Z","shell.execute_reply":"2023-05-30T21:10:18.974713Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"pr_auc_macro_metr = pr_auc_macro(\n    target_df=y_test, \n    predictions_df=X_test,\n    prec_level=0.75,\n    cat_column=\"cat3_grouped\"\n)\n\npr_auc_macro_metr","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:10:19.234935Z","iopub.execute_input":"2023-05-30T21:10:19.237602Z","iopub.status.idle":"2023-05-30T21:10:19.710277Z","shell.execute_reply.started":"2023-05-30T21:10:19.237560Z","shell.execute_reply":"2023-05-30T21:10:19.709209Z"},"trusted":true},"execution_count":170,"outputs":[{"execution_count":170,"output_type":"execute_result","data":{"text/plain":"0.4523775797282634"},"metadata":{}}]},{"cell_type":"code","source":"precision, recall, thrs = precision_recall_curve(y_test[\"target\"], X_test[\"scores\"])\npr_auc = auc(recall, precision)\n\nfig, ax1 = plt.subplots(1, figsize=(15, 7))\n\nax1.plot(recall, precision)\nax1.axhline(y=0.75, color='grey', linestyle='-');","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:30:42.074029Z","start_time":"2023-05-19T06:30:41.619959Z"},"execution":{"iopub.status.busy":"2023-05-30T21:10:19.892044Z","iopub.execute_input":"2023-05-30T21:10:19.892579Z","iopub.status.idle":"2023-05-30T21:10:20.302310Z","shell.execute_reply.started":"2023-05-30T21:10:19.892533Z","shell.execute_reply":"2023-05-30T21:10:20.301446Z"},"trusted":true},"execution_count":171,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x700 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABL4AAAJGCAYAAABV80xCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABei0lEQVR4nO3dd3xUZaLG8Wdmkkx6CJBCCQRCCR2lxCAgaBCFRV1dRd0VG7piWZUtBqXZgF3Xtgu7KnZdV+x6Nwgoioo0aQpID6GEFAKkkzZz7h+uo1mSkIFkzszk9/188rnnvOc9k2f2ehQf33OOxTAMQwAAAAAAAICfsZodAAAAAAAAAGgOFF8AAAAAAADwSxRfAAAAAAAA8EsUXwAAAAAAAPBLFF8AAAAAAADwSxRfAAAAAAAA8EsUXwAAAAAAAPBLAWYHaAyn06nDhw8rIiJCFovF7DgAAAAAAAAwiWEYKikpUfv27WW1NrymyyeKr8OHDyshIcHsGAAAAAAAAPASBw8eVMeOHRuc4xPFV0REhKQfvlBkZKTJaQAAAAAAAGCW4uJiJSQkuPqihvhE8fXj7Y2RkZEUXwAAAAAAAGjU47B4uD0AAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPyS28XXl19+qQkTJqh9+/ayWCz64IMPTnnOihUrdPbZZ8tut6tbt256+eWXTyMqAAAAAAAA0HhuF19lZWUaMGCAFixY0Kj5+/bt0/jx4zV69Ght3rxZ99xzjyZPnqylS5e6HRYAAAAAAABorAB3T7j44ot18cUXN3r+M888oy5duujxxx+XJPXq1UsrV67Uk08+qbFjx7r76/3CwWPl2n+03LUfE2FXz/gIExMBAAAAAAD4H7eLL3etXr1aaWlptcbGjh2re+65p95zKisrVVlZ6dovLi5urnim+HBztv66bFetsXenpGpQ59YmJQIAAAAAAPA/zf5w+9zcXMXFxdUai4uLU3FxsU6cOFHnOXPnzlVUVJTrJyEhobljelSbcLuS4yOUHB+hcPsP3ePe/DKTUwEAAAAAAPgXr3yr47Rp01RUVOT6OXjwoNmRmtQ1QztpyT0jteSekRrVM0aSVFpZY3IqAAAAAAAA/9LstzrGx8crLy+v1lheXp4iIyMVEhJS5zl2u112u725o3mFH1d8lVF8AQAAAAAANKlmL75SU1O1ePHiWmOffPKJUlNTm/tX+4Qfi6/mWvF1osqh3fkl2pVXqt15JdqdX6qcogrdfUF3XdQ3vll+JwAAAAAAgDdwu/gqLS3Vnj17XPv79u3T5s2b1bp1a3Xq1EnTpk1Tdna2Xn31VUnSbbfdpvnz5+tPf/qTbrrpJn322Wd66623lJGR0XTfwoeFNaL42pVXon+u2KvcogrNv/YstQmvfzVcXnGF1mQe1cb9x7XhwHFtzymRw2mcNO9fa/frnK6ttSuvVDvzSrQrt0THy6t030XJSmgdeuZfDAAAAAAAwGRuF1/r16/X6NGjXftTp06VJF1//fV6+eWXlZOTowMHDriOd+nSRRkZGbr33nv19NNPq2PHjnr++ec1duzYJojv+xq61bHG4dS8j3foha/3yfhvd/XmNwd1x+huteYdPFauxVtylLElR98dKjrpc9qGB6l7bIS6x4XrSEmlPt6aq692F2jgQ5+cNLei2qnrUjtrd16JduX9sFIsONCq568f4soKAAAAAADgC9xuMkaNGiXDOHkF0Y9efvnlOs/ZtGmTu7+qRfhpxZej1nhBaaXufGOj1mQekyQlx0doR26JPtycrdtHJclisWhN5lE9+ckurd13zHWexSL1bR+lIYmtNahztM7u3Erton56llp+cYWWb89XlcMpSerQKkQ94sLVqXWoXlm9X59uz9On22s/k02SZn+0TX+9ckCTf38AAAAAAIDmwhIek4XZbZJqr/janlOsm17+RjlFFQoLsunxqwYoNamthjzyqXblleqt9Qf10beH9fWeo5Ikq0VK6dJG4/u309g+8YqJqP9WyNjIYP3nd8NVdKJaPeMjFBkc6DpWXuXQ+5uy1blNqHrERah7XIRW7MzXd4eK9M6GQxrapbVqHIa+zynS94eLlVNUofSLk3XpwA7N9L8OAAAAAADA6aP4MllE8H9vdaz6ofiqcTh195ublFNUoa4xYXruukHqFhshSTo/OVZLtuXqvne3SJICbRZdPaSTbh+dVGtV16n0iIuoc/yxKwfoz1f0l9VqcY2d16OtrvjnaknSn9757qRz7l20WYE2q8b1a9fo3w8AAAAAAOAJFF8mCwv6762OFT8UX//+5qB25ZWqVWig3r1tmKLDglxzrxrSUUu25cpmtejKQR115/nd1DG6aR9E//PSS5IGdW6t924fpmsXrlG4PUC920epd7tI9W4fqS93HdE7Gw7pd//epCCbVWm945o0CwAAAAAAwJmg+DLZz9/qWHSiWk9+skuSdG9aj1qllySdnxynN289R+2jQtSpjefevHh2p2h9/+BFJ5Vi4/u1U7XDqQ83H9bt/9qo568frJE9YlTjcGpXXqk2HTyu3Xml+tWgjurbIcpjeQEAAAAAACSKL9P9/K2O8z/brWNlVeoWG65rUzrVOf+crm08Gc/lf0svSbJZLXr8ygGqrHZqybZc3fraevXv2EpbDhXpRPVPD+tfvCVHS+8ZeVKRBwAAAAAA0JysZgdo6X5c8VVW5dBLX2dJkqaP76VAm2/8vybAZtXfrjlL5yfHqqLaqXX7julEtUMR9gCd262NOkaHKL+kUtM/2Nrg20ABAAAAAACaGiu+TPbjw+0lqcZp6LweMRrVM9bERO4LCrDqH78+W6+v2a/I4ECd1amVkmLCZbVa9N2hQl3+j1XK2JKjz2bma/61Zyk6LEh92kfKHmAzOzoAAAAAAPBjFF8mswdYZbNa5HD+sBrq5uFdTE50eoIDbZo8outJ4/07ttLvLuiuJz7ZpRPVDt38ynpJ0h2jk/THscmejgkAAAAAAFoQ37ifzo9ZLD+VXpI0tEtrE9M0jztHd9PjVw6oNfbV7gJufQQAAAAAAM2KFV9eJDI4QMGB/nf7n9Vq0RWDOurifvHalVeqyxZ8re8OFWnYvM90fnKsLugVq2FJbf3yuwMAAAAAAPNQfHmRwYn+t9rr50KDAjSgY5R+ndJJ723MVk5Rhf619oD+tfaAggOtGt4tRhf0itUFybGKjQxWZY1Dmw4Uak3mUR0pqdTZnaJ1fnIsb4cEAAAAAACNYjF84H6z4uJiRUVFqaioSJGRkWbHaXIP/t82vbvhkDJ+N0IJrUPNjuMRFdUOrc48quXb87R8e75yiipqHU+KCdOh4ydUWeM86dxvZ16oE9UOxUXaZbFYTvrczQcLte1wsYZ3a6ue8RHN+j0AAAAAAIBnudMTUXx5CYfTkM1qOfVEP2QYhrbnlGj59jx9uiNf3x4sdB1rG25XalIbRQQH6I21B2qdlxQTpnduG6b1+49rfdYxfZN1TFuyi1Tt+Okv6bhIu34/pqf6dYxSm/AgxUYEe+prAQAAAACAZkDxBZ+WX1KhzQcK1TUmTEkx4a5VXc9/lanX1+xX1tHyBs+3WKT6/qoOtFn01MSzNL5/u6aODQAAAAAAPIDiC34t80ipzn/8C9d+t9hwDUmM1uDOrTW0S2t1jA7R9pwS3fb6Bh04VndJFmiz6J+/HqTosEAdLqxQUky4erfnry0AAAAAALwdxRf8Xl5xhb4/XKz+HaPUJtxe77yKaodyiioUHxms+9/fovc3Zdc79w8X9tBvz0tSoM3aHJEBAAAAAEAToPgC6rFka45e+jpLR8uqFGiz6mhppfJLKl3HU7u20dNXD1RsJM8CAwAAAADAG1F8AW7I+C5H0977TsUVNa6xW0d21f3jepmYCgAAAAAA1IXiCzgNO3KLddFTX7n2O7QK0YCEKN06MkmGYei7Q0XqGhOmc7q2qfN2yPKqGn17sEgRwQHq2yHKk9EBAAAAAGgxKL6A05RTdEKpcz9r1Nzp43upfasQrc86rg37j2nb4WLVOH+4nMLtAfrdBd1U4zTUMy5C1Q6nxvSOl81qac74AAAAAAD4PYov4AwcLa3Uy6uy9PfP9jT5Z79y01ANTWytkCBbk382AAAAAAAtAcUX0EQKy6tUUFqprm3DVeVw6stdR/TPL/Zq04FCSVJyfISGJLbW4MRoDeocrcoap6Yu2qzvc4pV7Wj40pqU2lkPXdrXA98CAAAAAAD/QfEFeEBljUP2gIZXbjmchqwW6dIFX+u7Q0V1zvns9+fpeHm1sgrKZA+0KjTIpuBAm3rFRyo6LKg5ogMAAAAA4LMovgAvZBiG1mQe06fb8/TCyn2NOue8HjF65aahzZwMAAAAAADfQfEFeLmyyhrd8up6rdp7VJLUJixIye0iVOMwdKLaUWt12JjecSqrrJEkdYwO0dzL+8tmtcjhNHhYPgAAAACgxaH4AnxEWWWNjpVVqWN0iCyWn0qskopq9Zu9rFGfMXtCb91wbpfmiggAAAAAgFeh+AL8gNNp6I11B7Q9p1hxkcF64pNdDc63WS26clBHPXRpX2UWlKpjdKjC7QEeSgsAAAAAgGdQfAF+yOE0tGJnvrZkF6lP+yjlFJ3QzA+3NXjOx3ePUK92kSquqNa27GJFhgQo+/gJSdKFfeI9ERsAAAAAgCZF8QW0EOVVNVr0zUFtzynWW+sP1TmnZ1yEduaV1Hns3G5tdM3QTvpF//bNGRMAAAAAgCZD8QW0QCUV1VqfdVyd24TqnQ2H9I8Ve906v1+HKL1/+zBJUoDN2hwRAQAAAAA4YxRfAPTW+oPaV1CmgQmtdHanaLUKDVRljVOV1Q7ds2izyqsc2rD/eJ3nDuocrT9f0V/dYsM9nBoAAAAAgIZRfAFolM925Cm7sEIzPtha5/Hk+Ah9fPeIWm+cBAAAAADATO70RLzyDWjBzk+OkyT9JqWTvj1UpCMllXruy736JuuHlWA7ckv0r7UH9OuUTjpR7VBoEH/LAAAAAAD4DlZ8AThJWWWNfvfvTVq+I/+kY0kxYbrh3C667pzOJiQDAAAAALR03OoI4Iw5nIbSnvhC+wrK6jw+uHO07rs4Wf07RskeYNOxsipt2H9cBaWVcjgNbTxwXO9tzJYkPX7lAF0xqKMn4wMAAAAA/BTFF4AmUe1wauWeAtltVr20KktdY8L07BeZJ80LsllV5XA26jM/nTpS3WIjmjoqAAAAAKCFoPgC0GwOHC3XyMc+r/e4zWpRatc2at8qWBsPFGpPfulJcy7sHad//PpsBdiszRkVAAAAAOCHKL4ANCvDMGQYUkFppT7YnK1useE6KyFa0WFBJ80tLK/Sq6v369Dxcr21/tBJx2Mi7Aq3B6hteJAmj+iqtF5x2pNfqsOFJ3RO1zbalVeizQcLtSuvRO1bhcgeYNUFveKU2CaUt00CAAAAQAtE8QXAK63NPKqJz61pcE5YkE1lVY5GfZ7VIl02sIOCAqwanRyr85NjFcgqMgAAAADwaxRfALyW02lo2fe5yimq0MrdBfp6b4GGd2urT7ef/AZJSWoVGqiBCa2UHB+phV9lyuGs/29ZfdpHKuN3I5orOgAAAADAC1B8AfA5xRXVWrHziLrFhKtHXLjySipVXeNU5/+5pdEwDO3OL1X6u9+p6ES1hnZpI6fT0KL1ByVJV5zdUT3iwjU4sbUGdY426+sAAAAAAJoJxReAFif93e/05jcHa421DQ/Sjed20eVnd9De/DKt23dUfTtE6US1QxHBARreLUZBAdwaCQAAAAC+hOILQIvjdBrqO3upnIahimpno8+bPr6XfjWoo1qFnvxgfgAAAACA96H4AtCiFZ2o1p1vbNRXuwtOOpYcH6EduSV1nje6Z4y2Hi7Wuvsv4I2RAAAAAOClKL4A4L9KKqpVVeNUm3C7a8zpNPTOxkN68pNdyimqqPO8tuFBOrtTtO67OFkJ0aHcEgkAAAAAXoLiCwAaKb+4Qluyi5RfUqlp721pcO6EAe3125Fd1TosSO1bhXgoIQAAAADg5yi+AOA0GIah/3yXo2qHU0u35WrptrxTnjO+fzs9PXGgAmysCAMAAAAAT6D4AoAmUONwKrOgTCt25mvO4h0Nzt3z6MWUXwAAAADgARRfANDEKqodOlJSqRPVDr2x9oDe3XBIJZU1J82bPLyLpv+itwkJAQAAAKBloPgCAA9JTM84aezNW8/ROV3bmJAGAAAAAPwfxRcAeIhhGPom67ichqGrn1vjGn/66oEa2qW1IoMDFRJoU2ZBqbYdLlZarziF2QNMTAwAAAAAvo3iCwBM8OwXezX344afBSZJ4/rFq2+HKJ3XI0bJ8ZGqdjgVHGjzQEIAAAAA8H0UXwBggqoap577cq/+umyX2+den9pZD17atxlSAQAAAIB/ofgCAJMdL6tSYIBVhwtPqNrhVI+4CK3ae1Sr9hTo2S8z6zxnSGK0npw4UB2jQz2cFgAAAAB8B8UXAHgxp9OQ0zBU7TC0LuuYrn9xXZ3zlt07UkUnqnXgaLk+25mv2RP6KCbC7uG0AAAAAOBdKL4AwIc4nIbG/+0r7SsoU2WNs8G50aGBSooJ19mdo9WrXYS6xUSoa0wYD8wHAAAA0GJQfAGAj1qTebTW2yHdEWEPUGCAVU9NHKiRPWKaOBkAAAAAeAeKLwDwcSeqHAqwWRRgtchisWjWh1v18dZc5ZdUuvU5cy/vp2uGdlJljUNBNqssFkszJQYAAAAAz6D4AoAWIqugTL9/+1vtyClWWZXjlPOvGZqgywZ20JbsIl05OEFRIYEeSAkAAAAATYfiCwBaKMMwlFdcqTvf2Kj1+4+fcn7WvPEeSAUAAAAATYfiCwAgwzD0+LJd6tshUoE2q25+ZX2d82xWi7bOHquQIJuHEwIAAACA+yi+AAAnOV5WpYoah2LC7er2wMf1zuvQKkTZhSckSZ/cO1Ld4yJU7XDKZrHIauUZYQAAAADMRfEFAGjQ4cITuvKZ1a6Cyx3Tx/fSTed2oQQDAAAAYAqKLwBAo+3KK9G3Bwv1zy/2qntsuIYkttYjGdsbdW58ZLDG9Wun3fklSo6PUGpSG7UKDdJZCa14gyQAAACAZkHxBQA4Y9UOp7ZkF6m6xqmYCLu+yTqm+97d4vbntA23y2qRLugVq3c2HNI5XdtoyqgklVc6FBhgVWrXNgoKsDbDNwAAAADgjyi+AADNJq+4Qs99makXVu5Tt9hwpXZto9fW7G+W39WnfaQevqyvzu4UrZKKapVU1GhLdpGKTlTrqsEJzfI7AQAAAHg3ii8AgMcZhiGnIe09Uqo1mUf19vpD2pJdJEkKCrBqdM8YLd2W1+S/t0vbMHWMDlHvdpGaNq5Xk38+AAAAAO9C8QUA8EqGYai8yqEwe4Ak6d0Nh3SsrErHyqt0uPCEduaWqOhEtXKKKuo832qRnI34p9a6+y9Qm3C7DMNQgI3bKAEAAAB/QvEFAPALhmHow82HFRcZrD4dIhUcYFOgzaL5n+1RduEJvfnNQZ3brY2+3nO0UZ/36k1DdW63trLxRkoAAADAZ1F8AQBalGNlVVq1t0B3vrHJrfNGdG+rAR1bae+RUv1hbE8lxYQ3U0IAAAAATYXiCwDQYu09Uqpv9h1T/46t9NmOPPWMj9Tcj7cryGbVjtySU54/dUwPxUbY1T0uXAMTolkdBgAAAHgZii8AAOpQ43Bq5Z4C3fDSN26fm9YrVs9dN1hWijAAAADAVBRfAAC4Ib+kQkMfXd7o+a/cNFQpXVorONDWjKkAAAAA1IXiCwCAM1RR7dC7Gw/p4f98r4pqZ73zRvaIUY3DqbF94nVtSicF8hZJAAAAoFlRfAEA0MQ++vawfvfvUz88v2dchA4cK9f2hy/yQCoAAACg5aH4AgCgGVVUOzTo4U/UvlWIdueX1juvZ1yE3rotVVEhgR5MBwAAAPg3ii8AADzs1dVZ+uT7PH21u+CkY+/clqrBia0l/fCAfZvVIouFh+QDAAAAp6PZi68FCxboscceU25urgYMGKC///3vGjp0aJ1zq6urNXfuXL3yyivKzs5Wz5499ec//1kXXdT4W0AovgAAvqK8qka/fW1DnQVYXf5yRX+NTo5VTIS9mZMBAAAA/sGdnsjtJ/AuWrRIU6dO1axZs7Rx40YNGDBAY8eOVX5+fp3zp0+frmeffVZ///vf9f333+u2227TL3/5S23adOrnpAAA4GtCgwL02s0pypo3XlPH9Djl/D+9+52GPPqpbnhpnRxOr1+EDQAAAPgUt1d8paSkaMiQIZo/f74kyel0KiEhQXfddZfS09NPmt++fXs98MADuuOOO1xjV1xxhUJCQvT666/X+TsqKytVWVnp2i8uLlZCQgIrvgAAPmdrdpHe25it+Ci7OrUOVbfYcL257qCeX7nvlOeO6xevBdeezW2RAAAAwM+4s+IrwJ0Prqqq0oYNGzRt2jTXmNVqVVpamlavXl3nOZWVlQoODq41FhISopUrV9b7e+bOnasHH3zQnWgAAHilvh2i1LdDVK2x6b/orem/6C1J+u5QoS6Z/3Wd5y7ekqsu0xZLkm4YlqhhSW00qmesggLcXrANAAAAtEhurfg6fPiwOnTooFWrVik1NdU1/qc//UlffPGF1q5de9I51157rb799lt98MEHSkpK0vLly3XppZfK4XDUWtX1c6z4AgC0NEdLK5VZUKYPN2dr/9HyRj0j7JsH0ng2GAAAAFqcZlvxdTqefvpp3XLLLUpOTpbFYlFSUpJuvPFGvfjii/WeY7fbZbfzB3kAQMvRJtyuNuF2Dfnv2x8lKafohFLnflbvOUMe/VQdo0O08r7zPRERAAAA8DluFV9t27aVzWZTXl5erfG8vDzFx8fXeU5MTIw++OADVVRU6OjRo2rfvr3S09PVtWvX008NAEAL0C4qRFnzxrv25328Q3vyS/Tp9p9eKHPo+AklpmdIkn57XlftzitVXKRd6Rf1UlRooMczAwAAAN7EreIrKChIgwYN0vLly3XZZZdJ+uHh9suXL9edd97Z4LnBwcHq0KGDqqur9e677+qqq6467dAAALRE6Rcnu7aLK6rVf/ayWsef/SLTtf3vdQdd24ltQpV1tFySlBQTpg7RoRrTO07/t/mw+neMUkLrUEUEByg1qY3aRYU087cAAAAAPMfttzouWrRI119/vZ599lkNHTpUTz31lN566y3t2LFDcXFxmjRpkjp06KC5c+dKktauXavs7GwNHDhQ2dnZmj17tvbt26eNGzeqVatWjfqd7ty7CQBAS3LwWLlG/OXzZvnsCHuAbh3ZVZsOFmpgQivdPipJATYerA8AAABzNeszviZOnKgjR45o5syZys3N1cCBA7VkyRLFxcVJkg4cOCCr9ac/FFdUVGj69OnKzMxUeHi4xo0bp9dee63RpRcAAKhfQuvQWrdDStK3Bws1/YOtOlJSqVC7TfYAm7bnFLv92SWVNXr8k12SpM925OuJ/27/8HtDFB8ZrLF94nXTuV1ktVrO7IsAAAAAzcDtFV9mYMUXAADNq9rh1OaDhfpi5xF9+G22qmqcKq9yyCKpuKKm0Z+zeeYYhQTZFGi1UoYBAACgWbjTE1F8AQCAUyosr9LnO/P1wsp92ppdrKSYMO09UnbK865N6aRHLu1LCQYAAIAmQ/EFAAA84khJpZ75Yq9eWLnvlHMtFumOUd30h7E9PZAMAAAA/oriCwAAmCKn6ISsFose/L9tWrwl161zo0IC1ad9pMb0jtP1qYmsEgMAAECdKL4AAIBXOFJSqfvf36KwIJs+2HzY7fPfuCVFw5LaNkMyAAAA+CqKLwAA4HWcTkPvbjyklXsKtDbzmGIj7TpwrFyF5dWNOv+iPvG67KwOSmgdom6x4bIH2Jo5MQAAALwRxRcAAPBZr63O0owPtzVq7tDE1nr15qEKDqQEAwAAaCkovgAAgM8rr6rRzS+v1+rMo42a36tdpGZN6K2zOrViNRgAAIAfo/gCAAB+yeE0dLS0Uku/z9OMD7Y2ONdqkaaMStL1wxIVGxHsoYQAAABobhRfAACgRdh7pFSfbc/Xo4u3n3Lu4M7Ren1yCrdFAgAA+DiKLwAA0CJV1jh0/3tbZcjQexuz65zTPipY3eMiNCChle46v5sCbVYPpwQAAMCZoPgCAAD4ry92HdH1L66r93igzaIP7jhXiW3CFGYP8GAyAAAAnA6KLwAAgP+xeu9R3f6vDQoJtOlwUUW9887p2lqjesbqtvOSPJgOAAAAjUXxBQAAcAp78kuU9sSXahtuV0Fp5UnHLRbpxRuGaHTPWBPSAQAAoD4UXwAAAG5wOA09/J/vtenAcX17qKjOOW3CgtQxOkQDElppSGJrTRjQ3sMpAQAAIFF8AQAAnJGpb22u9+H4P2cPsOrJiQM1rl87D6QCAACARPEFAADQJPbkl2rptlztzS/V3oIyfXuwsMH5704ZpkGdoz0TDgAAoIWi+AIAAGhGX+w6onve3KTj5dX1zsmcM05Wq8WDqQAAAFoGii8AAAAPWbfvmG54aZ3Kqxx1Hk9oHaKv/nS+h1MBAAD4L4ovAAAADzMMQwePndDIxz6v8/iI7m3VuU2oZv6ij4ICrB5OBwAA4D8ovgAAAExUWlmj7w4W6trn19Y7Z2BCK53TtY2SYsJ0ycD2sgfYPJgQAADAd1F8AQAAeIGKaodue32D2rcK0RtrD5xy/tzL++maoZ08kAwAAMB3UXwBAAB4oeKKav1rzQG9vma/sgtPNDi3TViQ1t5/gQJs3BYJAADwcxRfAAAAPiKvuEKX/2NVg0VYj7hw7cor1ZRRSfrVoI5KiA7lOWEAAKDFovgCAADwQTlFJ/TvtQf0t8/2NGr+1+nnq0OrkGZOBQAA4F0ovgAAAHzchv3HtOlAobrHReiNtfu1dFteg/NtVotuGdFVv07ppITWoR5KCQAA4HkUXwAAAH7I6TRUUFqpoXOWn3Lul38crU5tKMAAAID/ofgCAADwczUOpzK25Gjj/uN6ZfX+OudEhQTqgXG9dHbnaHVtGyar1eLhlAAAAE2P4gsAAKAFKqmo1oAHl8l5ij/dvXf7MEUGByihdajsATbPhAMAAGgiFF8AAAAtmMNp6KpnV2vD/uOnnBscaNXzk4bo3G5tZLGwIgwAAHg/ii8AAAC4FJZXKWNLjh54f+sp535wx7kamNCq+UMBAACcJoovAAAA1Kui2qHyKofOfviTBuddMqC9LugVq1E9YhUVGuihdAAAAA2j+AIAAECjnahy6OKnv1TW0fIG5z133SBd0CtONh6SDwAATETxBQAAALdVO5x6dfV+FZ+o1tPLdzc4d8KA9ppyXpJ6t+fPZgAAwLMovgAAANAkSitr1HfW0nqPj+jeVq/dnOLBRAAAoKWj+AIAAECTq3E4dfeizVqxI19lVY5ax164frAu6BVnUjIAANCSUHwBAACgWRWWV2ngQ3U/HH/D9DS1Cbd7OBEAAGgp3OmJrB7KBAAAAD/SKjRIOx+5SMnxEScdG/TIp0pMz9DW7CITkgEAAPyEFV8AAAA4Y6v2FujahWvrPBYZHKD2rUI0vFtbfb33qP58RT91bhOmqJBAD6cEAAD+gFsdAQAAYAqn09DVz63RuqxjjZrfoVWI/u+u4WodFtTMyQAAgL+g+AIAAICpDMPQJ9/n6fW1B/TlriMa1TNGK3YeafCcc7q21n0XJeusTtEeSgkAAHwRxRcAAAC8lmEYWpN5TNcsXFPn8dAgm87rEaObhnfR4M7RslgsHk4IAAC8GcUXAAAAfIJhGJrx4VZ9tPmwiitq6p23Kv18tW8V4sFkAADAW1F8AQAAwOfszC3Rlc+sarAA2zd3HCvAAABo4Si+AAAA4PMOHivXiL98Xuex5PgI3TS8i64anODhVAAAwGwUXwAAAPAbhmGoy7TF9R4f1TNGf7/mLEUEB3owFQAAMAvFFwAAAPzO3iOlem31fn2564gyC8rqnffHsT11x+huHkwGAAA8ieILAAAAfq2ovFpvrT+oRxdvb3DetgfHKswe4KFUAADAEyi+AAAA0GKUV9XonQ2HtCuvRK+vOVDvvBm/6K1f9G+nuMhgD6YDAABNjeILAAAALdae/BKNe3qlqhzOeuese+ACxUZQgAEA4IsovgAAANDibc8p1rNf7NUHmw83OO/yszvooj7xGtipFWUYAAA+gOILAAAA+B8Op6FuDyzWqf70e+nA9nrsVwMUFGD1TDAAAOAWii8AAACgHk6noQ82Z+vFr/dpa3Zxg3PH9YvX3Mv7Kyok0EPpAADAqVB8AQAAAG76eEuOpvxrY53HBnSM0tzL+6t3e/4sCgCA2Si+AAAAgNNkGIaWbM2tswTrEReu7nERunN0N/Vqx59LAQAwA8UXAAAA0AS+3lOgXz+/tt7jHVqF6KbhXXTz8C4eTAUAQMtG8QUAAAA0oWXbcvX8yn1at+9YvXPG9olT67AgVdY49duRSeoZH+HBhAAAtBwUXwAAAEAzWrI1V0u35er9Tdn1zsmaN96DiQAAaDkovgAAAAAPcDoN/fr5tVqdebTO41NGJenivvHq37GVZ4MBAODHKL4AAAAAE5RX1aj3zKV1HuvcJlSzL+mj87rHyGq1eDgZAAD+g+ILAAAAMMmxsiqd/fAnp5y36NZzlNK1jQcSAQDgXyi+AAAAAC9Q43DqkYztenfDIZVU1tQ5Z3y/dro2pZOGJbWRxcJKMAAAToXiCwAAAPBCR0srNeiRT085b+GkwTqvR4yCAqweSAUAgG+h+AIAAAC8mGEYmv3RNr2yen+D89qG27XyvtEKDrR5KBkAAN6P4gsAAADwIZlHSvXh5sN6evnuBuf9567h6tshykOpAADwThRfAAAAgA8rrqhW/9nL6j3er0OUrhzcUZNSEz0XCgAAL0HxBQAAAPiB7w4VavIr65VfUtngvHO6ttaVgxJ0+dkdeEA+AMDvUXwBAAAAfqba4dRNL3+j3Xmlyi2uaHBuuD1AUSGBigwJ1Gs3D1XbcLuHUgIA0PwovgAAAAA/tzuvRCt2HtGmg8e1eEvuKee/c1uqBie29kAyAACaF8UXAAAA0MJUVDv0fU6xVu0p0PacEmVsyal37g3DEmUPtOr287opKjTQgykBADhzFF8AAAAAtGJnvqZ/sFWHjp+od06A1aKdj1wsm5VngwEAfAPFFwAAAIBasgtP6G+f7tbirTkqqag56XjXmDCN7B6jySO6qGN0qAkJAQBoHIovAAAAAA0qKK3U4Ec+rff4V38arY7RIbwlEgDgdSi+AAAAADTKa6uzNOPDbQ3O+cOFPXTn+d09lAgAgIZRfAEAAABwm9Np6IpnVmnTgcI6j/dpH6mXbhii2MhgzwYDAOBnKL4AAAAAnDbDMJR1tFy/eX6tsgvrfjD+sntHqkdchIeTAQBA8QUAAACgCb2yKkuzPqr7dsh70rqroLRSrcPsmpTaWW3D7R5OBwBoadzpiayn8wsWLFigxMREBQcHKyUlRevWrWtw/lNPPaWePXsqJCRECQkJuvfee1VRUXE6vxoAAACAh10/LFFZ88Zr88wxJx176tPden3NAf1t+W4NfuRTJaZn6J8r9iq/mD/vAwDM5/aKr0WLFmnSpEl65plnlJKSoqeeekpvv/22du7cqdjY2JPmv/HGG7rpppv04osvatiwYdq1a5duuOEGXX311XriiSca9TtZ8QUAAAB4j4pqhya/sl6ZR0p1uKjhguu8HjF66YYhslp5OyQAoGk0662OKSkpGjJkiObPny9JcjqdSkhI0F133aX09PST5t95553avn27li9f7hr7/e9/r7Vr12rlypWN+p0UXwAAAIB3MwxD1yxcozWZx+qdYw+wauOMMQqzB3gwGQDA3zTbrY5VVVXasGGD0tLSfvoAq1VpaWlavXp1necMGzZMGzZscN0OmZmZqcWLF2vcuHH1/p7KykoVFxfX+gEAAADgvSwWi968NVVZ88Zr39xxumFY4klzKmuc6jNrqRLTMzTrw61aui3X80EBAC2KW/+ppaCgQA6HQ3FxcbXG4+LitGPHjjrPufbaa1VQUKDhw4fLMAzV1NTotttu0/3331/v75k7d64efPBBd6IBAAAA8BIWi0WzL+mj2Zf0UWF5lVbvPaop/9pYa84rq/frldX7Xfvj+7XT1At7KCkm3NNxAQB+7LQebu+OFStWaM6cOfrHP/6hjRs36r333lNGRoYefvjhes+ZNm2aioqKXD8HDx5s7pgAAAAAmkGr0CBd3K+dsuaNV+accbqwd1yd8zK25OiCx79QYnqGfvvaei3Zmqtqh9PDaQEA/satFV9t27aVzWZTXl5erfG8vDzFx8fXec6MGTN03XXXafLkyZKkfv36qaysTLfeeqseeOABWa0nd292u112O69BBgAAAPyJ1WrRc5MGu/bziit0y6vr9d2holrzlm7L09JtP/07x85HLpI9wOaxnAAA/+HWiq+goCANGjSo1oPqnU6nli9frtTU1DrPKS8vP6ncstl++IeWm8/VBwAAAOBH4iKD9dGdw5U1b7yy5o3X5Wd3qHNez+lLdOUzq1RR7fBwQgCAr3P7dSpTp07V9ddfr8GDB2vo0KF66qmnVFZWphtvvFGSNGnSJHXo0EFz586VJE2YMEFPPPGEzjrrLKWkpGjPnj2aMWOGJkyY4CrAAAAAAOCJqwbqiasGSvrhP5Knzv1MucUVkqRvso4recYSje0Tp5uHd9XQLq1NTAoA8BVuF18TJ07UkSNHNHPmTOXm5mrgwIFasmSJ64H3Bw4cqLXCa/r06bJYLJo+fbqys7MVExOjCRMm6NFHH226bwEAAADAr1gsFq25/wJtO1yk8X9b6Rr/+W2QL904RCO6tVWArdkfXQwA8FEWwwfuNywuLlZUVJSKiooUGRlpdhwAAAAAHvaHt7/VOxsONTgn0GbRSzcM1fDubT2UCgBgBnd6IoovAAAAAD7lN8+v1co9BQ3OyZwzTlarxUOJAACeRPEFAAAAwO85nYY+3Z6nNZnH9Ma6/aqodtY5b/r4Xrp+WKICuSUSAPwCxRcAAACAFsfpNNT1/sX1Ht/5yEWyB/CCLQDwdRRfAAAAAFqsJz/ZpQ82Z2v/0fIG5w1JjNasCX3Ut0OUh5IBAJoCxRcAAAAASKpxONXtgY9POe+bB9IUE2H3QCIAwJmi+AIAAACAn9l2uEhf7S5Qm7Ag/fGd7+qcc/PwLpo+vpcsFh6KDwDejOILAAAAAE7hRJVD9y7arCXbck86tvK+0eoYHWpCKgDAqVB8AQAAAEAjHTharpGPfX7SeOc2ofrDhT01skeMokICTUgGAKgLxRcAAAAAuCm/uEJD5yyv81jfDpF6+7fDFBLEWyEBwGzu9ERWD2UCAAAAAK8WGxmsrHnjteSeEYoMDqh1bGt2sXrNXKI9+aUmpQMAnA5WfAEAAABAPQ4XntCweZ/VGpsyKkn3XZRsUiIAALc6AgAAAEAT+uvSnZr/+Z5aY8nxEXpnyjCF2wPqOQsA0BwovgAAAACgiW3Yf1xX/HNVnceW3DNCyfH8uwoAeALFFwAAAAA0k+Xb83TzK+vrPHbZwPYa1TNWo5NjeRMkADQTii8AAAAAaGZVNU49+eku/XPF3jqPtw0P0rPXDdJZCdGyWi0eTgcA/oviCwAAAAA8xOk0dPeizfq/bw/XO2fZvSPVIy7Cg6kAwH9RfAEAAACASapqnBr40DKVVzlqjbcKDdSG6WNkY/UXAJwRii8AAAAA8AL3Ltqs9zdl13nsjckpGtatrYcTAYDvo/gCAAAAAC9RVF6tAQ8tq/NYz7gILblnhCwWVoEBQGNRfAEAAACAl6l2OPX+pmyt23dM72w4dNLxT+4dqW6x4ZRgAHAKFF8AAAAA4MXKq2rUe+bSOo+9dOMQnZXQSq1CgzycCgB8A8UXAAAAAPiA7w4V6pL5X9d5zB5g1Rd/HK34qGAPpwIA70bxBQAAAAA+5olPdunZL/aqssZ50rEP7zhXAxJaeT4UAHghii8AAAAA8FGVNQ6NffJLZR0trzX+8KV9dF1qojmhAMCLUHwBAAAAgI+rdjj19Ke7Nf/zPbXGbzw3UZNSE9WlbZhJyQDAXBRfAAAAAOAnVuzM1w0vfVPnsUsHttcfx/ZUx+hQD6cCAPNQfAEAAACAn/lwc7bufnNzvcc/vnuEerXj35cA+D+KLwAAAADwUw6noQWf79ETn+yq83j/jlGa88t+6tshysPJAMAzKL4AAAAAoAUwDENdpi2u93hIoE3rp6cpzB7gwVQA0LwovgAAAACghfl6T4EWfXNQH317+KRjqV3b6NlJgxQZHGhCMgBoWhRfAAAAANBCGYahT7fn65ZX1590bPW089UuKsSEVADQdCi+AAAAAADaeOC4Lv/HqpPGF1x7ti7qGy+b1WJCKgA4MxRfAAAAAACXGR9s1Wtr9p80Hhxo1X/uGq6kmHBZLJRgAHwDxRcAAAAAoJbKGod+uWCVvs8pbnBeWJBNK+87X9FhQR5KBgDuofgCAAAAANSroLRSgx/59JTzfnlWB41OjtWE/u1YEQbAa/ht8XXkyBGKLwAAAABoQuVVNVq996gytuRoydbceucNTGilV24aqkCb1YPpAOBkxcXFiomJaVTxFeChTE3i8ccfV3BwsNkxAAAAAMDvxEi6rqEXPhZIf/3L556KAwD1qqioaPRcqnoAAAAAAAD4JW51BAAAAACcUmWNQ5/vOKKpb22ud86G6WMUEmTzXCgALZI7tzr6VPHFw+0BAAAAwHzPfrFXcz/eUeextfdfoLhIHlEDoPn47cPtKb4AAAAAwHuUV9Vo5e4C3frahpOObZl9oSKCA01IBcDfudMT8YwvAAAAAMBpCQ0K0IV94rVv7jgltK79ZPx+s5dpyusb5HR6/VoLAH6M4gsAAAAAcEYsFou++tP52jd3nC4/q4Nr/OOtuep6/2J9e7DQvHAAWjRudQQAAAAANKnvDhXqkvlfnzw++0JFcvsjgDPErY4AAAAAANP079hKWfPG608X9aw9PnuZrl24xqRUAFoiii8AAAAAQLO4fVQ3bXtwbK2xVXuPKjE9Q48v22lSKgAtCcUXAAAAAKDZhNkDlDVvvDbNGFNr/O+f7dGf3vlWPvD0HQA+jGd8AQAAAAA8ZtE3B3Tfu1tqjf2ifztZLRY9eEkfRYcFmZQMgK9wpyei+AIAAAAAeFTmkVJd8c9VOl5efdKxqWN66HcXdDchFQBfQfEFAAAAAPB6H2/J0ZR/bazz2N0XdNc9ad1lsVg8nAqAt6P4AgAAAAD4lGXbcnXraxvqPDZ1TA/ddX43SjAAkii+AAAAAAA+qqFVYBf2jtOfr+jPc8CAFo7iCwAAAADg046WVurtDYc07+MddR6/fVSSpo7poQCb1cPJAJiN4gsAAAAA4DceW7pDCz7fW+ex2Ai73p0yTAmtQz2cCoBZKL4AAAAAAH7pvY2HNPWtb+s8tvORi2QPsHk4EQBPc6cnYk0oAAAAAMBnXH52R2XNG6//u3O4BnSMqnWs5/QlenPdAZVUVJuUDoC3YcUXAAAAAMBnlVRUq9/sZSeN94yL0N1p3TWmd5wCeQ4Y4Fe41REAAAAA0KJ8ueuIJr24rs5jfTtE6j93jfBwIgDNheILAAAAANAi5RVX6M9LdmjxlhxVVDtrHXv66oG6dGAHk5IBaCoUXwAAAACAFq+i2qHkGUtOGn9jcoqGdWtrQiIATYGH2wMAAAAAWrzgQJv2zhmnG89NrDV+7fNr1WvGEm3NLpLT6fVrQQCcAVZ8AQAAAAD8XkW1Q/e/t0Xvbco+6ViHViH6Ov18E1IBOB2s+AIAAAAA4GeCA216YuJAbZoxRkMSo2sdyy48ocT0DBWVV5uUDkBzYcUXAAAAAKDFcTgNHS48oRF/+fykY1cO6qg/X9FfVqvFhGQAToUVXwAAAAAANMBmtSihdaj2PHqxhia2rnXs7Q2H1PX+xXpv4yGT0gFoKqz4AgAAAAC0eLlFFbpm4RrtKyirNT4goZU+vONck1IBqAsrvgAAAAAAcEN8VLA+/8MoZc0br3H94l3j3x4sVGJ6hnbnlZiYDsDpovgCAAAAAOBn/vHrQdr1yMW1xsY8+aXufGOjSip4AD7gSyi+AAAAAAD4H0EBVu14+CJ1ah3qGvvPdznqN3uZbnl1vRxOr39qEABRfAEAAAAAUKfgQJu+/NNoLf7dCKV0+ekB+J98n6ek+xdr1Z4CE9MBaAwebg8AAAAAQCNsOnBcv/zHqpPGz+naWq/elKKgANaWAJ7Aw+0BAAAAAGhiZ3WK1o6HL9IFybG1xtdkHlOP6R9r2bZck5IBqA/FFwAAAAAAjRQcaNMLNwxR5pxxuj61c61jt762QeuzjpmUDEBduNURAAAAAIDTZBiGfv/2t3pvY7ZrbGSPGP06pZPG9ok3MRngv9zpiSi+AAAAAAA4Q59+n6fJr64/aTxr3ngT0gD+jWd8AQAAAADgQWm945Txu+EnjSemZ5iQBsCPKL4AAAAAAGgCfdpHKWveeO2dM67WeGJ6hrYcKjIpFdCynVbxtWDBAiUmJio4OFgpKSlat25dvXNHjRoli8Vy0s/48Sz3BAAAAAD4H5vVosz/Kb8mzF+pxPQM7T9aZlIqoGVyu/hatGiRpk6dqlmzZmnjxo0aMGCAxo4dq/z8/Drnv/fee8rJyXH9bN26VTabTVdeeeUZhwcAAAAAwBtZrRbtmztO5/WIqTV+3mMrlJieoceX7ZQPPHIb8HluP9w+JSVFQ4YM0fz58yVJTqdTCQkJuuuuu5Senn7K85966inNnDlTOTk5CgsLq3NOZWWlKisrXfvFxcVKSEjg4fYAAAAAAJ9076LNen9T9knje+eMk81qMSER4Lua7eH2VVVV2rBhg9LS0n76AKtVaWlpWr16daM+44UXXtDVV19db+klSXPnzlVUVJTrJyEhwZ2YAAAAAAB4lScnDlTWvPF689Zzao33m71UNQ6nSakA/+dW8VVQUCCHw6G4uLha43FxccrNzT3l+evWrdPWrVs1efLkBudNmzZNRUVFrp+DBw+6ExMAAAAAAK90Ttc22jRjjGu/vMqhbg98rA37j5mYCvBfHn2r4wsvvKB+/fpp6NChDc6z2+2KjIys9QMAAAAAgD+IDgvSrkcuVkigzTV2xT9X67IFX6uqhtVfQFNyq/hq27atbDab8vLyao3n5eUpPj6+wXPLysr05ptv6uabb3Y/JQAAAAAAfiQowKrtD1+keZf3c41tPlioHtM/VlYBb34EmopbxVdQUJAGDRqk5cuXu8acTqeWL1+u1NTUBs99++23VVlZqd/85jenlxQAAAAAAD9z9dBO+nTqyFpjo/66Qs98sdekRIB/cftWx6lTp2rhwoV65ZVXtH37dk2ZMkVlZWW68cYbJUmTJk3StGnTTjrvhRde0GWXXaY2bdqceWoAAAAAAPxEt9gIZc0brwuSY11j8z7eocT0DG59BM5QgLsnTJw4UUeOHNHMmTOVm5urgQMHasmSJa4H3h84cEBWa+0+befOnVq5cqWWLVvWNKkBAAAAAPAzL9wwROv2HdNVz652jfWY/rH2zR0ni8ViYjLAd1kMwzDMDnEqxcXFioqKUlFREQ+6BwAAAAD4NcMw1GXa4lpj3zyQppgIu0mJAO/iTk/k0bc6AgAAAACAhlksFu2bO04je8S4xoY8+ql+/fwaE1MBvoniCwAAAAAAL2OxWPTqTUM1vn8719jXe44qMT1DPnDjFuA1KL4AAAAAAPBSC649W6vSz6811mXaYq3bd4wCDGgEii8AAAAAALxY+1Yhypo3Xuf/7K2PVz27Wl2mLVb6u9+ZmAzwfhRfAAAAAAD4gBdvGKJRPWNqjb35zUElpmeopKLapFSAd+OtjgAAAAAA+Jg1mUd19XO1H3b/xuQUDevW1qREgOfwVkcAAAAAAPzYOV3baO+ccbXGrn1+rbpOyzApEeCdKL4AAAAAAPBBNqtF++aO0xVnd3SNOQ0pMT1DDqfX39wFeATFFwAAAAAAPspisejxqwYo839WfyXdv1hF5Tz3C6D4AgAAAADAx1mtFu2dM04xEXbX2ICHlumsh5apssZhYjLAXBRfAAAAAAD4AZvVom8eSNPUMT1cY8fLq9Vz+hJVVFN+oWWi+AIAAAAAwI/87oLu2jRjjIICfvpX/uQZS3S0tNLEVIA5KL4AAAAAAPAz0WFB2vXIxRqY0Mo1NuiRT/XuhkPmhQJMQPEFAAAAAICfem/KMP1q0E9vffz9298qMT1D3x4sNC8U4EEUXwAAAAAA+Cmr1aK/XjlAr9+cUmv80gVfa/ifP1PmkVKTkgGeYTEMwzA7xKkUFxcrKipKRUVFioyMNDsOAAAAAAA+p9rh1B/f/lYfbD5cazwqJFCbZ46RxWIxKRngHnd6IlZ8AQAAAADQAgTarHrq6rOUOWec7hid5BovOlGtLtMWm5gMaD4UXwAAAAAAtCBWq0V/HJusLbMvVNvwINd4YnqGKmscJiYDmh7FFwAAAAAALVBEcKDWTx9Ta6zn9CXacqjIpERA06P4AgAAAACgBdv64Nha+xPmr9SuvBKT0gBNi+ILAAAAAIAWLNweoKx543XfRcmusQuf/FITn11tYiqgaVB8AQAAAAAATRmVpFkTerv21+47psT0DO3JLzUxFXBmKL4AAAAAAIAk6cZzu2j578+rNZb2xBdKTM/Qx1tyTEoFnD6KLwAAAAAA4JIUE659c8dpTO+4WuNT/rVRW7N58D18C8UXAAAAAACoxWKxaOGkwdr24Fid1amVa/wXf1+pnKIT5gUD3ETxBQAAAAAA6hRmD9D7t5+rKwd1dI2lzv3MxESAeyi+AAAAAABAgx67coBGdG/r2k9Mz5DTaZiYCGgcii8AAAAAAHBKr940tNZ+1/sXyzAov+DdKL4AAAAAAMApWSwWZc4ZV2usy7TFevD/tpmUCDg1ii8AAAAAANAoVqtFux+9WJ3bhLrGXvo6S4npGXJw6yO8EMUXAAAAAABotECbVV/8cbTmXd6v1vjYp740KRFQP4ovAAAAAADgtquHdtLen936uCe/VInpGVqbedTEVEBtFF8AAAAAAOC02KwWfTvzwlpjE59bo8T0DFVUO0xKBfyE4gsAAAAAAJy2qNBAZc0br34domqNJ89YosT0DFXWUIDBPBRfAAAAAADgjP3fXcO1/aGLlBQTVmu85/QlrP6CaSi+AAAAAABAkwgJsmn570dpx8MXKSzI5hpPnrFEhsFbH+F5FF8AAAAAAKBJBQfatO2hi2qNdZm2WAePlZuUCC0VxRcAAAAAAGgWmT9766MkjfjL56z8gkdRfAEAAAAAgGZhtVqUNW+8nvnNINdY0v2LTUyElobiCwAAAAAANKuL+sarTViQJMlpSB9uzjY5EVoKii8AAAAAANDs1tx/gWv77jc3a8YHW01Mg5aC4gsAAAAAADS7QJtVL90wxLX/2pr9WpN51MREaAkovgAAAAAAgEeMTo7Vt7MudO1f/dwavfXNQRMTwd9RfAEAAAAAAI+JCgnUUxMHuvb/9O53Kq2sMS8Q/BrFFwAAAAAA8KjLzuqgt36b6trvO2upLnrqSzmdhomp4I8ovgAAAAAAgMcN7dJaI3vEuPZ35Jao6/2L9f3hYhNTwd9QfAEAAAAAAFO8cuMQ/eVX/WuNjfvbVzpceMKkRPA3FF8AAAAAAMAUFotFVw1OUNa88brvomTX+LB5n8kwuO0RZ47iCwAAAAAAmG7KqCSldm3j2p/23hYT08BfUHwBAAAAAACv8O9bz3Ftv/nNQe3JLzExDfwBxRcAAAAAAPAan04d6dpOe+JLE5PAH1B8AQAAAAAAr9EtNkLXndPZtf9oxvcmpoGvo/gCAAAAAABe5aFL+7i2F361TxOfXW1iGvgyii8AAAAAAOBVLBaL1ky7wLW/dt8x3fDSOhMTwVdRfAEAAAAAAK8THxWs72Zf6NpfsfOIbn11vYmJ4IsovgAAAAAAgFeKDA7Ut7N+Kr+WfZ+nVXsKTEwEX0PxBQAAAAAAvFZUSKA2zxzj2r/2+bUyDMPERPAlFF8AAAAAAMCrtQoN0vTxvVz7/WcvMzENfAnFFwAAAAAA8HqTR3R1bZdU1igxPUNOJyu/0DCKLwAAAAAA4BO+f2hsrf2u9y9WRbXDpDTwBRRfAAAAAADAJ4QGBShzzrhaY8kzlqja4TQpEbwdxRcAAAAAAPAZVqtF++aOU/+OUa6x7g98bGIieDOKLwAAAAAA4FMsFos+unO4okICXWO78kpMTARvRfEFAAAAAAB80uaZY1zbVz6z2sQk8FYUXwAAAAAAwCdZLBb97vxukqSiE9VKTM/gYfeoheILAAAAAAD4rFtGdq21nzxjiQ4dLzcpDbwNxRcAAAAAAPBZEcGBypo3Xh1ahbjGhv/5cxMTwZtQfAEAAAAAAJ/3dfr5Gt+vnWs/MT1Djy/baWIieAOKLwAAAAAA4BcevLRPrf2/f7ZHiekZJqWBN6D4AgAAAAAAfqFtuF17Hr1YL94wuNb4qj0FJiWC2Si+AAAAAACA3wiwWXV+cpz2zR3nGrv2+bUmJoKZKL4AAAAAAIDfsVgseviyvq79A0d502NLRPEFAAAAAAD80m9SOrm2Rz72uTbsP25iGpiB4gsAAAAAAPgli8Wix37V37V/xT9X6XDhCRMTwdMovgAAAAAAgN+6cnCCZk3o7dofNu8z1TicJiaCJ1F8AQAAAAAAv3bjuV302/O6uva7PfCxiWngSadVfC1YsECJiYkKDg5WSkqK1q1b1+D8wsJC3XHHHWrXrp3sdrt69OihxYsXn1ZgAAAAAAAAd027uJcCrBbX/jlzlpuYBp7idvG1aNEiTZ06VbNmzdLGjRs1YMAAjR07Vvn5+XXOr6qq0pgxY5SVlaV33nlHO3fu1MKFC9WhQ4czDg8AAAAAANBYux+92LWdW1yhxPQM7T1SamIiNDeLYRiGOyekpKRoyJAhmj9/viTJ6XQqISFBd911l9LT00+a/8wzz+ixxx7Tjh07FBgYeFohi4uLFRUVpaKiIkVGRp7WZwAAAAAAAEjSxGdXa+2+Y679fXPHyWKxNHAGvIk7PZFbK76qqqq0YcMGpaWl/fQBVqvS0tK0evXqOs/56KOPlJqaqjvuuENxcXHq27ev5syZI4fDUe/vqaysVHFxca0fAAAAAACAprDot6l66NI+rv3Ve4+amAbNya3iq6CgQA6HQ3FxcbXG4+LilJubW+c5mZmZeuedd+RwOLR48WLNmDFDjz/+uB555JF6f8/cuXMVFRXl+klISHAnJgAAAAAAQIMmpSa6tq99fq3W/WwFGPxHs7/V0el0KjY2Vs8995wGDRqkiRMn6oEHHtAzzzxT7znTpk1TUVGR6+fgwYPNHRMAAAAAALQw912U7Nq+6tnV2ppdZGIaNAe3iq+2bdvKZrMpLy+v1nheXp7i4+PrPKddu3bq0aOHbDaba6xXr17Kzc1VVVVVnefY7XZFRkbW+gEAAAAAAGhKU0Yl6YXrB7v2f/H3lXI43XoUOrycW8VXUFCQBg0apOXLf3rlp9Pp1PLly5WamlrnOeeee6727Nkjp9PpGtu1a5fatWunoKCg04wNAAAAAABw5i7oFaerBnd07Sfdv5jyy4+4favj1KlTtXDhQr3yyivavn27pkyZorKyMt14442SpEmTJmnatGmu+VOmTNGxY8d09913a9euXcrIyNCcOXN0xx13NN23AAAAAAAAOE3zLu9fa3/8374yKQmaWoC7J0ycOFFHjhzRzJkzlZubq4EDB2rJkiWuB94fOHBAVutPfVpCQoKWLl2qe++9V/3791eHDh10991367777mu6bwEAAAAAAHCarFaLsuaN14i/fKaDx05oR26JnE5DVqvF7Gg4QxbDMLx+/V5xcbGioqJUVFTE874AAAAAAECzKDpRrQEPLnPtZ80bb2Ia1MednqjZ3+oIAAAAAADgC6JCAhVo+2mV1websk1Mg6ZA8QUAAAAAAPBf3z90kWv7nkWbtSe/xMQ0OFMUXwAAAAAAAP8VaLPq1ZuGuvbTnvhSPvCUKNSD4gsAAAAAAOBnRvaI0W9HdnXt/3XZThPT4ExQfAEAAAAAAPyP9IuTXdsLPt/Lqi8fRfEFAAAAAADwPywWi166YYhrf9KL60xMg9NF8QUAAAAAAFCH0cmxru2vdheYmASni+ILAAAAAACgHi/d+NOqr3+s2GNiEpwOii8AAAAAAIB6jOoRozZhQZKkvyzZqf1Hy0xOBHdQfAEAAAAAANTDYrFo0W9TXfvnPbbCvDBwG8UXAAAAAABAA7rFhuuGYYmu/cT0DPPCwC0UXwAAAAAAAKcw+5I+tfYT0zPkdBompUFjUXwBAAAAAAA0wr6542rt/+LvK01Kgsai+AIAAAAAAGgEi8WizDnjFBz4Q53yfU6xPvk+z+RUaAjFFwAAAAAAQCNZrRatnZbm2r/l1fUmpsGpUHwBAAAAAAC4ISo0UC/dMMS1v3w7q768FcUXAAAAAACAm0Ynx7q2b35lvXKKTpiYBvWh+AIAAAAAADgNr9401LWdOvczE5OgPhRfAAAAAAAAp2FkjxhdMqC9az8xPUOGYZiYCP+L4gsAAAAAAOA0PXxp31r7Mz/cZlIS1IXiCwAAAAAA4DRFhQYqc8441/5ra/az6suLUHwBAAAAAACcAavVoo/uPNe1/9b6gyamwc9RfAEAAAAAAJyh/h1bubbve3eLeUFQC8UXAAAAAABAE7j7gu6u7ZKKahOT4EcUXwAAAAAAAE3g9tFJru1+s5fxrC8vQPEFAAAAAADQBOwBNl2b0sm1v2LXERPTQKL4AgAAAAAAaDJzftnPtX3jS9+YmAQSxRcAAAAAAECTSusV59r++/LdJiYBxRcAAAAAAEATWvDrs1zbj3+yi2d9mYjiCwAAAAAAoAnZA2x645YU1/51L6wzMU3LRvEFAAAAAADQxIYltXVtr9xTwKovk1B8AQAAAAAANIOv/jTatf3kJ7tMTNJyUXwBAAAAAAA0g4TWoa7tv322x8QkLRfFFwAAAAAAQDN5+uqBru073thoXpAWiuILAAAAAACgmVw6sINrO+O7HOUWVZiYpuWh+AIAAAAAAGhGX/xxlGs7dd5y84K0QBRfAAAAAAAAzahzmzAN7hwtSTIMadWeApMTtRwUXwAAAAAAAM3s9ckpru0/vvOdiUlaFoovAAAAAACAZhYcaNPvLuguScouPKEah9PkRC0DxRcAAAAAAIAHTB7RxbV91783mZik5aD4AgAAAAAA8IDI4EBdfvYPb3n8eGuuyWlaBoovAAAAAAAAD7k3rYdr2zAME5O0DBRfAAAAAAAAHtI6LMi1faSk0sQkLQPFFwAAAAAAgIeE2QNc25NeXGdikpaB4gsAAAAAAMCDesSFS5J25JZo9d6jJqfxbxRfAAAAAAAAHvTazSmu7WsWrjExif+j+AIAAAAAAPCguMhg/eHCnx5yv3x7nolp/BvFFwAAAAAAgIfdMbqba3vRNwdNTOLfKL4AAAAAAAA8zGKxaFy/eEnSsu/zZBiGyYn8E8UXAAAAAACACW4e3sW1/ddlO01M4r8ovgAAAAAAAEwwqHNr1/aCz/eamMR/UXwBAAAAAACY5NFf9pUktQ4LMjmJf6L4AgAAAAAAMMnYPj885+tYWZVOVDlMTuN/KL4AAAAAAABM0uZnK73e3sDbHZsaxRcAAAAAAIBJLBaLQgJtkqSZH27j7Y5NjOILAAAAAADARK/cNNS1velgoXlB/BDFFwAAAAAAgImGdvnp7Y5zMrabmMT/UHwBAAAAAACY7Mdnfa3ff1zfHy42OY3/oPgCAAAAAAAw2b9uSXFtj/vbVyYm8S8UXwAAAAAAACZLjo/U+H7tzI7hdyi+AAAAAAAAvMAdo7u5tp1O3u7YFCi+AAAAAAAAvED3uHDX9vr9x01M4j8ovgAAAAAAALxAoO2nmuaqZ1fLMFj1daYovgAAAAAAALzE7Am9Xdv5JZUmJvEPFF8AAAAAAABe4oZzu7i2d+SWmJjEP1B8AQAAAAAAeKHrX1xndgSfR/EFAAAAAADgRS4d2N61XeNwmpjE91F8AQAAAAAAeJE5v+zn2t5/rNzEJL6P4gsAAAAAAMCLhNkDXNuvrd5vYhLfR/EFAAAAAADgZcKCbJKkl1dlmRvEx1F8AQAAAAAAeJk5l/c79SScEsUXAAAAAACAl7mgV5xre8XOfBOT+DaKLwAAAAAAAC8T/rPnfN3w0jcmJvFtFF8AAAAAAABeaPaE3q7tA0d5u+PpoPgCAAAAAADwQtcPS3Rtj3zsc/OC+DCKLwAAAAAAAC9ksVh0Xo8Y1361w2liGt9E8QUAAAAAAOCl/n7tWa7tDzcfNjGJbzqt4mvBggVKTExUcHCwUlJStG7dunrnvvzyy7JYLLV+goODTzswAAAAAABASxEZHKjObUIlSY8t3WFyGt/jdvG1aNEiTZ06VbNmzdLGjRs1YMAAjR07Vvn59b9aMzIyUjk5Oa6f/fv3n1FoAAAAAACAluLKQR0lSXnFlSYn8T1uF19PPPGEbrnlFt14443q3bu3nnnmGYWGhurFF1+s9xyLxaL4+HjXT1xc3BmFBgAAAAAAaCkuO6uDa/uNtQdMTOJ73Cq+qqqqtGHDBqWlpf30AVar0tLStHr16nrPKy0tVefOnZWQkKBLL71U27Zta/D3VFZWqri4uNYPAAAAAABAS9QxOtS1ff/7W0xM4nvcKr4KCgrkcDhOWrEVFxen3NzcOs/p2bOnXnzxRX344Yd6/fXX5XQ6NWzYMB06dKje3zN37lxFRUW5fhISEtyJCQAAAAAA4FceGNfL7Ag+qdnf6piamqpJkyZp4MCBOu+88/Tee+8pJiZGzz77bL3nTJs2TUVFRa6fgwcPNndMAAAAAAAArzWm90+LkAzDMDGJbwlwZ3Lbtm1ls9mUl5dXazwvL0/x8fGN+ozAwECdddZZ2rNnT71z7Ha77Ha7O9EAAAAAAAD8VnxUsGt7V16pesZHmJjGd7i14isoKEiDBg3S8uXLXWNOp1PLly9Xampqoz7D4XBoy5YtateunXtJAQAAAAAAWqjgQJtahQZKktbvP2ZyGt/h9q2OU6dO1cKFC/XKK69o+/btmjJlisrKynTjjTdKkiZNmqRp06a55j/00ENatmyZMjMztXHjRv3mN7/R/v37NXny5Kb7FgAAAAAAAC3EY0t3mh3BZ7h1q6MkTZw4UUeOHNHMmTOVm5urgQMHasmSJa4H3h84cEBW60992vHjx3XLLbcoNzdX0dHRGjRokFatWqXevXs33bcAAAAAAADwc+d2a6uM73JUWF6t0soahdvdrnVaHIvhA09EKy4uVlRUlIqKihQZGWl2HAAAAAAAAI87dLxcw//8uSTphmGJmn1JH5MTmcOdnqjZ3+oIAAAAAACAM9cxOlQBVosk6eVVWeaG8REUXwAAAAAAAD7i9tHdzI7gUyi+AAAAAAAAfMSk1M6u7QWf7zExiW+g+AIAAAAAAPARbcPtru1vDxaaF8RHUHwBAAAAAAD4kCmjkiRJK/cUmJzE+1F8AQAAAAAA+JBhSW0kSeVVDhWUVpqcxrtRfAEAAAAAAPiQYUltXdv3LtpsXhAfQPEFAAAAAADgQ2xWi3rGRUiSvj9cbHIa70bxBQAAAAAA4GOuTekkSTpaViWn0zA5jfei+AIAAAAAAPAxlwxo79rOLjxhYhLvRvEFAAAAAADgY6LDghQc+EOt8/6mbJPTeC+KLwAAAAAAAB9UUe2UJD3xyS6Tk3gvii8AAAAAAAAf9MRVA1zbe4+UmpjEe1F8AQAAAAAA+KDLz+7o2k5/9zsTk3gvii8AAAAAAAAf1btdpCQpKiTQ5CTeieILAAAAAADAR00ckiBJ+nR7vslJvBPFFwAAAAAAgI/q1CbU7AhejeILAAAAAADAR52dEO3arqpxmpjEO1F8AQAAAAAA+Kgwu821veDzPSYm8U4UXwAAAAAAAD4qwGZVgNUiSXp6+W45nYbJibwLxRcAAAAAAIAPW/TbVNf2x1tzTUzifSi+AAAAAAAAfNigzj895+uLXbzd8ecovgAAAAAAAHxct9hwSdISVnzVQvEFAAAAAADg4y4Z0F6SZP3v877wA4ovAAAAAAAAH/erQR0lSYXl1SqtrDE5jfeg+AIAAAAAAPBxcZHBru0pr28wMYl3ofgCAAAAAADwcTarRfH/Lb++2l1gchrvQfEFAAAAAADgB+Zfe5Zre92+YyYm8R4UXwAAAAAAAH5gcGJr1/ZVz642MYn3oPgCAAAAAADwE8nxEa7taofTxCTegeILAAAAAADATzx33WDX9pbsIhOTeAeKLwAAAAAAAD/RqU2oa3tPXqmJSbwDxRcAAAAAAIAfiQ4NlCR9seuIyUnMR/EFAAAAAADgR0b2iJEkbTpw3OQk5qP4AgAAAAAA8COje8ZKkg4XVcjpNExOYy6KLwAAAAAAAD+S1jvOtZ1deMLEJOaj+AIAAAAAAPAj4fYAhQTaJEl/WbrT5DTmovgCAAAAAADwM93jwiVJ//ftYZOTmIviCwAAAAAAwM/cMCzRtV3jcJoXxGQUXwAAAAAAAH5mwoD2ru38kkoTk5iL4gsAAAAAAMDPBNqsCgv64Tlfh1vwA+4pvgAAAAAAAPxQWZWj1v9tiSi+AAAAAAAA/NDQxNaSpNkfbTM5iXkovgAAAAAAAPyQPfCH2mdfQZmKK6pNTmMOii8AAAAAAAA/9OTEga7tV1dlmZbDTBRfAAAAAAAAfqhtuF1DE1vLHmBV+1YhZscxRYDZAQAAAAAAANA8Fv32HFksFrNjmIYVXwAAAAAAAH6qJZdeEsUXAAAAAAAA/BTFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPwSxRcAAAAAAAD8EsUXAAAAAAAA/BLFFwAAAAAAAPxSgNkBGsMwDElScXGxyUkAAAAAAABgph/7oR/7oob4RPFVUlIiSUpISDA5CQAAAAAAALxBSUmJoqKiGpxjMRpTj5nM6XTq8OHDioiIkMViMTtOkyguLlZCQoIOHjyoyMhIs+MAPotrCWgaXEtA0+F6ApoG1xLQNPzxWjIMQyUlJWrfvr2s1oaf4uUTK76sVqs6duxodoxmERkZ6Td/4QFm4loCmgbXEtB0uJ6ApsG1BDQNf7uWTrXS60c83B4AAAAAAAB+ieILAAAAAAAAfoniyyR2u12zZs2S3W43Owrg07iWgKbBtQQ0Ha4noGlwLQFNo6VfSz7xcHsAAAAAAADAXaz4AgAAAAAAgF+i+AIAAAAAAIBfovgCAAAAAACAX6L4AgAAAAAAgF+i+AIAAAAAAIBfovhqRgsWLFBiYqKCg4OVkpKidevWNTj/7bffVnJysoKDg9WvXz8tXrzYQ0kB7+bOtbRw4UKNGDFC0dHRio6OVlpa2imvPaClcPefSz968803ZbFYdNlllzVvQMCHuHs9FRYW6o477lC7du1kt9vVo0cP/qwHyP1r6amnnlLPnj0VEhKihIQE3XvvvaqoqPBQWsA7ffnll5owYYLat28vi8WiDz744JTnrFixQmeffbbsdru6deuml19+udlzmoXiq5ksWrRIU6dO1axZs7Rx40YNGDBAY8eOVX5+fp3zV61apWuuuUY333yzNm3apMsuu0yXXXaZtm7d6uHkgHdx91pasWKFrrnmGn3++edavXq1EhISdOGFFyo7O9vDyQHv4u619KOsrCz94Q9/0IgRIzyUFPB+7l5PVVVVGjNmjLKysvTOO+9o586dWrhwoTp06ODh5IB3cfdaeuONN5Senq5Zs2Zp+/bteuGFF7Ro0SLdf//9Hk4OeJeysjINGDBACxYsaNT8ffv2afz48Ro9erQ2b96se+65R5MnT9bSpUubOak5LIZhGGaH8EcpKSkaMmSI5s+fL0lyOp1KSEjQXXfdpfT09JPmT5w4UWVlZfrPf/7jGjvnnHM0cOBAPfPMMx7LDXgbd6+l/+VwOBQdHa358+dr0qRJzR0X8Fqncy05HA6NHDlSN910k7766isVFhY26r8gAv7O3evpmWee0WOPPaYdO3YoMDDQ03EBr+XutXTnnXdq+/btWr58uWvs97//vdauXauVK1d6LDfgzSwWi95///0GV+rfd999ysjIqLXQ5uqrr1ZhYaGWLFnigZSexYqvZlBVVaUNGzYoLS3NNWa1WpWWlqbVq1fXec7q1atrzZeksWPH1jsfaAlO51r6X+Xl5aqurlbr1q2bKybg9U73WnrooYcUGxurm2++2RMxAZ9wOtfTRx99pNTUVN1xxx2Ki4tT3759NWfOHDkcDk/FBrzO6VxLw4YN04YNG1y3Q2ZmZmrx4sUaN26cRzID/qKl9Q8BZgfwRwUFBXI4HIqLi6s1HhcXpx07dtR5Tm5ubp3zc3Nzmy0n4O1O51r6X/fdd5/at29/0t/YgZbkdK6llStX6oUXXtDmzZs9kBDwHadzPWVmZuqzzz7Tr3/9ay1evFh79uzR7bffrurqas2aNcsTsQGvczrX0rXXXquCggINHz5chmGopqZGt912G7c6Am6qr38oLi7WiRMnFBISYlKy5sGKLwB+a968eXrzzTf1/vvvKzg42Ow4gM8oKSnRddddp4ULF6pt27ZmxwF8ntPpVGxsrJ577jkNGjRIEydO1AMPPMDjLAA3rVixQnPmzNE//vEPbdy4Ue+9954yMjL08MMPmx0NgBdjxVczaNu2rWw2m/Ly8mqN5+XlKT4+vs5z4uPj3ZoPtASncy396K9//avmzZunTz/9VP3792/OmIDXc/da2rt3r7KysjRhwgTXmNPplCQFBARo586dSkpKat7QgJc6nX82tWvXToGBgbLZbK6xXr16KTc3V1VVVQoKCmrWzIA3Op1racaMGbruuus0efJkSVK/fv1UVlamW2+9VQ888ICsVtZ1AI1RX/8QGRnpd6u9JFZ8NYugoCANGjSo1kMXnU6nli9frtTU1DrPSU1NrTVfkj755JN65wMtwelcS5L0l7/8RQ8//LCWLFmiwYMHeyIq4NXcvZaSk5O1ZcsWbd682fVzySWXuN78k5CQ4Mn4gFc5nX82nXvuudqzZ4+rQJakXbt2qV27dpReaLFO51oqLy8/qdz6sVDmnW1A47W4/sFAs3jzzTcNu91uvPzyy8b3339v3HrrrUarVq2M3NxcwzAM47rrrjPS09Nd87/++msjICDA+Otf/2ps377dmDVrlhEYGGhs2bLFrK8AeAV3r6V58+YZQUFBxjvvvGPk5OS4fkpKSsz6CoBXcPda+l/XX3+9cemll3ooLeDd3L2eDhw4YERERBh33nmnsXPnTuM///mPERsbazzyyCNmfQXAK7h7Lc2aNcuIiIgw/v3vfxuZmZnGsmXLjKSkJOOqq64y6ysAXqGkpMTYtGmTsWnTJkOS8cQTTxibNm0y9u/fbxiGYaSnpxvXXXeda35mZqYRGhpq/PGPfzS2b99uLFiwwLDZbMaSJUvM+grNilsdm8nEiRN15MgRzZw5U7m5uRo4cKCWLFnieoDcgQMHav3XimHDhumNN97Q9OnTdf/996t79+764IMP1LdvX7O+AuAV3L2W/vnPf6qqqkq/+tWvan3OrFmzNHv2bE9GB7yKu9cSgPq5ez0lJCRo6dKluvfee9W/f3916NBBd999t+677z6zvgLgFdy9lqZPny6LxaLp06crOztbMTExmjBhgh599FGzvgLgFdavX6/Ro0e79qdOnSpJuv766/Xyyy8rJydHBw4ccB3v0qWLMjIydO+99+rpp59Wx44d9fzzz2vs2LEez+4JFsNgTSgAAAAAAAD8D/9pFwAAAAAAAH6J4gsAAAAAAAB+ieILAAAAAAAAfoniCwAAAAAAAH6J4gsAAAAAAAB+ieILAAAAAAAAfoniCwAAAAAAAH6J4gsAAAAAAAB+ieILAAAAAAAAfoniCwAAAAAAAH6J4gsAAAAAAAB+6f8BWztwCJLBLUcAAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"test_pairs = pd.read_parquet(\"/kaggle/input/hackathon-files-for-participants-ozon/test_pairs_wo_target.parquet\")\ntest_etl = pd.read_parquet(\"/kaggle/input/hackathon-files-for-participants-ozon/test_data.parquet\")","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:31:32.836414Z","start_time":"2023-05-19T06:31:31.181747Z"},"execution":{"iopub.status.busy":"2023-05-30T20:12:06.888895Z","iopub.execute_input":"2023-05-30T20:12:06.889521Z","iopub.status.idle":"2023-05-30T20:12:08.581624Z","shell.execute_reply.started":"2023-05-30T20:12:06.889478Z","shell.execute_reply":"2023-05-30T20:12:08.580629Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"Generate the same features as for train","metadata":{}},{"cell_type":"code","source":"test_features = (\n    test_pairs\n    .merge(\n        test_etl\n        .add_suffix('1'),\n        on=\"variantid1\"\n    )\n    .merge(\n        test_etl\n        .add_suffix('2'),\n        on=\"variantid2\"\n    )\n)","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:31:44.061466Z","start_time":"2023-05-19T06:31:44.008543Z"},"execution":{"iopub.status.busy":"2023-05-30T20:12:08.583707Z","iopub.execute_input":"2023-05-30T20:12:08.584075Z","iopub.status.idle":"2023-05-30T20:12:08.644340Z","shell.execute_reply.started":"2023-05-30T20:12:08.584040Z","shell.execute_reply":"2023-05-30T20:12:08.643406Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"test_features.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:12:09.003894Z","iopub.execute_input":"2023-05-30T20:12:09.004247Z","iopub.status.idle":"2023-05-30T20:12:09.044380Z","shell.execute_reply.started":"2023-05-30T20:12:09.004220Z","shell.execute_reply":"2023-05-30T20:12:09.043485Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"   variantid1  variantid2                                              name1  \\\n0    52076340   290590137  Батарейка AAA щелочная Perfeo LR03/10BL Super ...   \n1    64525522   204128919  Смартфон Ulefone Armor X5 3/32 ГБ, черный, кра...   \n\n                                         categories1           color_parsed1  \\\n0  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...                    None   \n1  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Смартфо...  [черный, red, красный]   \n\n                           pic_embeddings_resnet_v11  \\\n0  [[0.15417035, 0.41160947, 0.2213532, -0.019731...   \n1  [[-0.239386, -0.8332473, -0.08384809, 0.071721...   \n\n                      main_pic_embeddings_resnet_v11  \\\n0  [[0.04763528, -0.20136409, 0.29605597, 0.26453...   \n1  [[-0.27325493, -0.6696304, 0.027148303, 0.0785...   \n\n                                       name_bert_641  \\\n0  [-0.28437558, 0.60909724, 0.5972025, -0.523296...   \n1  [-0.45766184, 0.5528555, 0.26298037, -0.663931...   \n\n                  characteristic_attributes_mapping1  \\\n0  {\"Напряжение, В\":[\"1.5\"],\"Бренд\":[\"Perfeo\"],\"Т...   \n1  {\"Операционная система\":[\"Android\"],\"Защищенно...   \n\n                                               name2  \\\n0  Батарейка AAA щелочная Perfeo LR03/2BL mini Su...   \n1  Смартфон Ulefone Armor X3 2/32 ГБ, черный, кра...   \n\n                                         categories2           color_parsed2  \\\n0  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...                    None   \n1  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Смартфо...  [черный, red, красный]   \n\n                           pic_embeddings_resnet_v12  \\\n0  [[-0.025554053, 0.012488857, 0.43989864, -0.10...   \n1  [[-0.071279265, -0.99063504, -0.3939417, 0.886...   \n\n                      main_pic_embeddings_resnet_v12  \\\n0  [[0.06223978, -0.16145544, 0.26409012, 0.24271...   \n1  [[-0.15358369, -0.8256463, -0.054863703, 0.453...   \n\n                                       name_bert_642  \\\n0  [-0.3380968, 0.6156224, 0.6428071, -0.57499236...   \n1  [-0.4489074, 0.6278857, 0.33072582, -0.6749875...   \n\n                  characteristic_attributes_mapping2  \n0  {\"Форм-фактор батареи\":[\"AAA\"],\"Химический тип...  \n1  {\"Встроенная память\":[\"32 ГБ\"],\"Видеопроцессор...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variantid1</th>\n      <th>variantid2</th>\n      <th>name1</th>\n      <th>categories1</th>\n      <th>color_parsed1</th>\n      <th>pic_embeddings_resnet_v11</th>\n      <th>main_pic_embeddings_resnet_v11</th>\n      <th>name_bert_641</th>\n      <th>characteristic_attributes_mapping1</th>\n      <th>name2</th>\n      <th>categories2</th>\n      <th>color_parsed2</th>\n      <th>pic_embeddings_resnet_v12</th>\n      <th>main_pic_embeddings_resnet_v12</th>\n      <th>name_bert_642</th>\n      <th>characteristic_attributes_mapping2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52076340</td>\n      <td>290590137</td>\n      <td>Батарейка AAA щелочная Perfeo LR03/10BL Super ...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...</td>\n      <td>None</td>\n      <td>[[0.15417035, 0.41160947, 0.2213532, -0.019731...</td>\n      <td>[[0.04763528, -0.20136409, 0.29605597, 0.26453...</td>\n      <td>[-0.28437558, 0.60909724, 0.5972025, -0.523296...</td>\n      <td>{\"Напряжение, В\":[\"1.5\"],\"Бренд\":[\"Perfeo\"],\"Т...</td>\n      <td>Батарейка AAA щелочная Perfeo LR03/2BL mini Su...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...</td>\n      <td>None</td>\n      <td>[[-0.025554053, 0.012488857, 0.43989864, -0.10...</td>\n      <td>[[0.06223978, -0.16145544, 0.26409012, 0.24271...</td>\n      <td>[-0.3380968, 0.6156224, 0.6428071, -0.57499236...</td>\n      <td>{\"Форм-фактор батареи\":[\"AAA\"],\"Химический тип...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>64525522</td>\n      <td>204128919</td>\n      <td>Смартфон Ulefone Armor X5 3/32 ГБ, черный, кра...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Смартфо...</td>\n      <td>[черный, red, красный]</td>\n      <td>[[-0.239386, -0.8332473, -0.08384809, 0.071721...</td>\n      <td>[[-0.27325493, -0.6696304, 0.027148303, 0.0785...</td>\n      <td>[-0.45766184, 0.5528555, 0.26298037, -0.663931...</td>\n      <td>{\"Операционная система\":[\"Android\"],\"Защищенно...</td>\n      <td>Смартфон Ulefone Armor X3 2/32 ГБ, черный, кра...</td>\n      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Смартфо...</td>\n      <td>[черный, red, красный]</td>\n      <td>[[-0.071279265, -0.99063504, -0.3939417, 0.886...</td>\n      <td>[[-0.15358369, -0.8256463, -0.054863703, 0.453...</td>\n      <td>[-0.4489074, 0.6278857, 0.33072582, -0.6749875...</td>\n      <td>{\"Встроенная память\":[\"32 ГБ\"],\"Видеопроцессор...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#! Переписать бы через apply\n\ntest_features['main_cos_dist'] = np.nan\ntest_features['main_evc_dist'] = np.nan\n#from scipy.spatial.distance import cdist\nfrom scipy import spatial\nfor ind in tqdm(test_features.index):\n    #print(ind)\n    cosine_val = cosine(test_features['main_pic_embeddings_resnet_v11'][ind][0], test_features['main_pic_embeddings_resnet_v12'][ind][0])\n    evlid_val = euclidean(test_features['main_pic_embeddings_resnet_v11'][ind][0], test_features['main_pic_embeddings_resnet_v12'][ind][0])\n    test_features.at[ind, 'main_cos_dist'] = cosine_val\n    test_features.at[ind, 'main_evc_dist'] = evlid_val","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:12:12.031165Z","iopub.execute_input":"2023-05-30T20:12:12.032142Z","iopub.status.idle":"2023-05-30T20:12:16.254512Z","shell.execute_reply.started":"2023-05-30T20:12:12.032100Z","shell.execute_reply":"2023-05-30T20:12:16.253018Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stderr","text":"100%|██████████| 18084/18084 [00:04<00:00, 4297.02it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_features[[\"pic_dist_0_perc\", \"pic_dist_25_perc\", \"pic_dist_50_perc\"]] = (\n    test_features[[\"main_pic_embeddings_resnet_v11\", \"main_pic_embeddings_resnet_v12\"]].apply(\n        lambda x: pd.Series(get_pic_features_func(*x)), axis=1\n    )\n)\n\ntest_features[[\"euclidean_name_bert_dist\", \"cosine_name_bert_dist\"]] = (\n    test_features[[\"name_bert_641\", \"name_bert_642\"]].apply(\n        lambda x: pd.Series(text_dense_distances(*x)), axis=1\n    )\n)","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:32:25.287137Z","start_time":"2023-05-19T06:32:10.342926Z"},"execution":{"iopub.status.busy":"2023-05-30T20:12:17.770190Z","iopub.execute_input":"2023-05-30T20:12:17.771566Z","iopub.status.idle":"2023-05-30T20:12:33.766437Z","shell.execute_reply.started":"2023-05-30T20:12:17.771525Z","shell.execute_reply":"2023-05-30T20:12:33.765482Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"test_features[\"cat3\"] = test_features[\"categories1\"].apply(lambda x: json.loads(x)[\"3\"])","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:32:34.415102Z","start_time":"2023-05-19T06:32:34.354763Z"},"execution":{"iopub.status.busy":"2023-05-30T20:12:59.323661Z","iopub.execute_input":"2023-05-30T20:12:59.324252Z","iopub.status.idle":"2023-05-30T20:12:59.412867Z","shell.execute_reply.started":"2023-05-30T20:12:59.324220Z","shell.execute_reply":"2023-05-30T20:12:59.411956Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"test_features.shape","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:32:37.601571Z","start_time":"2023-05-19T06:32:37.596721Z"},"execution":{"iopub.status.busy":"2023-05-30T20:12:59.690149Z","iopub.execute_input":"2023-05-30T20:12:59.690824Z","iopub.status.idle":"2023-05-30T20:12:59.696611Z","shell.execute_reply.started":"2023-05-30T20:12:59.690791Z","shell.execute_reply":"2023-05-30T20:12:59.695741Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"(18084, 24)"},"metadata":{}}]},{"cell_type":"code","source":"test_cat3_counts = test_features[\"cat3\"].value_counts().to_dict()\n\ncntr = 0\nfor cat3 in test_cat3_counts:\n    if test_cat3_counts[cat3] < 50:\n        cntr += test_cat3_counts[cat3]\n        \ncntr","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:32:40.679595Z","start_time":"2023-05-19T06:32:40.668656Z"},"execution":{"iopub.status.busy":"2023-05-30T20:13:00.441667Z","iopub.execute_input":"2023-05-30T20:13:00.442020Z","iopub.status.idle":"2023-05-30T20:13:00.454988Z","shell.execute_reply.started":"2023-05-30T20:13:00.441992Z","shell.execute_reply":"2023-05-30T20:13:00.454011Z"},"trusted":true},"execution_count":112,"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"537"},"metadata":{}}]},{"cell_type":"code","source":"test_features[\"cat3_grouped\"] = test_features[\"cat3\"].apply(lambda x: x if test_cat3_counts[x] > 50 else \"rest\")\n# btw you can rename to `rest` the same categories that were assigned to this group in train","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:34:07.170273Z","start_time":"2023-05-19T06:34:07.157474Z"},"execution":{"iopub.status.busy":"2023-05-30T20:13:01.014890Z","iopub.execute_input":"2023-05-30T20:13:01.015778Z","iopub.status.idle":"2023-05-30T20:13:01.028567Z","shell.execute_reply.started":"2023-05-30T20:13:01.015734Z","shell.execute_reply":"2023-05-30T20:13:01.027618Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"# добавим долю совпадающих численных значений\n\ntest_features[[\"numerical_intersection_percent\"]] = (\n    test_features[[\"name1\", \"name2\"]].apply(\n        lambda x: pd.Series(texts_to_intersection_percent(*x)), axis=1\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:14:43.851873Z","iopub.execute_input":"2023-05-30T20:14:43.852246Z","iopub.status.idle":"2023-05-30T20:14:49.652878Z","shell.execute_reply.started":"2023-05-30T20:14:43.852216Z","shell.execute_reply":"2023-05-30T20:14:49.651939Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"submission_example = test_features.copy()","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:34:11.446732Z","start_time":"2023-05-19T06:34:11.382287Z"},"execution":{"iopub.status.busy":"2023-05-30T20:14:49.654968Z","iopub.execute_input":"2023-05-30T20:14:49.655327Z","iopub.status.idle":"2023-05-30T20:14:49.670470Z","shell.execute_reply.started":"2023-05-30T20:14:49.655277Z","shell.execute_reply":"2023-05-30T20:14:49.669539Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catboost_submission_scores = model.predict_proba(test_features[feats])[:, 1]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T20:15:56.460414Z","iopub.execute_input":"2023-05-30T20:15:56.461242Z","iopub.status.idle":"2023-05-30T20:15:56.493189Z","shell.execute_reply.started":"2023-05-30T20:15:56.461209Z","shell.execute_reply":"2023-05-30T20:15:56.492306Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# y не будет использоваться. Хотел сделать его списком None, но даталоадер ругается если элементы разных типов\n# поэтому сделал списком -1 \nsubmission_dist_dataset = DistDataset(test_features[dist_feats], [-1]*len(test_features))\nsubmission_dist_dataloader = DataLoader(submission_dist_dataset, batch_size=len(submission_dist_dataset), shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:03:34.495855Z","iopub.execute_input":"2023-05-30T21:03:34.496237Z","iopub.status.idle":"2023-05-30T21:03:34.533641Z","shell.execute_reply.started":"2023-05-30T21:03:34.496205Z","shell.execute_reply":"2023-05-30T21:03:34.532730Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"dist_model_submission_scores = eval_model(net_model, submission_dist_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:03:35.116661Z","iopub.execute_input":"2023-05-30T21:03:35.117049Z","iopub.status.idle":"2023-05-30T21:03:35.302350Z","shell.execute_reply.started":"2023-05-30T21:03:35.117019Z","shell.execute_reply":"2023-05-30T21:03:35.301414Z"},"trusted":true},"execution_count":150,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"len(dist_model_submission_scores)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:03:37.203788Z","iopub.execute_input":"2023-05-30T21:03:37.204149Z","iopub.status.idle":"2023-05-30T21:03:37.211087Z","shell.execute_reply.started":"2023-05-30T21:03:37.204121Z","shell.execute_reply":"2023-05-30T21:03:37.209999Z"},"trusted":true},"execution_count":151,"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"18084"},"metadata":{}}]},{"cell_type":"code","source":"submission_siam_dataset = SiamiseMainImgDataset(\n    test_features['main_pic_embeddings_resnet_v11'],\n    test_features['main_pic_embeddings_resnet_v12'],\n    [-1]*len(test_features))\n\nsubmission_siam_loader = DataLoader(submission_siam_dataset, batch_size=100, shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:15:27.246081Z","iopub.execute_input":"2023-05-30T21:15:27.246504Z","iopub.status.idle":"2023-05-30T21:15:27.261110Z","shell.execute_reply.started":"2023-05-30T21:15:27.246471Z","shell.execute_reply":"2023-05-30T21:15:27.260091Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"sub_siam_score_list = test_siam_model(siam_imgs_net, device, submission_siam_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:16:59.433070Z","iopub.execute_input":"2023-05-30T21:16:59.433466Z","iopub.status.idle":"2023-05-30T21:16:59.853257Z","shell.execute_reply.started":"2023-05-30T21:16:59.433434Z","shell.execute_reply":"2023-05-30T21:16:59.852302Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Важно соблюсти тот же порядок, что и при обучении! (понимаю, что я капитан очевидность)\nsubmission_scores_list = [dist_model_submission_scores, catboost_submission_scores, sub_siam_score_list, list(test_features['main_cos_dist'])] ","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:20:31.746190Z","iopub.execute_input":"2023-05-30T21:20:31.746780Z","iopub.status.idle":"2023-05-30T21:20:31.758009Z","shell.execute_reply.started":"2023-05-30T21:20:31.746739Z","shell.execute_reply":"2023-05-30T21:20:31.757034Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"submission_metadataset = MetaDataset(submission_scores_list, [-1]*len(submission_scores_list[0]))\nsub_meta_dataloader = DataLoader(submission_metadataset, batch_size=len(submission_scores_list), shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:20:33.823477Z","iopub.execute_input":"2023-05-30T21:20:33.824146Z","iopub.status.idle":"2023-05-30T21:20:33.835838Z","shell.execute_reply.started":"2023-05-30T21:20:33.824112Z","shell.execute_reply":"2023-05-30T21:20:33.834807Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"final_meta_scores = eval_model(metamodel, sub_meta_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:20:36.670247Z","iopub.execute_input":"2023-05-30T21:20:36.670850Z","iopub.status.idle":"2023-05-30T21:20:38.501764Z","shell.execute_reply.started":"2023-05-30T21:20:36.670811Z","shell.execute_reply":"2023-05-30T21:20:38.500717Z"},"trusted":true},"execution_count":179,"outputs":[{"name":"stderr","text":"100%|██████████| 4521/4521 [00:01<00:00, 2485.95it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_example[\"target\"] = final_meta_scores","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:34:14.146730Z","start_time":"2023-05-19T06:34:14.086525Z"},"execution":{"iopub.status.busy":"2023-05-30T21:20:42.609720Z","iopub.execute_input":"2023-05-30T21:20:42.610101Z","iopub.status.idle":"2023-05-30T21:20:42.617720Z","shell.execute_reply.started":"2023-05-30T21:20:42.610070Z","shell.execute_reply":"2023-05-30T21:20:42.616727Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"submission_example.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:20:43.880321Z","iopub.execute_input":"2023-05-30T21:20:43.881207Z","iopub.status.idle":"2023-05-30T21:20:43.891264Z","shell.execute_reply.started":"2023-05-30T21:20:43.881165Z","shell.execute_reply":"2023-05-30T21:20:43.890329Z"},"trusted":true},"execution_count":181,"outputs":[{"execution_count":181,"output_type":"execute_result","data":{"text/plain":"   variantid1  variantid2    target\n0    52076340   290590137  0.009577\n1    64525522   204128919  0.166921","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variantid1</th>\n      <th>variantid2</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52076340</td>\n      <td>290590137</td>\n      <td>0.009577</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>64525522</td>\n      <td>204128919</td>\n      <td>0.166921</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission_example = submission_example[[\"variantid1\", \"variantid2\", \"target\"]]","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:34:17.373009Z","start_time":"2023-05-19T06:34:17.357230Z"},"execution":{"iopub.status.busy":"2023-05-30T21:20:48.860354Z","iopub.execute_input":"2023-05-30T21:20:48.860729Z","iopub.status.idle":"2023-05-30T21:20:48.868463Z","shell.execute_reply.started":"2023-05-30T21:20:48.860702Z","shell.execute_reply":"2023-05-30T21:20:48.867363Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"submission_example.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T21:40:39.493031Z","iopub.execute_input":"2023-05-30T21:40:39.493438Z","iopub.status.idle":"2023-05-30T21:40:39.507842Z","shell.execute_reply.started":"2023-05-30T21:40:39.493400Z","shell.execute_reply":"2023-05-30T21:40:39.506757Z"},"trusted":true},"execution_count":187,"outputs":[{"execution_count":187,"output_type":"execute_result","data":{"text/plain":"   variantid1  variantid2    target\n0    52076340   290590137  0.009577\n1    64525522   204128919  0.166921","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variantid1</th>\n      <th>variantid2</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52076340</td>\n      <td>290590137</td>\n      <td>0.009577</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>64525522</td>\n      <td>204128919</td>\n      <td>0.166921</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission_example.drop_duplicates().merge(\n    test_features[[\"variantid1\", \"variantid2\"]].drop_duplicates([\"variantid1\", \"variantid2\"]),\n    on=[\"variantid1\", \"variantid2\"]\n).to_csv(\"submission_example_meta_new.csv\", index=False)","metadata":{"ExecuteTime":{"end_time":"2023-05-19T06:35:41.877989Z","start_time":"2023-05-19T06:35:41.794727Z"},"execution":{"iopub.status.busy":"2023-05-30T21:21:05.515751Z","iopub.execute_input":"2023-05-30T21:21:05.516135Z","iopub.status.idle":"2023-05-30T21:21:05.608254Z","shell.execute_reply.started":"2023-05-30T21:21:05.516106Z","shell.execute_reply":"2023-05-30T21:21:05.607261Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"markdown","source":"Upload your submission to leaderboard :)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission_example[\"target\"] = catboost_submission_scores","metadata":{"execution":{"iopub.status.busy":"2023-05-27T22:41:14.419169Z","iopub.execute_input":"2023-05-27T22:41:14.419565Z","iopub.status.idle":"2023-05-27T22:41:14.426994Z","shell.execute_reply.started":"2023-05-27T22:41:14.419531Z","shell.execute_reply":"2023-05-27T22:41:14.425824Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"# submission_example.drop_duplicates().merge(\n#     test_features[[\"variantid1\", \"variantid2\"]].drop_duplicates([\"variantid1\", \"variantid2\"]),\n#     on=[\"variantid1\", \"variantid2\"]\n# ).to_csv(\"catboost_1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-27T22:41:31.417958Z","iopub.execute_input":"2023-05-27T22:41:31.418367Z","iopub.status.idle":"2023-05-27T22:41:31.496557Z","shell.execute_reply.started":"2023-05-27T22:41:31.418335Z","shell.execute_reply":"2023-05-27T22:41:31.495437Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"markdown","source":"### Recommendations \n\n- Work with names, in electronics names often contain a lot of useful information for matching.\n- Don't forget about attributes: working with it will allow your model to better distinguish matches from non-matches.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save({\n            'siamese_model_state_dict': siam_imgs_net.state_dict(),\n            'siamese_optimizer_state_dict': optimizer.state_dict(),\n            'distance_model_state_dict': net_model.state_dict(),\n            'distance_model_optimizer_state_dict': 'утрачено :(',\n            'metamodel_state_dict': metamodel.state_dict(),\n            'metaoptimizer_state_dict': optimizer_meta.state_dict(),\n            }, \"31_05_23__1_10.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-05-30T22:14:40.747707Z","iopub.execute_input":"2023-05-30T22:14:40.748163Z","iopub.status.idle":"2023-05-30T22:14:40.771641Z","shell.execute_reply.started":"2023-05-30T22:14:40.748125Z","shell.execute_reply":"2023-05-30T22:14:40.770617Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"modelA =  Mega_model(len(dist_feats))\nmodelB = SiameseNetwork(in_features = resnet_emb_dim)\nmodelC = Mega_model(len(all_scores_list))\noptimizerA = torch.optim.Adam(modelA.parameters(), lr=3e-3)\noptimizerB = torch.optim.Adadelta(modelB.parameters(), lr=lr)\noptimizerC = torch.optim.Adam(modelA.parameters(), lr=3e-3)\n\ncheckpoint = torch.load(\"31_05_23__1_10.pt\")\nmodelA.load_state_dict(checkpoint['distance_model_state_dict'])\nmodelB.load_state_dict(checkpoint['siamese_model_state_dict'])\nmodelC.load_state_dict(checkpoint['metamodel_state_dict'])\noptimizerB.load_state_dict(checkpoint['siamese_optimizer_state_dict'])\noptimizerC.load_state_dict(checkpoint['metaoptimizer_state_dict'])\n\n\nmodelA.eval()\nmodelB.eval()\n# - or -\nmodelA.train()\nmodelB.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-30T22:14:25.082909Z","iopub.execute_input":"2023-05-30T22:14:25.083274Z","iopub.status.idle":"2023-05-30T22:14:25.118041Z","shell.execute_reply.started":"2023-05-30T22:14:25.083243Z","shell.execute_reply":"2023-05-30T22:14:25.116909Z"},"trusted":true},"execution_count":197,"outputs":[{"execution_count":197,"output_type":"execute_result","data":{"text/plain":"SiameseNetwork(\n  (feature_extractor): Sequential(\n    (0): Linear(in_features=128, out_features=128, bias=True)\n    (1): Sigmoid()\n    (2): Linear(in_features=128, out_features=128, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=128, out_features=128, bias=True)\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=256, out_features=256, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Linear(in_features=256, out_features=1, bias=True)\n  )\n  (sigmoid): Sigmoid()\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
# Как расширить датасет?

В ветке development ведется работа по расширению датасета


Для матчинга выполняется свойство транзитивности: (is_same(a,b) == True and is_same(b,c) == True) => is_same(a,c) == True

Это позволяет нам получать новые пары одинаковых и неодинаковых товаров.

Транзитивность позволяет очень сильно увеличить датасет: в моей первой имплементации 5% датасета весят больше 30Гб

Но есть подводный камень в факториальном расте процента ошибочных данных при наивной имплементации

## Гипотетически 0.001% неверной разметки исходных данных может привести к 50% неверной разметки расширенных данных

Например, если у нас есть два множества товаров A и B такие что:
*  ∀ (a1, a2) ∈ A => is_same(a1, a2) == True 
*  ∀ (b1, b2) ∈ B => is_same(b1, b2) == True
*  ∀ a1 ∈ A, ∀ b2 ∈ B => is_same(a1, b2) == False

Пусть |A| = 300, |B| = 300

Предположим, что эти множества были составлены без ошибок, но потом попался неверный target: для какого-то a1 и b1 был target = 1

Тогда эти множества сольтся в одно множество C, |С| = 600

```math
C_{300}^2 = 44850
```
```math
С_{600}^2 = 179700
```

Это значит, что верных данных будет 44850*2 = 89700, а неверных 179700 - 89700 = 90000


Тогда при таких множествах в ужасном крайнем случаеу нас в исходной разметке (44850-1)*2 = 89698 верных строк и одна неверная. Те исходный процент неверной разметки  = 0.001%, а в расширенном датасете процент неверных данных = 50%



# Важные insight'ы про задачу

## Одно слово меняет всё
Два товара могут иметь буквально все одинаковое от изображений до атирбутов, отличаясь лишь одинм словом в названии, и при этом быть разными товарами:
    
Например, синтетическое и полусинтетическое моторное масло

## Чтобы товары были одинаковыми требуется, чтобы характеристики были одинаковыми

В частности одинаковым должен быть
* цвет
* объем
* линейные размеры

Но нужно учитывать, что иногда у кого-то написано “синий”, к кого-то “черный”, у кого-то “темно-синий”, но на самом деле это на картинке один цвет. Тогда это один товар


# В чем Гарри хочет разобраться
* Как устроен катбуст
* Как устроен contrastive loss (был использован для получение эмбеддингов изображений)


# Разделимые задачи
* поиск моделей, выдающих высокую метрику
* реализация взвешивания
    * например, вывод уверенностей моделей в одну табличку и пройтись MLP
* расширение датасета


# Идеи
* Использовать tripplet loss
* Мб для обработки категорий иисопльзовать графовые нейронные сети, так как категории являются деревьсями?